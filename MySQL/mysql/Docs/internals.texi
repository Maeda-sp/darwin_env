\input texinfo  @c -*-texinfo-*-
@c Copyright 2002 MySQL AB
@c
@c %**start of header
@setfilename internals.info

@c We want the types in the same index
@synindex cp fn

@iftex
@afourpaper
@end iftex

@c Get version and other info
@include include.texi

@ifclear tex-debug
@c This removes the black squares in the right margin
@finalout
@end ifclear

@c Set background for HTML
@set _body_tags BGCOLOR=#FFFFFF TEXT=#000000 LINK=#101090 VLINK=#7030B0
@settitle MySQL Internals Manual for version @value{mysqlversion}.
@setchapternewpage odd
@paragraphindent 0

@c %**end of header

@ifinfo
@format
START-INFO-DIR-ENTRY
* mysql-internals: (mysql-internals).               MySQL internals.
END-INFO-DIR-ENTRY
@end format
@end ifinfo

@titlepage
@sp 10
@center @titlefont{MySQL Internals Manual}
@sp 10
@center Copyright @copyright{} 1998-2004 MySQL AB
@page
@end titlepage

@node Top, guided tour, (dir), (dir)

@ifinfo
This is a manual about MySQL internals.
@end ifinfo

@center Copyright @copyright{} 1998-2004 MySQL AB

@menu
* guided tour::                 A Guided Tour Of The MySQL Source Code
* coding guidelines::           Coding Guidelines
* optimizer::                   The Optimizer
* Algorithms::                  Important Algorithms and Structures
* MySQL column types::          The different column types in MySQL
* Charsets::                    Charsets and Related Issues
* selects::                     How MySQL Performs Different Selects
* transformations::             How MySQL Transforms Subqueries
* Client/Server Protocol::      MySQL Client/Server Protocol
* Replication::                 Replication
* MyISAM Record Structure::     @code{MyISAM} Record Structure
* The .MYI file::               The @file{.MYI} file
* InnoDB Record Structure::     @code{InnoDB} Record Structure
* InnoDB Page Structure::       @code{InnoDB} Page Structure
* Error message::               Adding New Error Messages to MySQL
* Files in MySQL Sources::      Annotated List of Files in the MySQL Source Code Distribution
* Files in InnoDB Sources::     Annotated List of Files in the @code{InnoDB} Source Code Distribution
@end menu

@node guided tour, coding guidelines, Top, Top
@chapter A Guided Tour Of The MySQL Source Code

Hi, welcome to chapter 1.
What we're about to do in this chapter is pick up the latest
copy of the MySQL source code off the Internet. Then
we'll get a list of the directories and comment on why
they're there. Next we'll open up some of the files that
are vital to MySQL's working, and comment on specific
lines in the source code. We'll close off with a few
pictures of file formats.

@strong{BitKeeper}

We want to download the latest, the very latest, version
of the MySQL server. So we won't click "Downloads" on the MySQL
Developer Zone page -- that's usually a few weeks old.
Instead we'll get BitKeeper (tm), which is a revision
control package, vaguely like CVS or Perforce. This is what MySQL's
developers use every day, so what we download with BitKeeper
is usually less than a day old. If you've ever submitted
a bug report and gotten the response
"thanks, we fixed the bug in the source code repository"
that means you can get the fixed version with BitKeeper.

First, log on to www.bitkeeper.com and register. One way is:
@example
- Click "Downloads" which takes you to the downloads page
  http://bitkeeper.com/Products.BK_Pro.Downloads.html
- Click on "Software download form" which takes you to
  http://www.bitmover.com/cgi-bin/download.cgi
- Fill in all the fields, including the Platform name,
  which was "Linux/x86 ..." for us, but you'll be okay with
  other choices. Like MySQL, BitKeeper is available on
  many platforms, so the details will vary here.
- Click "Send Requests".
@end example
Then you'll have to wait until BitKeeper mails you some
more instructions, which are actually quite simple. There
is no fee to use BitKeeper for downloads of open-source
code repositories like MySQL's.

After you have BitKeeper, you'll be able to clone.
That is, you'll be able to get a copy of the source
code, using a statement that looks like this:
@example
shell> bk clone
@end example
... that is,
@example
bk clone <MySQL machine:/directory name> <your directory name>
... that is,
- Start a shell
- On the shell, make a directory named (say) mysql-5.0:
  md /mysql-5.0
  cd /
- bk clone bk://mysql.bkbits.net/mysql-5.0 mysql-5.0
@end example

There is a lot of code, so the first time you do this
the download will take over an hour. That's if you're lucky.
Glitches can occur, for example the 'bk' command fails due
to a firewall restriction.

If you're glitch-prone, you'll need to read the manual:
Section 2.8.3, Installing from the Development Source Tree.

On later occasions, you'll be doing what's called a "bk pull"
instead of a "bk clone", and it will go faster. Typically
a "bk pull" 10 minutes and is glitch-free.

@strong{Directories, Alphabetical Order}

After bk clone finishes and says "Clone completed successfully"
you'll have 41 new sets of files on your computer, as you'll
be able to see with "ls" or "dir".

@example
bdb              
BitKeeper        
BUILD            
Build-tools      
client           
cmd-line-utils   
config             
dbug             
Docs             
extra            
heap             
include          
innobase         
libmysql         
libmysql_r       
libmysqld        
man              
myisam           
myisammrg          
mysql-test       
mysys            
ndb                
netware          
NEW-RPMS         
os2              
pstack           
regex            
SCCS            
scripts         
server-tools      
sql             
sql-bench       
sql-common        
SSL             
strings         
support-files   
tests           
tools           
VC++Files       
vio             
zlib            
@end example

These will all be installed
as directories below the directory that you chose
when you ran bk clone. At first all these directory
names might intimidate you, and that's natural. After
all, MySQL is a big project. But we're here to show
you that there's order in this apparent chaos.

@strong{The Major Directories}

@example
#1 BUILD
#2 client
#3 Docs
#4 myisam
#5 mysys
#6 sql
#7 vio
@end example

The orderly approach is to look first at the most
important directories, then we'll look at the whole
list in our second pass. So, first, let's look at
what you'll find in just seven of the directories:
BUILD, client, Docs, myisam, mysys, sql, and vio.

@strong{The Major Directories: #1 BUILD}

The first major directory we'll look at is BUILD.
It actually has very little in it, but it's
vital, because one of the first things you might
want to do with the source code is: compile and
link it.

The example command line that we'll use is
@example
BUILD/compile-pentium-debug
@end example
It invokes
a batch file in the BUILD directory. When it's
done, you'll have an executable MySQL server and
client.

Or, um, well, maybe you won't. Sometimes people
have trouble with this step because there's
something missing in their operating system version,
or whatever. Don't worry, it really does work, and
there are people around who might help you if you have
trouble with this step. Search for "build" in the
archives of lists.mysql.com.

We, when we're done building, tend to install it with
@example
make
make install
@end example
(You have to be root to do this.)
Typically this causes the new MySQL installation on
@example
/usr/local/mysql/libexec      -- for the server
/usr/local/mysql/lib          -- for the mysql client
@end example

@strong{gdb GNU debugger}

Once you've got something that runs, you can put
a debugger on it. We recommend use of the GNU debugger

@example
http://www.gnu.org/software/gdb/documentation/
@end example

And many developers use the graphical debugger tool
DDD - Data Display Debugger

@example
http://www.gnu.org/software/ddd/manual/
@end example

These are free and common, they're probably
on your Linux system already.

There are debuggers for Windows and other operating
systems, of course -- don't feel left out just because
we're mentioning a Linux tool name! But it happens
that we do a lot of things with Linux ourselves, so
we happen to know what to say. To debug the mysqld server,
say:

@example
xhost +
su root
ddd --gdb --args /usr/local/mysql/libexec/mysqld --user=root --skip-networking
@end example

From this point on, it may be tempting to follow
along through the rest of the "guided tour" by
setting breakpoints, displaying the contents of
variables, and watching what happens after starting
a client from another shell. That would be more fun.
But it would require a detour, to discuss how to use
the debugger. So we'll plow forward, the dull way,
noting what's in the directories and using a text
editor to note what's in the individual files.

@strong{The Major Directories: #2 client}

The next major directory is mysql-5.0/client.

@example
size   name          comment
----   ----          -------
 93733 mysql.cc     "The MySQL command tool"
 36935 mysqladmin.c maintenance of MYSQL databases
 20680 mysqlshow.c  show databases, tables, or columns
+ 15 more .c and .cc programs
@end example

It has the source code of many of your familiar favourites,
like mysql, which everybody has used to connect to
the MySQL server at one time or another. There are
other utilities too -- in fact, you'll find the source
of most client-side programs here. There are also
programs for checking the password, and for testing that
basic functions -- such as threading or access via SSL --
are possible.

You'll notice, by the way, that we're concentrating
on the files that have extension of ".c" or ".cc".
By now it's obvious that C is our principal language
although there are some utilities written in Perl as
well.

@strong{The Major Directories: #3 Docs}

The next major directory is mysql-5.0/Docs.

With the BitKeeper downloads, /Docs is nearly empty.
The important files are only present if you do a
regular source-file download, or if you do a separate
'bk clone' for 'mysqldoc' instead of 'mysql-5.0'
(in which case this major directory is mysqldoc/Docs
instead of mysql-5.0/Docs). Let's just pretend that
either of those scenarios applies, so there are some
important files here:

@example
size   name           comment
----   ----           -------
384644 world.sql      script to make 'world' database
372681 internals.texi internals manual
4314634 manual.texi   reference manual
+ 9 more .texi programs
@end example

The documentation files with the extension .texi are
written for an open-source text-formatting package,
Texinfo. The documentation is here:
http://www.gnu.org/software/texinfo/manual/texinfo/
However, you might want to skip becoming an expert,
because MySQL might switch to using DocBook someday.
The important thing to learn is how to convert .texi
to .html, and that's reasonably easy. Example:

@example
texi2html internals.texi
@end example

You can do that with manual.texi, but you've already
seen what the result looks like -- it's the MySQL
Reference Manual available online -- so let's look
at what the real "source code" lover cares about,
internals.texi. After converting it to .html and
opening it with a browser, click "Coding Guidelines"
to see the table of contents.

@example
Contents of internals.texi (abbreviated titles):

Coding Guidelines
The Optimizer
Important Algorithms and Structures
The different column types in MySQL
Charsets and Related Issues
How MySQL Performs Different Selects
How MySQL Transforms Subqueries
MySQL Client/Server Protocol
Replication
MyISAM Record Structure
The '.MYI' file
InnoDB Record Structure
InnoDB Page Structure
Adding New Error Messages to MySQL
Annotated List of MySQL Source Code Files
Annotated List of InnoDB Source Code Files
@end example

At this moment, internals.texi has over 100 pages
of information, including some details about the
formats of MySQL files that you won't find anywhere
else, and a complete description of the message
formats that the client and server use to communicate.
Although it's rough and may contain errors and is
obsolete in parts, it is a document that you must
read to truly understand the workings of MySQL.

@strong{The Major Directories: #4 myisam}

The next major directory is labelled myisam. We will
begin by mentioning that myisam is one of what we call
the MySQL handler directories.

@example
The MySQL handler directories:
heap           -- also known as 'memory'
innodb         -- maintained by Innobase Oy
isam           -- no longer distributed as part of 5.0
myisam         -- see next section!
ndb            -- ndb cluster
@end example

For example the heap directory contains the source files
for the heap handler and the ndb directory contains
the source files for the ndb handler.

But the files in those directories are mostly duplicates
of what's in the myisam directory, and the myisam
directory is sort of a 'template' and least common denominator.

On the myisam directory, you'll find the programs that
do file I/O. Notice that the file names begin with the
letters mi, by the way. That stands for MyISAM, and
most of the important files in this directory start with
mi.

File handling programs on mysql-5.0/myisam:

@example
size   name           comment
----   ----           -------
 40299 mi_open.c      for opening
  3593 mi_close.c     for closing
  1951 mi_rename.c    for renaming
+ more mi_*.c programs
@end example

Row handling programs on mysql-5.0/myisam:

@example
size   name           comment
----   ----           -------
 29064 mi_delete.c    for deleting
  2562 mi_delete_all.c for deleting all
  6797 mi_update.c    for updating
 31847 mi_write.c     for inserting
+ more mi_*.c programs
@end example

Drilling down a bit, you'll also find programs in the
myisam directory that handle deleting, updating, and
inserting of rows. The only one that's a little hard
to find is the program for inserting rows, which we've
called mi_write.c instead of mi_insert.c.

Key handling programs on mysql-5.0/myisam:

@example
size   name           comment
----   ----           -------
 29064 mi_rkey.c      for random key searches
  2562 mi_rnext.c     for next-key searches
  6797 mi_key.c       for key searches in general
+ more mi_*.c programs
@end example

The final notable group of files in the myisam
directory is the group that handles keys in indexes.

To sum up:
(1) The myisam directory is where you'll find
programs for handling files, rows, and keys. You
won't find programs for handling columns -- we'll get
to them a bit later.
(2) The myisam directory is just one of the handler
directories. The programs in the other handler directories
fulfill about the same functions.

@strong{The Major Directories: #5 mysys}

The next major directory is labelled mysys, which
stands for MySQL System Library. This is
the toolbox directory, for example it has low
level routines for file access. The .c files in mysys have
procedures and functions that are handy for calling
by main programs, for example by the programs in the
myisam directory. There are 115 .c files in mysys, so
we only can note a sampling.

Sampling of programs on mysql-5.0/mysys

@example
size   name           comment
----   ----           -------
 16477 charset.c      character sets
  6165 mf_qsort.c     quicksort
  5521 mf__tempfile.c temporary files
+ 112 more *.c programs
@end example

Example one: with charset.c routines, you can change
the character set.

Example two: mf_qsort.c contains our quicksort package.

Example three: mf_tempfile.c has what's needed for
maintaining MySQL's temporary files.

You can see from these examples that mysys is a
hodgepodge. That's why we went to the trouble of
producing extra documentation to help you analyze
mysys's contents, in the internals.texi document that
we mentioned earlier.

@strong{The Major Directories: #6 sql}

The next major directory is mysql-5.0/sql.
If you remember your manual, you know that you
must pronounce this: ess queue ell.

The "parser" programs on mysql-5.0/sql:

@example
size   name           comment
----   ----           -------
 50788 sql_lex.cc     lexer
193323 sql_parse.cc   parser
+ many more *.cc programs
@end example

This is where we keep the parser. In other words,
programs like sql_lex.cc and sql_parse.cc are
responsible for figuring out what's in an SQL
command, and deciding what to do about it.

The "handler" programs on mysql-5.0/sql:

@example
size   name           comment
----   ----           -------
 79262 ha_berkeley.cc bdb
 56687 ha_federated.cc federated (sql/med)
 15834 ha_heap.cc     heap (memory)
185233 ha_innodb.cc   innodb
 47138 ha_myisam.cc   myisam
 13542 ha_isammrg.cc  merge
153806 ha_ndbcluster.cc ndb
@end example

This is also where we keep the handler programs.
Now, you'll recall that the handler itself, for
example myisam, is a separate directory. But here
in the sql directory, we have programs which are
responsible for determining which handler to call,
formatting appropriate arguments, and checking
results. In other words, the programs that begin
with the letters ha are the handler interface
programs, and there's one for each handler.

The "statement" routines in mysql-5.0/sql:

@example
size   name           comment
----   ----           -------
 22535 sql_delete.cc  'delete ...' statement
  1220 sql_do.cc      'do ...'
 22162 sql_help.cc    'help ...'
 63313 sql_insert.cc  'insert ...'
401755 sql_select.cc  'select ...'
121929 sql_show.cc    'show ...'
 41127 sql_update.cc  'update ...'
+ many more sql_*.cc programs
@end example

Also in the sql directory, you'll find individual
programs for handling each of the syntactical
components of an SQL statement. These programs
tend to have names beginning with sql_. So for
the SELECT statement, check out sql_select.cc.

Thus, there are "statement" routines like
sql_delete.c, sql_load.c, and sql_help.c, which
take care of the DELETE, LOAD DATA, and HELP
statements. The file names are hints about the SQL
statements involved.

The "statement function" routines in mysql-5.0/sql:

@example
size   name           comment
----   ----           -------
 19854 sql_string.cc  strings
  6151 sql_olap.cc    olap (rollup)
 13105 sql_udf.cc     user-defined functions
 18214 sql_union.cc   unions
@end example

Then there are the routines for components of
statements, such as strings, or online analytical
processing, or user-defined functions, or the
UNION operator.

@strong{The Major Directories: #7 vio}

The final major directory that we'll highlight today
is labelled vio, for "virtual I/O".

The vio routines are wrappers for the various network
I/O calls that happen with different protocols. The
idea is that in the main modules one won't have to
write separate bits of code for each protocol. Thus
vio's purpose is somewhat like the purpose of
Microsoft's winsock library.

And the preceding paragraph about vio is actually a
quotation from the internals documentation file,
internals.texi, which we mentioned earlier.

(We didn't lift the quotation because I'm lazy, but to
indicate the sort of information that's in the
documentation.)

Okay, that wraps up our quick look at the seven major
directories. Just one summary chart remains to do.

@strong{The Flow}

This is a diagram of the flow.

@example
 User enters "INSERT" statement     /* client */
 |
 |
 Message goes over TCP/IP line      /* vio, various */
 |
 |
 Server parses statement            /* sql */
 |
 |
 Server calls low-level functions   /* mysys */
 |
 |
 Handler stores in file             /* myisam */
@end example

The diagram is very simplified -- it's a caricature that
distorts important things, but remember that we've only
discussed seven major directories so far: Docs, BUILD, and
the five that you see here.

The flow works like this:

First, the client routines get an SQL statement from a user,
allowing edit, performing initial checks, and so on.

Then, via the vio routines, the somewhat-massaged
statement goes off to the server.

Next, the sql routines handle the parsing and call what's
necessary for each individual part of the statement. Along the
way, the sql routines will be calling the low level mysys
routines frequently.

Finally, one of the ha (handler) programs in the sql directory
will dispatch to an appropriate handler for storage. In this case
we've assumed, as before, that the handler is myisam -- so a
myisam-directory program is involved. Specifically, that
program is mi_write.c, as we mentioned earlier.

Simple, eh?

@strong{The Open-source Directories}

We're now getting into the directories which aren't "major".
Starting with:

@example
dbug
pstack
regex
strings
zlib
@end example

Now it's time to reveal a startling fact, which is --
we didn't write all of the source code in all of the
source code directories all by ourselves. This list
is, in a sense, a tribute to the idea of open source.

There's dbug, which is Fred Fish's debug library.

There's pstack, which displays the process stack.

There's regex, which is what we use for our regular
expressions function.

There's strings, the meaning of which is obvious.

There's zlib, which is for Zempel-Liv compression.

All of the programs in these directories were supplied
by others, as open source code. We didn't just take them,
of course. MySQL has checked and changed what's in these
directories. But we acknowledge with thanks that they're
the products of other projects, and other people's labour,
and we only regret that we won't have time to note all
the contributed or publicly available components of MySQL.

@strong{The Internal and External Handler Directories}

Continuing with our extract from the directory list ...

@example
bdb                           /* external */
heap
innobase                      /* external */
myisam
myisammrg
ndb
@end example

Let's go through the idea of handlers once more,
this time with a list of all the handlers, both the
ones that we produce, and the ones that others produce.
We've already mentioned the internal ones -- so now
we'll remark on the directories of the two common external
handlers -- BDB and innobase.

The BDB, or Berkeley Database, handler, is strictly
the product of Sleepycat software. Sleepycat has a
web page at sleepycat.com, which contains, among other
things, documentation for their product. So you can
download Sleeycat's own documentation of the source code
in the BDB directory.

As for the innobase handler, which many of you
probably use, you'll be happy to know that the
comments in the files are reasonably clear (the
InnoBase Oy people are pretty strict about comments).
There's an overview chapter in the internals.texi file.

@strong{The "OS Specific" Directories}

@example
netware
NEW-RPMS
os2
VC++Files
@end example

A few words are in order about the directories
that contain files which relate to a particular
environment that MySQL can run in.

The netware directory contains a set of files for
interfacing with netware, and anyone who has an
involvement with NetWare knows that we're
allied with them, and so this is a one of the
directories that represents a joint enterprise.

The NEW-RPMS directory is for Linux, and the os2
directory is for OS/2.

Finally, the VC++Files directory is for Windows.
We've found that the majority of Windows programmers
who download and build MySQL from source use
Microsoft Visual C. In the VC++Files directory
you will find a nearly complete replication of
what's in all the other directories that we've
discussed, except that the .c files are modified
to account for the quirks of Microsoft tools.

Without endorsing by particular names, we should
note that other compilers from other manufacturers
also work.

@strong{Odds and Ends}

Finally, for the sake of completeness, we'll put
up a list of the rest of the directories -- those
that we haven't had occasion to mention till now.

@example
Source Code Administration Directories:
BitKeeper
SCCS

Common .h Files:
include

Stand-alone Utility & Test Programs:
cmd-line-utils
extra
mysql-test
repl-tests
support-files
tests
tools
@end example

You don't have to worry about the administration
directories since they're not part of what you build.

You probably won't have to worry about the stand-alone
programs either, since you just use them, you don't
need to remake them.

Finally, there's an include directory that you SHOULD
have a look at, because the common header files for
programs from several directories are in here.

And those are the last. We've now traipsed through every
significant directory created during your download of
the MySQL source package.

@strong{A Chunk of Code in /sql/sql_update.cc}

Now, having finished with our bird's eye view of the source
code from the air, let's take the perspective of the worms
on the ground. (Which is another name for MySQL's developer
staff -- turn on laugh track here.)

@example
int mysql_update(THD *thd, ...)
@{
   ...
   if ((lock_tables(thd, table_list)))
     DBUG_RETURN(1); ...
   ...
   init_read_record(&info,thd,table,select,0,1); ...
   while (!(error=info.read_record(&info)) && !thd->killed)
   @{
      ...    
     if (!(error=table->file->update_row((byte*) table->record[1]),
                                          (byte*) table->record[0])))
        updated++;
      ...
      if (table->triggers)
        table->triggers->process_triggers(thd, TRG_EVENT_UPDATE, TRG_ACTION_AFTER);
      ...
     @}
   ...
   if (updated && (error <= 0 || !transactional_table))
   @{
     mysql_bin_log.write(&qinfo) && transactional_table);
     ...
@}
@end example

Here's a snippet of code from a .c file in the sql directory,
specifically from sql_update.cc, which -- as we mentioned earlier
-- is invoked when there's an UPDATE statement to process.

The entire routine has many error checks with handlers for
improbable solutions, and showing multiple screens would be
tedious, so we've truncated the code a lot. Where you see an
ellipsis (three dots in a row), that means "and so on".

So, what do we learn from this snippet of code? In the
first place, we see that it's fairly conventional
C code. A brace causes an indentation, instructions
tend to be compact with few unnecessary spaces, and
comments are sparse.

Abbreviations are common, for example thd stands
for thread, you just have to get used to them.
Typically a structure will be in a separate .h file.

Routine names are sometimes long enough that they
explain themselves. For example, you can probably
guess that this routine is opening and locking,
allocating memory in a cache, initializing a
process for reading records, reading records in
a loop until the thread is killed or there are
no more to read, storing a modified record for
the table, and -- after the loop is through --
possibly writing to the log. Incidentally, a
transactional table is usually a BDB or an InnoDB
table.

Obviously we've picked out what's easy to follow,
and we're not pretending it's all smooth sailing.
But this is actual code and you can check it out
yourself.

@strong{The Skeleton Of The Server Code}

And now we're going to walk through something harder, namely
the server.

WARNING WARNING WARNING: code changes constantly, so names
and parameters may have changed by the time you read this.

Important programs we'll be walking through:
@example
/sql/mysqld.cc
/sql/sql_parse.cc
/sql/sql_prepare.cc
/sql/sql_insert.cc
/sql/ha_myisam.cc
/myisam/mi_write.c
@end example

This is not as simple as what we've just done.
In fact we'll need multiple pages to walk through this one, and
that's despite our use of truncation and condensation again.
But the server is important, and if you can grasp what
we're doing with it, you'll have grasped the essence of
what the MySQL source code is all about.

We'll mostly be looking at programs in the sql directory,
which is where mysqld and most of the programs for the SQL
engine code are stored.

Our objective is to follow the server from the time it starts
up, through a single INSERT statement that it receives from a
client, to the point where it finally performs the low level
write in the MyISAM file.

Walking Through The Server Code: /sql/mysqld.cc

@example
  int main(int argc, char **argv)
  @{
    _cust_check_startup();
    (void) thr_setconcurrency(concurrency);
    init_ssl();
    server_init();                             // 'bind' + 'listen'
    init_server_components();
    start_signal_handler();
    acl_init((THD *)0, opt_noacl);
    init_slave();
    create_shutdown_thread();
    create_maintenance_thread();
    handle_connections_sockets(0);             // !
    DBUG_PRINT("quit",("Exiting main thread"));
    exit(0);
  @}
@end example

Here is where it all starts, in the main function of mysqld.cc.

Notice that we show a directory name and program name just
above this snippeg. We will do the same for all the snippets in this
series.

By glancing at this snippet for a few seconds, you will probably
see that the main function is doing some initial checks on
startup, is initializing some components, is calling a function
named handle_connections_sockets, and then is exiting. It's
possible that acl stands for "access control" and it's interesting
that DBUG_PRINT is something from Fred Fish's debug library,
which we've mentioned before. But we must not digress.

In fact there are 150 code lines in the main function, and we're
only showing 13 code lines. That will give you an idea of how much
we are shaving and pruning. We threw away the error checks, the
side paths, the optional code, and the variables. But we did not
change what was left. You will be able to find these lines if you
take an editor to the mysqld.cc program, and the same applies for
all the other routines in the snippets in this series.

The one thing you won't see in the actual source code is the little
marker "// !". This marker will always be on the line of
the function that will be the subject of the next snippet. In this
case, it means that the next snippet will show the
handle_connection_sockets function. To prove that, let's go to the
next snippet.

Walking Through The Server Code: /sql/mysqld.cc

@example
  handle_connections_sockets (arg __attribute__((unused))
  @{
     if (ip_sock != INVALID_SOCKET)
     @{
       FD_SET(ip_sock,&clientFDs);
       DBUG_PRINT("general",("Waiting for connections."));
       while (!abort_loop)
       @{
         new_sock = accept(sock, my_reinterpret_cast(struct sockaddr*)
           (&cAddr),
            &length);
         thd= new THD;
         if (sock == unix_sock)
         thd->host=(char*) localhost;
         create_new_thread(thd);            // !
         @}
@end example

Inside handle_connections_sockets you'll see the hallmarks of a
classic client/server architecture. In a classic client/server, the
server has a main thread which is always listening for incoming
requests from new clients. Once it receives such a request, it assigns
resources which will be exclusive to that client. In particular, the
main thread will spawn a new thread just to handle the connection.
Then the main server will loop and listen for new connections --
but we will leave it and follow the new thread.

As well as the sockets code that we chose to display here, there are
several variants of this thread loop, because clients can choose to
connect in other ways, for example with named pipes or with shared
memory. But the important item to note from this slide is that the
server is spawning new threads.

Walking Through The Server Code: /sql/mysqld.cc

@example
  create_new_thread(THD *thd)
  @{
    pthread_mutex_lock(&LOCK_thread_count);
    pthread_create(&thd->real_id,&connection_attrib,
        handle_one_connection,                        // !
        (void*) thd));
    pthread_mutex_unlock(&LOCK_thread_count);
  @}
@end example

Here is a close look at the routine that spawns the new thread.
The noticeable detail is that, as you can see, it uses a mutex
or mutual exclusion object. MySQL has a great variety of mutexes
that it uses to keep actions of all the threads from conflicting
with each other.

Walking Through The Server Code: /sql/sql_parse.cc

@example
handle_one_connection(THD *thd)
  @{
    init_sql_alloc(&thd->mem_root, MEM_ROOT_BLOCK_SIZE, MEM_ROOT_PREALLOC);
    while (!net->error && net->vio != 0 && !thd->killed)
    @{
      if (do_command(thd))            // !
        break;
    @}
    close_connection(net);
    end_thread(thd,1);
    packet=(char*) net->read_pos;
@end example

With this slide, we've wandered out of mysqld.cc. Now, we're in the
sql_parse program, still in the sql directory. This is where the
session's big loop is.

The loop repeatedly gets and does commands. When it ends, the
connection closes. At that point, the thread will end and the
resources for it will be deallocated.

But we're more interested in what happens inside the loop, when we
call the do_command function.

@example
Graphic:

   client           <===== MESSAGE ====>       server
                    <======PACKETS ====>

   Example:
   INSERT INTO Table1 VALUES (1);
@end example

To put it graphically, at this point there is a long-lasting
connection between the client and one server thread. Message
packets will go back and forth between them through this
connection. For today's tour, let's assume that the client
passes the INSERT statement shown on the Graphic, for the server
to process.

Walking Through The Server Code: /sql/sql_parse.cc

@example
bool do_command(THD *thd)
@{
  net_new_transaction(net);
  packet_length=my_net_read(net);
  packet=(char*) net->read_pos;
  command = (enum enum_server_command) (uchar) packet[0];
  dispatch_command(command,thd, packet+1, (uint) packet_length);
// !
@}
@end example

You've probably noticed by now that whenever we call a lower-level
routine, we pass an argument named thd, which is an abbreviation
for the word thread (we think). This is the essential context which we
must never lose.

The my_net_read function is in another program called net_serv.cc. It
gets a packet from the client, uncompresses it, and strips the header.

Once that's done, we've got a multi-byte variable named packet which
contains what the client has sent. The first byte is important because
it contains a code identifying the type of message.

We'll pass that and the rest of the packet on to the dispatch_command
function.

Walking Through The Server Code: /sql/sql_parse.cc

@example
bool dispatch_command(enum enum_server_command command, THD *thd,
       char* packet, uint packet_length)
@{
  switch (command) @{
    case COM_INIT_DB:          ...
    case COM_REGISTER_SLAVE:   ...
    case COM_TABLE_DUMP:       ...
    case COM_CHANGE_USER:      ...
    case COM_EXECUTE:
         mysql_stmt_execute(thd,packet);
    case COM_LONG_DATA:        ...
    case COM_PREPARE:
         mysql_stmt_prepare(thd, packet, packet_length);   // !
    /* and so on for 18 other cases */
    default:
     send_error(thd, ER_UNKNOWN_COM_ERROR);
     break;
    @}
@end example

And here's just part of a very large switch statement in sql_parse.cc.
The snippet doesn't have room to show the rest, but you'll see when you
look at the dispatch_command function that there are more case
statements after the ones that you see here.

There will be -- we're going into list mode now and just reciting the
rest of the items in the switch statement -- code for prepare, close
statement, query, quit, create database, drop database, dump binary
log, refresh, statistics, get process info, kill process, sleep,
connect, and several minor commands. This is the big junction.

We have cut out the code for all of the cases except for two,
COM_EXECUTE and COM_PREPARE.

Walking Through The Server Code: /sql/sql_prepare.cc

We are not going to follow what happens with COM_PREPARE. Instead,
we are going to follow the code after COM_EXECUTE. But we'll have to
digress from our main line for a moment and explain what the prepare
does.

@example
"Prepare:
Parse the query
Allocate a new statement, keep it in 'thd->prepared statements' pool
Return to client the total number of parameters and result-set
metadata information (if any)"
@end example

The prepare is the step that must happen before execute happens. It
consists of checking for syntax errors, looking up any tables and
columns referenced in the statement, and setting up tables for the
execute to use. Once a prepare is done, an execute can be done
multiple times without having to go through the syntax checking and
table lookups again.

Since we're not going to walk through the COM_PREPARE code, we decided
not to show any code at this point. Instead, we have cut and pasted
some code comments that describe prepare. All we're illustrating here
is that there are comments in the code, so you will have aid when you
look harder at the prepare code.

Walking Through The Server Code: /sql/sql_parse.cc

@example
  bool dispatch_command(enum enum_server_command command, THD *thd,
       char* packet, uint packet_length)
  @{
  switch (command) @{
    case COM_INIT_DB:          ...
    case COM_REGISTER_SLAVE:   ...
    case COM_TABLE_DUMP:       ...
    case COM_CHANGE_USER:      ...
    case COM_EXECUTE:
         mysql_stmt_execute(thd,packet);                   // !
    case COM_LONG_DATA:        ...
    case COM_PREPARE:
         mysql_stmt_prepare(thd, packet, packet_length);
    /* and so on for 18 other cases */
    default:
     send_error(thd, ER_UNKNOWN_COM_ERROR);
     break;
    @}
@end example

Let's return to the grand central junction again in sql_parse.cc
for a moment. The thing to note on this slide is that the line
which we're really going to follow is what happens for COM_EXECUTE.

Walking Through The Server Code: /sql/sql_prepare.cc

@example
  void mysql_stmt_execute(THD *thd, char *packet)
  @{
    if (!(stmt=find_prepared_statement(thd, stmt_id, "execute")))
    @{
      send_error(thd);
      DBUG_VOID_RETURN;
    @}
    init_stmt_execute(stmt);
    mysql_execute_command(thd);           // !
  @}
@end example

In this case, the line that we're following is the line that executes
a statement.

Notice how we keep carrying the THD thread and the packet along with
us, and notice that we expect to find a prepared statement waiting for
us, since this is the execute phase. Notice as well that we continue
to sprinkle error-related functions that begin with the letters DBUG,
for use by the debug library. Finally, notice that the name stmt is
the same name that ODBC uses for the equivalent object. We try to use
standard names when they fit.

Walking Through The Server Code: /sql/sql_parse.cc

@example
  void mysql_execute_command(THD *thd)
       switch (lex->sql_command) @{
       case SQLCOM_SELECT: ...
       case SQLCOM_SHOW_ERRORS: ...
       case SQLCOM_CREATE_TABLE: ...
       case SQLCOM_UPDATE: ...
       case SQLCOM_INSERT: ...                   // !
       case SQLCOM_DELETE: ...
       case SQLCOM_DROP_TABLE: ...
       @}
@end example

In the mysql_execute_command function. we encounter another
junction. One of the items in the switch statement is named
SQLCOM_INSERT.

Walking Through The Server Code: /sql/sql_parse.cc

@example
case SQLCOM_INSERT:
@{
  my_bool update=(lex->value_list.elements ? UPDATE_ACL : 0);
  ulong privilege= (lex->duplicates == DUP_REPLACE ?
                    INSERT_ACL | DELETE_ACL : INSERT_ACL | update);
  if (check_access(thd,privilege,tables->db,&tables->grant.privilege))
    goto error;
  if (grant_option && check_grant(thd,privilege,tables))
    goto error;
  if (select_lex->item_list.elements != lex->value_list.elements)
  @{
    send_error(thd,ER_WRONG_VALUE_COUNT);
    DBUG_VOID_RETURN;
  @}
  res = mysql_insert(thd,tables,lex->field_list,lex->many_values,
                     select_lex->item_list, lex->value_list,
                     (update ? DUP_UPDATE : lex->duplicates));
// !
  if (thd->net.report_error)
    res= -1;
  break;
@}
@end example

For this snippet, we've blown up the code around the SQLCOM_INSERT case
in the mysql_execute_command function. The first thing to do is
check whether the user has the appropriate privileges for doing
an INSERT into the table, and this is the place where the server
checks for that, by calling the check_access and check_grant
functions. It would be tempting to follow those functions, but
those are side paths. Instead, we'll follow the path where the work
is going on.

Walking Through The Server Code: Navigation Aid

Some program names in the /sql directory:

@example
Program Name          SQL statement type
------------          ------------------
sql_delete.cc         DELETE
sql_do.cc             DO
sql_handler.cc        HANDLER
sql_help.cc           HELP
sql_insert.cc         INSERT            // !
sql_load.cc           LOAD
sql_rename.cc         RENAME
sql_select.cc         SELECT
sql_show.cc           SHOW
sql_update.cc         UPDATE
@end example

Question: Where will mysql_insert() be?

The line that we're following will take us next to a routine
named mysql_insert. Sometimes it's difficult to guess what
program a routine will be in, because MySQL has no consistent
naming convention. However, here is one aid to navigation that
works for some statement types. In the sql directory, the
names of some programs correspond to statement types. This
happens to be the case for INSERT, for instance. So the
mysql_insert program will be in the program sql_insert.cc.
But there's no reliable rule.

Walking Through The Server Code: /sql/sql_insert.cc

@example
  int mysql_insert(THD *thd,TABLE_LIST *table_list, List<Item> &fields,
        List<List_item> &values_list,enum_duplicates duplic)
  @{
    table = open_ltable(thd,table_list,lock_type);
    if (check_insert_fields(thd,table,fields,*values,1) ||
      setup_tables(table_list) ||
      setup_fields(thd,table_list,*values,0,0,0))
      goto abort;
    fill_record(table->field,*values);
    error=write_record(table,&info);                 // !
    query_cache_invalidate3(thd, table_list, 1);
    if (transactional_table)
      error=ha_autocommit_or_rollback(thd,error);
    query_cache_invalidate3(thd, table_list, 1);
    mysql_unlock_tables(thd, thd->lock);
    @}
@end example

For the mysql_insert routine, we're just going to read what's
in the snippet. What we're trying to do here is highlight the fact
that the function names and variable names are nearly English.

Okay, we start by opening a table. Then, if a check of the fields
in the INSERT fails, or if an attempt to set up the tables fails,
or if an attempt to set up the fields fails, we'll abort.

Next, we'll fill the record buffer with values. Then we'll write the
record. Then we'll invalidate the query cache. Remember, by the
way, that MySQL stores frequently-used select statements and result
sets in memory as an optimization, but once the insert succeeds
the stored sets are invalid. Finally, we'll unlock the tables.

Walking Through The Server Code: /sql/sql_insert.cc

@example
  int write_record(TABLE *table,COPY_INFO *info)
  @{
    table->file->write_row(table->record[0];           // !
  @}
@end example

You can see from our marker that we're going to follow the
line that contains the words 'write row'. But this is not an
ordinary function call, so people who are just reading the
code without the aid of a debugger can easily miss what
the next point is in the line of execution here. The fact
is, 'write_row' can take us to one of several different
places.

Walking Through The Server Code: /sql/handler.h

@example
  /* The handler for a table type.
     Will be included in the TABLE structure */

  handler(TABLE *table_arg) :
table(table_arg),active_index(MAX_REF_PARTS),
    ref(0),ref_length(sizeof(my_off_t)),
block_size(0),records(0),deleted(0),
    data_file_length(0), max_data_file_length(0),
index_file_length(0),
    delete_length(0), auto_increment_value(0), raid_type(0),
    key_used_on_scan(MAX_KEY),
    create_time(0), check_time(0), update_time(0), mean_rec_length(0),
    ft_handler(0)
    @{@}
  ...
  virtual int write_row(byte * buf)=0;
@end example

To see what the write_row statement is doing, we'll have to look at one of
the include files. In handler.h on the sql directory, we find that
write_row is associated with a handler for a table. This definition
is telling us that the address in write_row will vary -- it gets
filled in at run time. In fact, there are several possible addresses.

There is one address for each handler. In our case, since we're using
the default values, the value at this point will be the address of
write_row in the MyISAM handler program.

Walking Through The Server Code: /sql/ha_myisam.cc

@example
int ha_myisam::write_row(byte * buf)
@{
  statistic_increment(ha_write_count,&LOCK_status);
   /* If we have a timestamp column, update it to the current time */
   if (table->time_stamp)
    update_timestamp(buf+table->time_stamp-1);
   /*
  If we have an auto_increment column and we are writing a changed row
    or a new row, then update the auto_increment value in the record.
  */
  if (table->next_number_field && buf == table->record[0])
    update_auto_increment();
  return mi_write(file,buf);     // !
@}
@end example

And that brings us to write_row in the ha_myisam.cc program. Remember
we told you that these programs beginning with the letters ha
are interfaces to handlers, and this one is the interface to the
myisam handler. We have at last reached the point where we're ready
to call something in the handler package.

Walking Through The Server Code: /myisam/mi_write.c

@example
int mi_write(MI_INFO *info, byte *record)
@{
  _mi_readinfo(info,F_WRLCK,1);
  _mi_mark_file_changed(info);
  /* Calculate and check all unique constraints */
  for (i=0 ; i < share->state.header.uniques ; i++)
  @{
    mi_check_unique(info,share->uniqueinfo+i,record,
      mi_unique_hash(share->uniqueinfo+i,record),
      HA_OFFSET_ERROR);
  @}

  ... to be continued in next snippet
@end example

Notice that at this point there is no more referencing of tables,
the comments are about files and index keys. We have reached the
bottom level at last. Notice as well that we are now in a C
program, not a C++ program.

In this first half of the mi_write function, we see a call which
is clearly commented. This is where checking happens for columns
defined as UNIQUE.

Walking Through The Server Code: /myisam/mi_write.c

@example
 ... continued from previous snippet

  /* Write all keys to indextree */
  for (i=0 ; i < share->base.keys ; i++)
  @{
    share->keyinfo[i].ck_insert(info,i,buff,
      _mi_make_key(info,i,buff,record,filepos)
  @}
  (*share->write_record)(info,record);
  if (share->base.auto_key)
    update_auto_increment(info,record);
@}
@end example

In this second half of the mi_write function, we see another clear
comment, to the effect that this is where the new keys are made
for any indexed columns. Then we see the culmination of all that
the last 20 slides have been preparing, the moment we've all been
waiting for, the writing of the record.

And, since the object of the INSERT statement is ultimately to
cause a write to a record in a file, that's that. The server
has done the job.

Walking Through The Server Code: Stack Trace

@example
main in /sql/mysqld.cc
handle_connections_sockets in /sql/mysqld.cc
create_new_thread in /sql/mysqld.cc
handle_one_connection in /sql/sql_parse.cc
do_command in /sql/sql_parse.cc
dispatch_command in /sql/sql_parse.cc
mysql_stmt_execute in /sql/sql_prepare.cc
mysql_execute_command in /sql/sql_parse.cc
mysql_insert in /sql/mysql_insert.cc
write_record in /sql/mysql_insert.cc
ha_myisam::write_row in /sql/ha_myisam.cc
mi_write in /myisam/mi_write.c
@end example

And now here's a look at what's above us on the stack, or at
least an idea of how we got here. We started with the main
program in mysqld.cc. We proceeded through the creation of a
thread for the client, the several junction processes that
determined where we're heading, the parsing and initial
execution of an SQL statement, the decision to invoke the
MyISAM handler, and the writing of the row. We ended in a
low level place, where we're calling the routines that write
to the file. That's about as low as we should go today.

The server program would, of course, continue by returning
several times in a row, sending a packet to the client saying
"Okay", and ending up back in the loop inside the
handle_one_connection function.

We, instead, will pause for a moment in awe at the amount of
code we've just flitted past. And that will end our walk
through the server code.

@example
Graphic: A Chunk of MyISAM File

CREATE TABLE Table1 (
   column1 CHAR(1),
   column2 CHAR(1),
   column3 CHAR(1));

INSERT INTO Table1 VALUES ('a', 'b', 'c');

INSERT INTO Table1 VALUES ('d', NULL, 'e');

F1 61 62 63 00 F5 64 00 66 00 ... .abc..d e.
@end example

Continuing with our worm's-eye view, let's glance
at the structure of a record in a MyISAM file.

The SQL statements on this graphic show a table
definition and some insert statements that we
used to populate the table.

The final line on the graphic is a hexadecimal dump
display of the two records that we ended up with,
as taken from the MyISAM file for Table1.

The thing to notice here is that the records
are stored compactly. There is one byte at the
start of each record -- F1 for the first record
and F5 for the second record -- which contains
a bit list.

When a bit is on, that means its corresponding field
is NULL. That's why the second row, which has a NULL
in the second column, or field, has a different header
byte from the first row.

Complications are possible, but a simple record
really does look this simple.

NOTE TO READER: Yes, we know you don't believe
worms have eyes. Leave it alone, this isn't
some zoology class. Also, yes, we know this
is unoriginal since it's from internals.texi.
Maybe you'll dream up a more exotic example.
Ditto for the next snippet.

@example
Graphic: A Chunk of InnoDB File

19 17 15 13 0C 06 Field Start Offsets /* First Row */
00 00 78 0D 02 BF Extra Bytes
00 00 00 00 04 21 System Column #1
00 00 00 00 09 2A System Column #2
80 00 00 00 2D 00 84 System Column #3
50 50 Field1 'PP'
50 50 Field2 'PP'
50 50 Field3 'PP'
@end example

If, on the other hand, you look at an InnoDB
file, you'll find that it's got more complexities
in the storage. The details are in the internals.texi
document -- which you'll find in the Docs directory,
remember -- and you can ask for more details when
you go to Heikki Tuuri's presentation at the MySQL
User converence. But here's an introductory
look.

The header here begins with offsets -- unlike MyISAM,
which has no offsets. So you'd have to go through
column 1 before getting to column 2.

Then there is a fixed header -- the extra bytes.

Then comes the record proper. The first fields of a
typical record contain information that the user won't
see, such as a row ID, a transaction ID, and a rollback
pointer. This part would look different if the user had
defined a primary key during the CREATE TABLE statement.

And finally there are the column contents -- the
string of Ps at the end of the slide here. You
can see that InnoDB does more administrating.

@example
Graphic: A Packet

Header
Number Of Rows
ID
Status
Length
Message Content
@end example

Our final worm's-eye look at a physical structure
will be a look at packets.

By packet, we mean: what's the format of a message that
the client sends over the tcp/ip line to the server --
and what does the server send back?

Here we're not displaying a dump. If you want to see
hexadecimal dumps of the contents of packets, internals.texi
is full of them. We're just going to note that a typical
message will have a header, an identifier, and a length,
followed by the message contents.

Admittedly this isn't following a standard like
ISO's RDA or IBM's DRDA, but it's documented so
if you want to go out and write your own type 4
JDBC driver, you've got what you need here. But
a word of advice on that last point: it's
already been done. Mark Matthews wrote it
originally, it's all in "MySQL Connector/J".

@strong{The Last Subheader}

Okay, let's back up and restate. In this walkthrough,
we've told you four main things.

One: How to get the MySQL source.

Two: What's in each directory in the source.

Three: The main sequence, as one walks through the server code.

Four: What physical structures look like.

We worked hard to make a description of the MySQL source
that is simple, without distorting. If you were able to
follow all that we've said, then that's wonderful,
congratulations. If you ended up thinking that MySQL
is really simple, well that's not what we wanted to
convey, but we think you'll be disabused of that notion
when you have a look at the code yourself.

@node coding guidelines, optimizer, guided tour, Top
@chapter Coding Guidelines

The purpose of this chapter is to establish a set of guidelines that
will help you, the developer, to follow the established MySQL coding
styles and standards when writing code. Consistent style is important as
it makes it easier to maintain our code and allows you to find specific
routines much more quickly. 

The standards contained within this chapter apply to the mysql server,
and do not necessarily apply to other projects such as JDBC, ODBC,
Administrator, etc.

@strong{Indentation and Spacing}

The following rules apply to indentation and spacing of code within a
source file:

@itemize @bullet
@item
Do not use tab characters (\t), use spaces. All indentation should be
two spaces.  You should be able to configure your editor to use spaces
instead of tabs. (See the editor configuration tips at the end of this
chapter for instruction for vim and emacs).

@item
Line breaks should occur on column 80, with two line breaks between each
function in a file.

@item
Do not use carriage return (\r\n) characters in a source document; this
can cause problems for other users and for builds.

@item
Matching @samp{@{@}} (left and right braces) should be in the same
column. With the exception of a @code{switch} statement, all braces
should appear on their own line. The only exception to having braces on
separate lines is if there is nothing between the braces.

Examples:
@example
if (is_valid(x))
@{
  x= 2;
@}

switch (my_arg) @{

for (...)
@{@}
@end example


@item
Put a space after evaluation keywords @code{if}, @code{for} and
@code{while}.

@item
When a function has multiple arguments, place a space after each comma
(@samp{,}) in the argument set.

@example
return_value= my_function(arg1, arg2, arg3);
@end example

@item
When performing assignments, place a space after the equals sign but
make sure there is no space between the variable and the equals sign.
This allows for easier searching through the code for variable
assignments; It is easier to search for an assignment to @samp{x} when
you can search for @code{x= }. 

When you make multiple assignments indent the right-hand values to make
them easier to read:

@example
int x=          27;
int new_var=    18;
@end example
 
@item
Operators should have spaces on both sides, including the @samp{==}
operator. 

@example
x + y;
if (x == y);
@end example

@item
Do not do multiple tasks on the same line, whether you are
declaring variables or performing commands.

@example
int x= 11;
int y= 12;
int z= 0;

z= x;
y += x;
@end example

@item
Do not put a space between a pointer asterisk and its variable.

@example
int *var;
@end example

@item
Use blank lines to separate functions and blocks of code. Successive
functions should have two newlines between them.
@end itemize

@strong{Naming Conventions}
@itemize @bullet

@item
Use @code{my_var} as opposed to @code{myVar} or @code{MyVar} (underscore
rather than capitalization is to be used for separating words in
identifiers). 

@item
Avoid capitalization except for class names; class names should begin
with a capital letter.

@item
Don't have function names, structure elements, or variables that begin
or end with @samp{_}, these make your code less readable. 

@item
Use long function and variable names in English. This will make your
code easier to read for all developers. 

@item
Structure types are @code{typedef}'ed to an all-upper-case identifier.

@item
All @code{#define} declarations should be in upper case.

@example
#define MY_CONSTANT 15
@end example

@item 
Enumeration names should begin with @code{enum_}.
@end itemize

@strong{Commenting Code}
@itemize @bullet
@item
Comment your code when you do something that someone else may think is
not ``trivial''.

@item
When writing multi-line comments, the beginning and ending markers
should be on their own lines.

In addition, do not use asterixes on left of the comment.

@example
/*
  This is how
  a multi-line comment
  should look.
*/
@end example

@item
@code{//} comments are allowed at end of lines. In other cases, use
@code{/* */} comments. In C files or headers used by C files, one should not use 
@code{//} comments.

@item
Function comments are important! When commenting a function, note the IN
parameters (the word IN is implicit).

Every function should have a description unless the function is very
short and its purpose is obvious.

@item
All comments should be in English.

@item
Place a blank line between a function and its description.

@example
/*
  This is a function.
  Use it wisely.
*/

int my_function()
@end example
@end itemize

@strong{General Development Guidelines}
@itemize @bullet
@item
We use @uref{http://www.bitkeeper.com/, BitKeeper} for source
management.  Bitkeeper can be downloaded from
@uref{http://www.bitmover.com/cgi-bin/download.cgi}

@item
You should use the MySQL 5.0 source for all new developments. The public
5.0 development branch can be downloaded with
@code{shell> bk clone bk://mysql.bkbits.net/mysql-5.0 mysql-5.0}

@item
If you have any questions about the MySQL source, you can post them to
@email{internals@@lists.mysql.com} and we will answer them.

@item
Before making big design decisions, please begin by posting a summary of
what you want to do, why you want to do it, and how you plan to do it.
This way we can easily provide you with feedback and also discuss it
thoroughly. 
Perhaps another developer can assist you.

@item
Try to write code in a lot of black boxes that can be reused or at
least use a clean, easy to change interface.

@item
Reuse code;  There are already many algorithms in MySQL that can be
reused for list handling, queues, dynamic and hashed arrays, sorting,
etc. 

@item
Use the @code{my_*} functions like @code{my_read()}/@code{my_write()}/
@code{my_malloc()} that you can find in the @code{mysys} library, instead
of the direct system calls;  This will make your code easier to debug and 
more portable.

@item
Use @code{libstring} functions (in the @file{strings} directory)
instead of standard @code{libc} string functions whenever possible.
For example, use @code{bfill()} and @code{bzero()} instead of
@code{memset()}.

@item
Try to always write optimized code, so that you don't have to
go back and rewrite it a couple of months later.  It's better to
spend 3 times as much time designing and writing an optimal function than
having to do it all over again later on.

@item
Avoid CPU wasteful code, even when its use is trivial, to avoid
developing sloppy coding habits.

@item
If you can do something in fewer lines, please do so (as long as the
code will not be slower or much harder to read).

@item
Do not check the same pointer for @code{NULL} more than once.

@item
Never use a macro when an (inline) function would work as well.

@item
Do not make a function inline if you don't have a very good reason for
it.  In many cases, the extra code that is generated is more likely to
slow down the resulting code than give a speed increase because the
bigger code will cause more data fetches and instruction misses in the
processor cache.

The cases where you should use inline functions are when the function
satisfies most of the following requirements:

@itemize @bullet
@item
Function is very short (just a few lines)
@item
Function is used in a speed critical place and is executed over and over
again.
@item
Function is handling the normal case, not some extra functionallity that most
users will not use.
@item
The function is only called in very few cases.
(This restriction must be followed unless the resulting assembler code of
the inlined function < 16 assembler instructions).
@item
If the compiler can do additional optimizations by inlining it and the
resulting function will be only a fraction of the original one.
@end itemize

@item
Think assembly - make it easier for the compiler to optimize your code.

@item
Avoid using @code{malloc()}, which is very slow.  For memory allocations
that only need to live for the lifetime of one thread, use
@code{sql_alloc()} instead.

@item
Functions return zero on success, and non-zero on error, so you can do:

@example
if(a() || b() || c()) @{ error("something went wrong"); @}
@end example

@item
Using @code{goto} is okay if not abused.

@item
Avoid default variable initializations. Use @code{LINT_INIT()} if the
compiler complains after making sure that there is really no way
the variable can be used uninitialized.

@item
Use @code{TRUE} and @code{FALSE} instead of @code{true} and @code{false}
in C++ code.  This makes the code more readable and makes it easier to
use it later in a C library, if needed.

@item
@code{bool} exists only in C++. In C, you have to use
@code{my_bool} (which is @code{char}); it has different cast rules than
@code{bool}:
@example
int c= 256*2;
bool a= c; /* a gets 'true' */
my_bool b= c; /* b gets zero, i.e. 'false': BAD */
my_bool b= test(c); /* b gets 'true': GOOD */
@end example
In C++, use @code{bool}, unless the variable is used in C code
(for example the variable is passed to a C function).

@item
Do not instantiate a class if you do not have to.

@item
Use pointers rather than array indexing when operating on strings.

@item
Never pass parameters with the @code{&variable_name} construct in C++.
Alway use a pointer instead!

The reason is that the above makes it much harder for the one reading
the caller function code to know what is happening and what kind of
code the compiler is generating for the call.

@item
Format function arguments in the following way: 

@example
Return_value_type *Class_name::method_name(const char *arg1,
                                           size_t arg2, Type *arg3)
@end example

@example
return_value= function_name(argument1, argument2, long_argument3,
                            argument4,
                            function_name2(long_argument5,
                                           long_argument6));
@end example

If function or argument names are too long:

@example
return_value=
  long_long_function_name(long_long_argument1, long_long_argument2,
                          long_long_long_argument3,
                          long_long_argument4,
                          long_function_name2(long_long_argument5,
                                              long_long_argument6));
@end example


@example
Long_long_return_value_type *
Long_long_class_name::
long_long_method_name(const char *long_long_arg1, size_t long_long_arg2,
                      Long_long_type *arg3)
@end example

(you can but don't have to split @code{Class_name::method_name} into two lines)

In such cases think also about renaming arguments.

@item
Format constructors in the following way: 

@example
Item::Item(int a_arg, int b_arg, int c_arg)
  :a(a_arg), b(b_arg), c(c_arg)
@{@}
@end example

But keep lines short to make them more readable:

@example
Item::Item(int longer_arg, int more_longer_arg)
  :longer(longer_arg),
  more_longer(more_longer_arg)
@{@}
@end example

If constructor can fit into one line:

@example
Item::Item(int a_arg) :a(a_arg) @{@}
@end example

@item 
You can align variable declarations and assignments, like this:

@example
Type      value;
int       var2;
ulonglong var3;
@end example

Always align assignments of one structure to another, like this:

@example
foo->member=      bar->member;
foo->name=        bar->name;
foo->name_length= bar->name_length;
@end example

When you write the assignments that way, you typically don't read the
structures names more than once.

@end itemize

Suggested mode in @code{emacs}:

@example
(require 'font-lock)
(require 'cc-mode)
(setq global-font-lock-mode t) ;;colors in all buffers that support it
(setq font-lock-maximum-decoration t) ;;maximum color
(c-add-style "MY"
 '("K&R"
   '("MY"
     (c-basic-offset . 2)
     (c-comment-only-line-offset . 0)
     (c-offsets-alist . ((statement-block-intro . +)
                         (knr-argdecl-intro . 0)
                         (substatement-open . 0)
                         (label . -)
                         (statement-cont . +)
                         (arglist-intro . c-lineup-arglist-intro-after-paren)
                         (arglist-close . c-lineup-arglist)
                         ))
     )))

(setq c-mode-common-hook '(lambda ()
                            (c-set-style "MY")
                            (setq tab-width 8)
                            (setq indent-tabs-mode t)
                            (setq comment-column 48)))

(c-set-style "MY")
(setq c-default-style "MY")
@end example

Basic @code{vim} setup:

@example
set tabstop=8
set shiftwidth=2
set backspace=2
set softtabstop
set smartindent
set cindent
set cinoptions=g0:0t0c2C1(0f0l1
"set expandtab "uncomment if you don't want to use tabstops
@end example

Another @code{vim} setup:
@example
set tabstop=8
set shiftwidth=2
set bs=2
set et
set sts=2
set tw=78
set formatoptions=cqroa1
set cinoptions=g0:0t0c2C1(0f0l1
set cindent

function InsertShiftTabWrapper()
  let num_spaces = 48 - virtcol('.')
  let line = ' '
  while (num_spaces > 0)
    let line = line . ' '
    let num_spaces = num_spaces - 1
  endwhile
  return line
endfunction
" jump to 48th column by Shift-Tab - to place a comment there
inoremap <S-tab> <c-r>=InsertShiftTabWrapper()<cr>
" highlight trailing spaces as errors
let c_space_errors=1
@end example

@strong{DBUG Tags}

Here are some of the DBUG tags we now use:

@table @code
@item enter
Arguments to the function.

@item exit
Results from the function.

@item info
Something that may be interesting.

@item warning
When something doesn't go the usual route or may be wrong.

@item error
When something went wrong.

@item loop
Write in a loop, that is probably only useful when debugging
the loop.  These should normally be deleted when you are
satisfied with the code and it has been in real use for a while.
@end table

Some tags specific to @code{mysqld}, because we want to watch these carefully:

@table @code
@item trans
Starting/stopping transactions.

@item quit
@code{info} when @code{mysqld} is preparing to die.

@item query
Print query.
@end table


@node optimizer, Algorithms, coding guidelines, Top
@chapter The Optimizer

@strong{Definitions}

This description uses a narrow definition:
The OPTIMISER is the set of routines which decide what
execution path the DBMS should take for queries.

MySQL changes these routines frequently, so you
should compare what is said here with what's in the
current source code. To make that easy, this description
includes notes referring to the relevant routine,
for example "See: @file{/sql/select_cc}, @code{optimize_cond()}".

When one query is changed into another query which
delivers the same result, that is a TRANSFORMATION. For
example, the DBMS could change
@example
SELECT ... WHERE 5 = a
@end example

to

@example
SELECT ...WHERE a = 5
@end example

Most transformations are less obvious. Some
transformations result in faster execution.

@strong{The Code}

Here is a diagram showing the code structure of
@code{handle_select()} in @file{/sql/sql_select.cc}, the server
code that handles a query:

@example
handle_select()
   mysql_select()
     JOIN::prepare()
       setup_fields()
     JOIN::optimize()            /* optimizer is from here ... */
       optimize_cond()
       opt_sum_query()
       make_join_statistics()
         get_quick_record_count()
         choose_plan()
           /* Find the best way to access tables */
           /* as specified by the user.          */
           optimize_straight_join()
             best_access_path()
           /* Find a (sub-)optimal plan among all or subset */
           /* of all possible query plans where the user    */
           /* controlls the exhaustiveness of the search.   */
           greedy_search()
             best_extension_by_limited_search()
               best_access_path()
           /* Perform an exhaustive search for an optimal plan */
           find_best()
       make_join_select()        /* ... to here */
     JOIN::exec()
@end example

The indentation in the diagram shows what calls what.
Thus you can see that @code{handle_select()} calls @code{mysql_select()}
which calls @code{JOIN::prepare()} which calls @code{setup_fields()},
and so on. The first part of @code{mysql_select()} is @code{JOIN::prepare()}
which is for context analysis, metadata setup, and some
subquery transformations. The optimizer is @code{JOIN::optimize()}
and all its subordinate routines. When the optimizer finishes,
@code{JOIN::exec()} takes over and does the job that @code{JOIN::optimize()}
decides upon.

Although the word ``JOIN'' appears, these optimizer routines
are for all query types.

The @code{optimize_cond()} and @code{opt_sum_query()} routines do
transformations. The @code{make_join_statistics()}
routine puts together all the information it can find about
indexes that might be useful for accessing the query's tables.

@strong{Constant Propagation}

A transformation takes place for expressions like this:

@example
WHERE column1 = column2 AND column2 = 'x'
@end example

For such expressions, since it is known that
``if A=B and B=C then A=C'' (the Transitivity Law), the
transformed condition becomes:

@example
WHERE column1='x' AND column2='x'
@end example

This transformation occurs for @code{column1 <operator> column2}
conditions if and only if @code{<operator>} is one of these operators:

@example
=, <, >, <=, >=, <>, <=>, LIKE
@end example

That is, transitive transformations don't apply for
@code{BETWEEN}. Probably they should not apply for @code{LIKE} either,
but that's a story for another day.

Constant propagation happens in a loop, so the output
from one ``propagation step'' can be input for the next
step.

See: @file{/sql/sql_select.cc}, @code{change_cond_ref_to_const()}.
Or see: @file{/sql/sql_select.cc}, @code{propagate_cond_constants()}.

@strong{Dead Code Elimination}

A transformation takes place for always-true conditions:

@example
WHERE 0=0 AND column1='y'
@end example

The first condition is always true, so it is removed, leaving:

@example
WHERE column1='y'
@end example

See: @file{/sql/sql_select.cc}, @code{remove_eq_conds()}.

A transformation takes place for always-false conditions:

@example
WHERE (0 = 1 AND s1 = 5) OR s1 = 7
@end example

The parenthesized part is always false, so it is removed,
reducing the expression above to:

@example
WHERE s1 = 7
@end example

Sometimes the optimizer might eliminate the whole @code{WHERE}
clause:

@example
WHERE (0 = 1 AND s1 = 5)
@end example

The @code{EXPLAIN} statement will show the words @code{Impossible WHERE}.
Informally, we at MySQL say: ``The @code{WHERE} has been optimized
away.''

If a column cannot be @code{NULL}, the optimizer removes any
non-relevant @code{IS NULL} conditions. Thus,

@example
WHERE not_null_column IS NULL
@end example

is an always-false situation, and

@example
WHERE not_null_column IS NOT NULL
@end example

is an always-true situation --- so such columns are also
eliminated from the conditional expression. This can be
tricky. For example, in an @code{OUTER JOIN}, a column which is
defined as @code{NOT NULL} might still contain a @code{NULL}. The optimizer
leaves @code{IS NULL} conditions alone in such exceptional
situations.

The optimizer will not detect all possible @code{impossible
WHERE} situations --- there are too many. For example:

@example
CREATE TABLE Table1 (column1 CHAR(1));
...
SELECT * FROM Table1 WHERE column1 = 'Canada';
@end example

The optimizer will not eliminate the condition in the
query, even though the @code{CREATE TABLE} definition makes it
an impossible condition.

@strong{Constant Folding}

A transformation takes place for this expression:

@example
WHERE column1 = 1 + 2
@end example

which becomes:

@example
WHERE column1 = 3
@end example

Before you say ``but I never would write 1 + 2 in the
first place'' --- remember what was said earlier about
constant propagation. It is quite
easy for the optimizer to put such expressions
together. This process simplifies the result.

@strong{Constants and Constant Tables}

A MySQL ``constant''
is something more than a mere literal in the query. It can
also be the contents of a ``constant table,'' which is defined
as follows:

@enumerate

@item A table with zero rows, or with only one row

@item A table expression that is restricted with a
@code{WHERE} condition, containing expressions of the form
@code{column = constant}, for all the columns of the table's
@code{PRIMARY KEY}, or for all the columns of any of the table's
@code{UNIQUE} keys (provided that the @code{UNIQUE} columns are also
defined as @code{NOT NULL}).

@end enumerate

For example, if the table
definition for @code{Table0} contains

@example
... PRIMARY KEY (column1,column2)
@end example

then this expression

@example
FROM Table0 ... WHERE column1=5 AND column2=7 ...
@end example

returns a constant table. More simply, if the
table definition for @code{Table1} contains

@example
... unique_not_null_column INT NOT NULL UNIQUE
@end example

then this expression

@example
FROM Table1 ... WHERE unique_not_null_column=5
@end example

returns a constant table.

These rules mean that a constant table has at most one
row value. MySQL will evaluate a constant table in advance,
to find out what that value is. Then MySQL will ``plug''
that value into the query. Here's an example:

@example
SELECT Table1.unique_not_null_column, Table2.any_column
    FROM Table1, Table2
    WHERE Table1.unique_not_null_column = Table2.any_column
    AND Table1.unique_not_null_column = 5;
@end example

When evaluating this query, MySQL first finds that table
@code{Table1} --- after restriction with @code{Table1.unique_not_null_column}
--- is a constant table according to the second definition above.
So it retrieves that value.

If the retrieval fails (there is no row in the table with
@code{unique_not_null_column} = 5), then the constant table has zero
rows and you will see this message if you run @code{EXPLAIN} for
the statement:

@example
Impossible WHERE noticed after reading const tables
@end example

Alternatively, if the retrieval succeeds (there is exactly
one row in the table with @code{unique_not_null_column} = 5), then
the constant table has one row and MySQL transforms the
query to this:

@example
SELECT 5, Table2.any_column
    FROM Table1, Table2
    WHERE 5 = Table2.any_column
    AND 5 = 5;
@end example

Actually this is a grand-combination example. The optimizer
does some of the transformation because of constant
propagation, which we described earlier. By the way, we
described constant propagation first because it happens
happens @emph{before} MySQL figures out what the constant tables are.
The sequence of optimizer steps sometimes makes a difference.

Although many queries have no constant-table references, it
should be kept in mind that whenever the word ``constant'' is
mentioned hereafter, it refers either to a literal or to the
contents of a constant table.

See: @file{/sql/sql_select.cc}, @code{make_join_statistics()}.

@strong{Join Type}

When evaluating a conditional expression, MySQL decides what
``join type'' the expression has. (Again: despite the word ``join,''
this applies for all conditional expressions, not just join
expressions. A term like ``access type'' would be clearer.)
These are the documented join types, in order from best to worst:

@example
system          ... a system table which is a constant table
const           ... a constant table
eq_ref          ... unique/primary index with '=' for joining
ref             ... index with '='
ref_or_null     ... index with '=', possibly NULL
range           ... index with BETWEEN, IN, >=, LIKE, etc.
index           ... sequential scan of index
ALL             ... sequential scan of table
@end example

See: @file{/sql/sql_select.h}, @code{enum join_type@{@}}. Notice that there are
a few other (undocumented) join types too, for subqueries.

The optimizer can use the join type to pick a ``driver expression.''
For example, consider this query:

@example
SELECT *
FROM Table1
WHERE indexed_column = 5 AND unindexed_column = 6
@end example

Since @code{indexed_column} has a better join type, it is more likely
to be the driver. You'll see various exceptions as this
description proceeds, but this is a simple first rule.

What is significant about a driver? Consider that there are
two execution paths for the query:

(The Bad Execution Path) Read every row in the table. (This is
called a ``sequential scan of @code{Table1}'' or just ``table scan.'')
For each row, examine the values in @code{indexed_column} and in
@code{unindexed_column}, to see if they meet the conditions.

(The Good Execution Plan) Via the index, look up the rows which
have @code{indexed_column} = 5. (This is called an ``indexed search.'')
For each row, examine the value in unindexed_column to see if
it meets the condition.

An indexed search generally involves fewer accesses than
a sequential scan, and far fewer accesses if the table is
large but the index is UNIQUE. That is why it is better to
access with ``The Good Execution Plan,'' and that is why it is
often good to choose indexed_column as the driver.

@strong{The 'range' Join Type}

Some conditions can work with indexes, but over a (possibly
wide) range of keys. These are known as ``range'' conditions,
and are most often encountered with expressions involving
these operators: @code{>, >=, <, <=,  IN, LIKE, BETWEEN}

To the optimizer, this expression:

@example
column1 IN (1,2,3)
@end example

is the same as this one:

@example
column1 = 1 OR column1 = 2 OR column1 = 3
@end example

and MySQL treats them the same --- there is no need to
change IN to OR for a query, or vice versa.

The optimizer will use an index (range search) for

@example
column1 LIKE 'x%'
@end example

but not for

@example
column1 LIKE '%x'
@end example

That is, there is no range search if the first character
in the pattern is a wildcard.

To the optimizer,

@example
column1 BETWEEN 5 AND 7
@end example

is the same as this expression

@example
column1 >= 5 AND column1 <= 7
@end example

and again, MySQL treats both expressions the same.

The optimizer may change a @code{Range} to an @code{ALL}
join type if a condition would examine too many
index keys. Such a change is particularly likely
for @code{<} and @code{>} conditions and multiple-level
secondary indexes. See: (for @code{MyISAM} indexes)
@file{/myisam/mi_range.c}, @code{mi_records_in_range()}.

@strong{The @code{index} Join Type}

Consider this query:

@example
SELECT column1 FROM Table1;
@end example

If @code{column1} is indexed, then the optimizer may
choose to retrieve the values from the index
rather than from the table. An index which is
used this way is called a ``covering index''
in most texts. MySQL just uses the word ``index''
in @code{EXPLAIN} descriptions.

For this query:

@example
SELECT column1, column2 FROM Table1;
@end example

the optimizer will use ``join type = @code{index}'' only
if the index has this definition:

@example
CREATE INDEX ... ON Table1 (column1, column2);
@end example

In other words, all columns in the select list
must be in the index. (The order of the columns
in the index does not matter.) Thus it might make
sense to define a multiple-column index strictly for
use as a covering index, regardless of search
considerations.

@strong{Transposition}

MySQL supports transpositions (reversing the order of
operands around a relational operator) for simple
expressions only. In other words:

@example
WHERE - 5 = column1
@end example

becomes:

@example
WHERE column1 = -5
@end example

However, MySQL does not support transpositions where
arithmetic exists. Thus:

@example
WHERE 5 = -column1
@end example

is not treated the same as:

@example
WHERE column1 = -5
@end example

Transpositions to expressions of the form @code{<column>=<constant>}
are ideal for index lookups. If an expression of this
form refers to an indexed column, then MySQL always uses
the index, regardless of the table size. (Exception:
if the table has only zero rows or only one row, it is
a constant table and receives special treatment. See the
earlier section "Constants and Constant Tables".)

@strong{AND}

The ANDed search has the form @code{<condition> AND <condition>}, as in:

@example
WHERE column1 = 'x' AND column2 = 'y'
@end example

Here the optimizer's decision is:

@enumerate
@item
If (neither condition is indexed) use sequential scan.

@item
Otherwise, if (one condition has better join type) then
pick a driver based on join type
(see the earlier section "Join Type").

@item
Otherwise, since (both conditions are indexed and have equal join type)
pick a driver based on the first index that was created.
@end enumerate

Here's an example:

@example
CREATE TABLE Table1 (s1 INT, s2 INT);
CREATE INDEX Index1 ON Table1 (s2);
CREATE INDEX Index2 ON Table1 (s1);
...
SELECT * FROM Table1 WHERE s1 = 5 AND s2 = 5;
@end example

When choosing a strategy to solve this query, the optimizer
picks @code{s2 = 5} as the driver because the index for @code{s2} was
created first. Regard this as an accidental
effect rather than a rule --- it could change at any moment.

@strong{OR}

The ORed search has the form "<condition> OR <condition>" as in:

@example
WHERE column1 = 'x' OR column2 = 'y'
@end example

Here the optimizer's decision is:

@example
Use a sequential scan.
@end example

In theory there is another choice if both column1 and
column2 are indexed:

@example
index search for the first condition,
index search for the second condition,
merge the two result sets
@end example

@c Isn't that code what is now described in the Index Merge section?

MySQL never does that. But MySQL will do that in future,
the code for doing so already exists.

The above warning does not apply if the same column is used
in both conditions. For example:

@example
WHERE column1 = 'x' OR column1 = 'y'
@end example

In such a case, the search is indexed because the expression
is a range search. This subject will be revisited during the
discussion of the @code{IN} predicate.

@strong{AND plus OR}

Consider this search expression:

@example
WHERE column1 = 5 AND (column2 = 5 OR column3 = 5)
@end example

If @code{column1} is indexed, then the optimizer will choose to use
the index. In other words, the ``sequential scan if @code{OR}'' rule
does not apply if the @code{OR} is subordinate to an @code{AND}.

@strong{UNION}

All @code{SELECT} statements within a @code{UNION} are optimized separately.
Therefore, for this query:

@example
SELECT * FROM Table1 WHERE column1 = 'x'
UNION ALL
SELECT * FROM TABLE1 WHERE column2 = 'y'
@end example

if both @code{column1} and @code{column2} are indexed, then each @code{SELECT}
is done using an indexed search, and the result sets are
merged. Notice that this query might produce the same results
as the query used in the @code{OR} example, which uses a sequential
scan.

@strong{NOT, <>}

It is a logical rule that

@example
column1 <> 5
@end example

is the same as

@example
column1 < 5 OR column1 > 5
@end example

However, MySQL does not transform in this circumstance.
If you think that a range search would be better, then
you should do your own transforming in such cases.

It is also a logical rule that

@example
WHERE NOT (column1 != 5)
@end example

is the same as

@example
WHERE column1 = 5
@end example

However, MySQL does not transform in this circumstance
either.

We expect to add optimizations soon for both the above
cases.

@strong{ORDER BY}

In general, the optimizer will skip the sort procedure
for the @code{ORDER BY} clause if it sees that the rows will
be in order anyway. But let's examine some exceptional
situations.

For the query:

@example
SELECT column1 FROM Table1 ORDER BY 'x';
@end example

the optimizer will throw out the @code{ORDER BY} clause. This
is another example of dead code elimination.

For the query:

@example
SELECT column1 FROM Table1 ORDER BY column1;
@end example

the optimizer will use an index on @code{column1}, if it exists.

For the query:

@example
SELECT column1 FROM Table1 ORDER BY column1+1;
@end example

the optimizer will use an index on @code{column1}, if it exists.
But don't let that fool you! The index is only for finding
the values. (It's cheaper to do a sequential scan of the
index than a sequential scan of the table, that's why @code{index}
is a better join type than @code{ALL} --- see "The 'index' Join Type"
section, earlier.) There will still be a full sort of the
results.

For the query:

@example
SELECT * FROM Table1
WHERE column1 > 'x' AND column2 > 'x'
ORDER BY column2;
@end example

if both @code{column1} and @code{column2} are indexed, the optimizer will
choose an index on ... @code{column1}. The fact that ordering takes
place by @code{column2} values does not affect the choice of driver
in this case.

See: @file{/sql/sql_select.cc}, @code{test_if_order_by_key()},
and @file{/sql/sql_select.cc}, @code{test_if_skip_sort_order()}.

There is a description of the internal sort procedure in
the MySQL Reference Manual, in section 5.2.8 ``How MySQL
optimizes @code{ORDER BY}.'' We will not repeat it here, but urge
you to read it because it includes a description of how
the buffering and the quicksort operate.

See: @file{/sql/sql_select.cc}, @code{create_sort_index()}.

@strong{GROUP BY}

These are the main optimizations that take place for
@code{GROUP BY} and related items (@code{HAVING}, @code{COUNT()}, @code{MAX()},
@code{MIN()}, @code{SUM()}, @code{AVG()}, @code{DISTINCT()}).
@itemize @bullet

@item
@code{GROUP BY} will use an index, if one exists.

@item
@code{GROUP BY} will use sorting, if there is no index.
The optimizer may choose to use a hash table.

@item
For the case @code{GROUP BY x ORDER BY x}, the optimizer
will realize that the @code{ORDER BY} is unnecessary, because
the @code{GROUP BY} comes out in order by @code{x}.

@item
The optimizer contains code for shifting certain
@code{HAVING} conditions to the @code{WHERE} clause; however, this
code is not operative at time of writing.
See: @file{/sql/sql_select.cc}, @code{JOIN::optimize()}, after
@code{#ifdef HAVE_REF_TO_FIELDS}.

@item
If the table handler has a quick row-count available,
then the query

@example
SELECT COUNT(*) FROM Table1;
@end example

gets the count without going through all the rows.
This is true for @code{MyISAM} tables, but not for @code{InnoDB}
tables. Note that the query

@example
SELECT COUNT(column1) FROM Table1;
@end example

is not subject to the same optimization, unless
@code{column1} is defined as @code{NOT NULL}.

@item
New optimizations exist for @code{MAX()} and @code{MIN()}. For example,
consider the query

@example
SELECT MAX(column1)
  FROM Table1
  WHERE column1 < 'a';
@end example

If @code{column1} is indexed, then it's easy to find the
highest value by looking for @code{'a'} in the index and
going back to the key before that.

@item
The optimizer transforms queries of the form

@example
SELECT DISTINCT column1 FROM Table1;
@end example

to

@example
SELECT column1 FROM Table1 GROUP BY column1;
@end example

if and only if both of these conditions are true:

@itemize @bullet
@item
The @code{GROUP BY} can be done with an index.
(This implies that there is only one table in the @code{FROM}
clause, and no @code{WHERE} clause.)

@item
There is no @code{LIMIT} clause.

@end itemize

Because @code{DISTINCT} is not always transformed to @code{GROUP BY},
do not expect that queries with @code{DISTINCT} will always
cause ordered result sets. (You can, however, rely on
that rule with @code{GROUP BY}, unless the query includes
@code{ORDER BY NULL}.)

@end itemize

See: @file{/sql/sql_select.cc}, @code{opt_sum_query()},
and @file{/sql/sql_select.cc}, @code{remove_duplicates()}.

@strong{JOIN}

Bad join choices can cause more damage than bad choices in single-table
searches, so MySQL developers have spent proportionally more time making
sure that the tables in a query are joined in an optimal order and that
optimal access methods (often called ``access paths'') are chosen to
retrieve table data. A combination of a fixed order in which tables are
joined and the corresponding table access methods for each table is called
``query execution plan'' (QEP). The goal of the query optimizer is to find
an optimal QEP among all possible such plans. There are several general
ideas behind join optimization.

Each plan (or part of plan) is assigned a ``cost.'' The cost of a plan
reflects roughly the resources needed to compute a query according to the
plan, where the main factor is the number of rows that will be accessed
while computing a query. Once we have a way to assign costs to different
QEPs we have a way to compare them. Thus, the goal of the optimizer is to
find a QEP with minimal cost among all possible plans.

In MySQL, the search for an optimal QEP is performed in a bottom-up
manner. The optimizer first considers all plans for one table, then
all plans for two tables, and so on, until it builds a complete optimal
QEP. Query plans that consist of only some of the tables (and predicates)
in a query are called ``partial plans.'' The optimizer relies on the fact
that the more tables are added to a partial plan, the greater its cost. This
allows the optimizer to expand with more tables only the partial plans
with lower cost than the current best complete plan.

The key routine that performs the search for an optimal QEP is
@file{sql/sql_select.cc}, @code{find_best()}. It performs an exhaustive
search of all possible plans and thus guarantees it will find an optimal
one.

Below we represent @code{find_best()} in an extremely free translation to
pseudocode. It is recursive, so some input variables are labeled ``so far''
to indicate that they come from a previous iteration.

@example
remaining_tables = @{t1, ..., tn@}; /* all tables referenced in a query */

procedure find_best(
   partial_plan in,      /* in, partial plan of tables-joined-so-far */
   partial_plan_cost,    /* in, cost of partial_plan */
   remaining_tables,     /* in, set of tables not referenced in partial_plan */
   best_plan_so_far,     /* in/out, best plan found so far */
   best_plan_so_far_cost)/* in/out, cost of best_plan_so_far */
@{
   for each table T from remaining_tables
   @{
     /* Calculate the cost of using table T. Factors that the
        optimizer takes into account may include:
          Many rows in table (bad)
          Many key parts in common with tables so far (very good)
          Restriction mentioned in the WHERE clause (good)
          Long key (good)
          Unique or primary key (good)
          Full-text key (bad)
        Other factors that may at some time be worth considering:
          Many columns in key
          Short average/maximum key length
          Small table file
          Few levels in index
          All ORDER BY / GROUP columns come from this table */
     cost = complex-series-of-calculations;
     /* Add the cost to the cost so far. */
     partial_plan_cost+= cost;

     if (partial_plan_cost >= best_plan_so_far_cost)
       /* partial_plan_cost already too great, stop search */
       continue;

     partial_plan= expand partial_plan by best_access_method;
     remaining_tables= remaining_tables - table T;
     if (remaining_tables is not an empty set)
     @{
       find_best(partial_plan, partial_plan_cost,
                 remaining_tables,
                 best_plan_so_far, best_plan_so_far_cost);
     @}
     else
     @{
       best_plan_so_far_cost= partial_plan_cost;
       best_plan_so_far= partial_plan;
     @}
   @}
@}
@end example

Here the optimizer applies a ``depth-first search algorithm.'' It tries
estimates for every table in the @code{FROM} clause. It will stop a search
early if the estimate becomes worse than the best estimate so far. The order
of scanning will depend on the order that the tables appear in the
@code{FROM} clause.

See: @file{/sql/table.h}, @code{struct st_table}.

@code{ANALYZE TABLE} may affect some of the factors that the
optimizer considers.

See also: @file{/sql/sql_sqlect.cc}, @code{make_join_statistics()}.

The straightforward use of @code{find_best()} and @code{greedy_search()}
will not apply for @code{LEFT JOIN} or @code{RIGHT JOIN}. For example,
starting with MySQL 4.0.14, the optimizer may change a left join to a
straight join and swap the table order in some cases. See also ``5.2.7
How MySQL Optimises @code{LEFT JOIN} and @code{RIGHT JOIN}'' in the MySQL
Reference Manual.


@menu
* Index Merge Join Type::       The @code{Index Merge} Join Type
@end menu

@node Index Merge Join Type,  , optimizer, optimizer
@section The @code{Index Merge} Join Type

@menu
* Index Merge overview::        Overview
* Index Merge Optimizer::       Index Merge Optimizer
* Index Merge Row Retrieval Algorithm::  Row Retrieval Algorithm
@end menu

@node Index Merge overview, Index Merge Optimizer, Index Merge Join Type, Index Merge Join Type
@subsection Overview

@code{Index Merge} is used when table condition can be converted to form:

@example
cond_1 OR cond_2 ... OR cond_N
@end example

The conditions for conversion are that
each @code{cond_i} can be used for a range scan,
and no pair (@code{cond_i}, @code{cond_j}) uses the same index.
(If @code{cond_i} and @code{cond_j} use the same index, then
@code{cond_i OR cond_j} can be combined into a single range scan
and no merging is necessary.)

For example, @code{Index Merge} can be used for the following queries:

@example
SELECT * FROM t WHERE key1=c1 OR key2<c2 OR key3 IN (c3,c4);

SELECT * FROM t WHERE (key1=c1 OR key2<c2) AND nonkey=c3;
@end example

@code{Index Merge} is implemented as a ``container'' for range key scans
constructed from @code{cond_i} conditions. When doing @code{Index Merge},
MySQL retrieves rows for each of the keyscans and then runs them through
a duplicate elimination procedure. 
Currently the @code{Unique} class is used for duplicate elimination.


@node Index Merge Optimizer, Index Merge Row Retrieval Algorithm, Index Merge overview, Index Merge Join Type
@subsection Index Merge Optimizer

@menu
* Index Merge Range Optimizer::  Range Optimizer
* Index Merge Optimizer2::      Index Merge Optimizer
@end menu

@node Index Merge Range Optimizer, Index Merge Optimizer2, Index Merge Optimizer, Index Merge Optimizer
@subsubsection Range Optimizer

@c pull this section out to range access method section

For @code{Range}-type queries, the MySQL optimizer builds a @code{SEL_TREE}
object which represents a condition in this form:

@example
range_cond = (cond_key_1 AND cond_key_2 AND ... AND cond_key_N)
@end example

Each of @code{cond_key_i} is a condition that refers to components of one
key. MySQL creates a @code{cond_key_i} condition for each of the usable keys.
Then the cheapest condition @code{cond_key_i} is used for doing range scan.

A single @code{cond_key_i} condition is represented by a pointer-linked
network of @code{SEL_ARG} objects. Each @code{SEL_ARG} object refers to
particular part of the key and represents the following condition:

@example
  sel_arg_cond= (inf_val < key_part_n AND key_part_n < sup_val) (1)
                AND next_key_part_sel_arg_cond                  (2)
                OR left_sel_arg_cond                            (3)
                OR right_sel_arg_cond                           (4)
@end example

@enumerate
@item
is for an interval, possibly without upper or lower bound, either including or not including boundary values. 
@item
is for a @code{SEL_ARG} object with condition on next key component.
@item
is for a @code{SEL_ARG} object with interval on the same field as this
@code{SEL_ARG} object. Intervals of current and ``left'' object are
disjoint and @code{left_sel_arg_cond.sup_val <= inf_val}. 
@item
is for a @code{SEL_ARG} object with interval on the same field as this
@code{SEL_ARG} object. Intervals of current and ``right'' object are
disjoint and @code{left_sel_arg_cond.min_val >= max_val}.
@end enumerate

MySQL is able to convert arbitrary-depth nested AND-OR conditions to the above
conjunctive form.


@node Index Merge Optimizer2,  , Index Merge Range Optimizer, Index Merge Optimizer
@subsubsection Index Merge Optimizer

A single @code{SEL_TREE} object cannot be constructed for conditions that
have  different members of keys in the @code{OR} clause, like in condition:

@example
key1 < c1 OR key2 < c2
@end example

Beginning with MySQL 5.0,
these conditions are handled with the @code{Index Merge} method, and its
range optimizer structure, class @code{SEL_IMERGE}. @code{SEL_IMERGE}
represents a disjunction of several @code{SEL_TREE} objects, which can be
expressed as:

@example
sel_imerge_cond = (t_1 OR t_1 OR ... OR t_n) 
@end example

where each of @code{t_i} stands for a @code{SEL_TREE} object, and no pair
(@code{t_i}, @code{t_j}) of distinct @code{SEL_TREE} objects can be combined
into single @code{SEL_TREE} object.

The current implementation builds @code{SEL_IMERGE} only if no single
@code{SEL_TREE} object can be built for the part of the query condition
it has analyzed, and discards @code{SEL_TREE} immediately if it discovers
that a single @code{SEL_TREE} object can be constructed. This is actually
a limitation, and can cause worse row retrieval strategy to be used.
E.g. for query:

@example
SELECT * FROM t WHERE (goodkey1=c1 OR goodkey1=c2) AND badkey=c3
@end example

scan on @code{badkey} will be chosen even if @code{Index Merge} on
(@code{goodkey1}, @code{goodkey}) would be faster.

The @code{Index Merge} optimizer collects a list of possible ways to access
rows with @code{Index Merge}. This list of @code{SEL_IMERGE} structures
represents the following condition:

@example
  (t_11 OR t_12 OR ... OR t_1k) AND
  (t_21 OR t_22 OR ... OR t_2l) AND
   ...                          AND
  (t_M1 OR t_M2 OR ... OR t_mp)
@end example

where @code{t_ij} is one @code{SEL_TREE} and one line is for one
@code{SEL_IMERGE} object. 

The @code{SEL_IMERGE} object with @emph{minimal} cost is used for row
retrieval.

In @file{sql/opt_range.cc}, see @code{imerge_list_and_list()},
@code{imerge_list_or_list()}, and
@code{SEL_IMERGE} class member functions for more details of
@code{Index Merge} construction.

See the @code{get_index_merge_params} function in the same file for
@code{Index Merge} cost calculation algorithm.


@node Index Merge Row Retrieval Algorithm,  , Index Merge Optimizer, Index Merge Join Type
@subsection Row Retrieval Algorithm

@code{Index Merge} works in two steps:

Preparation step:

@example
activate 'index only';
foreach key_i in (key_scans \ clustered_pk_scan)
@{
  while (retrieve next (key, rowid) pair from key_i)
  @{
    if (no clustered PK scan || 
        row doesn't match clustered PK scan condition)
      put rowid into Unique;
  @}
@}  
deactivate 'index only';
@end example

Row retrieval step:

@example
for each rowid in Unique
@{
  retrieve row and pass it to output;
@}
if (clustered_pk_scan)
@{
  while (retrieve next row for clustered_pk_scan)
   pass row to output;
@}
@end example

See: @file{sql/opt_range.cc}, @code{QUICK_INDEX_MERGE_SELECT} class members
for @code{Index Merge} row retrieval code.


@node Algorithms, MySQL column types, optimizer, Top
@chapter Important Algorithms and Structures

MySQL uses many different algorithms and structures.
This chapter tries to describe some of them.

@menu
* item class::                  The Item class
* filesort::                    How MySQL Does Sorting (@code{filesort})
* bulk-insert::                 Bulk Insert
* caching::                     How MySQL Does Caching
* join_buffer_size::            How MySQL Uses the Join Buffer Cache
* flush tables::                How MySQL Handles @code{FLUSH TABLES}
* Full-text Search::            Full-text Search in MySQL
* floating-point types::        @code{FLOAT} and @code{DOUBLE} data types and their representation.
* mysys functions::             Functions in the @code{mysys} Library
@end menu

@node item class, filesort, Algorithms, Algorithms
@section The Item class

To us, the word Item means more than just Thingamabob, it is a technical
term in the context of our source code. Item is a class, and all instances
of the Item class have (a) an analogue in the SQL language, (b) a value,
(c) a data type descriptor. The following SQL thingamabobs all have
analogues in the Item class: literals, column references, session or
global variables, procedure variables, and parameters. And also: any
SQL function (not a surprise since SQL functions have data types and
return values). In the "function" category we include operators such
as + and ||, because operators are merely functions that return values,
and we include operators such as = and LIKE, which are operators that
return boolean values. Consider the following statement:
@example
SELECT UPPER(column1) FROM t WHERE column2 = @@x
@end example
For this statement, MySQL will need to store a list of items for the
select list ('column1' column reference and UPPER function), and a
list of items for the WHERE clause ('column2' column reference and
'@@x' variable and '=' operator).

Terminology: an Item instance in a MySQL program roughly corresponds
to a "site", which according to the standard_SQL definition is
"a place that holds an instance of a value of a specified data type",
Another word that you'll see often in MySQL code is "field", which
means column reference, and the Item_field subclass is generally for column
values that occur for the intersection of a row and column in a table.

MySQL's Item class is defined in .../sql/item.h, and its subclasses are
defined in .../sql/item*.h (that is, in item.h, item_cmpfunc.h,
item_func.h, item_geofunc.h, item_row.h, item_strfunc.h, item_subselect.h,
item_sum.h, item_timefunc.h). Page-width limitations prevent us from
displaying the whole tree, but these are the main Item subclasses, and
the subclasses of the subclasses:

@example
Item_ident (Item_field, Item_ref)
Item_null
Item_num (Item_int, Item_real)
Item_param
Item_string (Item_static_string_func, Item_datetime, Item_empty_string)
Item_hex_string (Item_bin_string)     
Item_result_field (all "item_func.h" "item_subselect.h" "item_sub.h" classes)
Item_copy_string
Item_cache (Item_cache_int, Item_cache_real, Item_cache_str, Item_cache_row)
Item_type_holder
Item_row
@end example

There's no formal classification of subclasses, but the main distinctions
are by use (field, parameter, function) and by data type (num, string).

So, how does MySQL use items? You'll find that nearly every .cc program
in the /sql directory makes some use of the Item class and its subclasses,
so this list of programs is only partial and very general:

@example
sql_parse.cc:     Makes new items in add_field_to_list()
item_sum.cc:      Uses item_func subclasses for COUNT, AVG, SUM
item_buff.cc:     Where buffers for item values can be stored
item_cmpfunc.cc:  Comparison functions with item_func subclasses
item_create.cc    For creating items that the lex might use
item_subselect.cc Subqueries are another type of function
mysqld.cc:        When main() ends, it uses clean_up() for items
opt_range.cc:     Uses field, compare-condition, and value subclasses
procedure.cc:     Notice Procedure * has a pointer to an item list
protocol.cc:      Uses send_fields() to pass item values back to users
sys_var.cc:       System variables have Item associations too
sql_base.cc:      Thread-specific Item searchers like find_field_in_table()
sql_class.cc:     Look at cleanup_after_query()
sql_delete.cc     This (like sql_insert.cc etc.) has field references
sql_error.cc      Has one of many examples of SHOW's use of items
sql_lex.cc:       Notice "add...to_list" functions
sql_select.cc     The largest program that uses items, apparently
udf_example.cc    The comments in this program are extensive
@end example

Whenever there's a need for an SQL operation that assigns, compares,
aggregates, accepts, sends, or validates a site, you'll find a MySQL
use of Item and its subclasses.


@node filesort, bulk-insert, item class, Algorithms
@section How MySQL Does Sorting (@code{filesort})

@c NOTE: This description is also present in manual.texi

@cindex filesort optimization
@cindex optimizing, filesort

In those cases where MySQL must sort the result, it uses the following
@code{filesort} algorithm before MySQL 4.1:

@enumerate

@item
Read all rows according to key or by table scanning.
Rows that don't match the @code{WHERE} clause are skipped.

@item
For each row, store a pair of values in a buffer (the sort key and the row
pointer).  The size of the buffer is the value of the @code{sort_buffer_size}
system variable.

@item
When the buffer gets full, run a qsort (quicksort) on it and store the
result in a temporary file.  Save a pointer to the sorted block.  (If all
pairs fit into the sort buffer, no temporary file is created.)

@item
Repeat the preceding steps until all rows have been read.

@item
Do a multi-merge of up to @code{MERGEBUFF} (7) regions to one block in
another temporary file.  Repeat until all blocks from the first file
are in the second file.

@item
Repeat the following until there are fewer than @code{MERGEBUFF2} (15)
blocks left.

@item
On the last multi-merge, only the pointer to the row (the last part of
the sort key) is written to a result file.

@item
Read the rows in sorted order by using the row pointers in the result file.
To optimize this, we read in a big block of row pointers, sort them, and use
them to read the rows in sorted order into a row buffer. The size of the
buffer is the value of the @code{read_rnd_buffer_size} system variable.
The code for this step is in the @file{sql/records.cc} source file.

@end enumerate

One problem with this approach is that it reads rows twice: One time when
evaluating the @code{WHERE} clause, and again after sorting the pair values.
And even if the rows were accessed successively the first time (for example,
if a table scan is done), the second time they are accessed randomly. (The
sort keys are ordered, but the row positions are not.)

In MySQL 4.1 and up, a @code{filesort} optimization is used that records not
only the sort key value and row position, but also the columns required for
the query.  This avoids reading the rows twice. The modified @code{filesort}
algorithm works like this:

@enumerate

@item
Read the rows that match the @code{WHERE} clause, as before.

@item
For each row, record a tuple of values consisting of the sort key value and
row position, and also the columns required for the query.

@item
Sort the tuples by sort key value

@item
Retrieve the rows in sorted order, but read the required columns directly from
the sorted tuples rather than by accessing the table a second time.

@end enumerate

Using the modified @code{filesort} algorithm, the tuples are longer than the
pairs used in the original method, and fewer of them fit in the sort buffer
(the size of which is given by @code{sort_buffer_size}). As a result, it is
possible for the extra I/O to make the modified approach slower, not faster.
To avoid a slowdown, the optimization is used only if the total size of the
extra columns in the sort tuple does not exceed the value of the
@code{max_length_for_sort_data} system variable. (A symptom of setting the
value of this variable too high is that you will see high disk activity and
low CPU activity.)


@node bulk-insert, caching, filesort, Algorithms
@section Bulk Insert

The logic behind bulk insert optimization is simple.

Instead of writing each key value to B-tree (that is, to the key cache,
although the bulk insert code doesn't know about the key cache), we store
keys in a balanced binary (red-black) tree, in memory. When this tree
reaches its memory limit, we write all keys to disk (to key cache, that is).
But since the key stream coming from the binary tree is already sorted,
inserting goes much faster, all the necessary pages are already in cache,
disk access is minimized, and so forth.

@node caching, join_buffer_size, bulk-insert, Algorithms
@section How MySQL Does Caching

MySQL has the following caches.  (Note that the some of the
filenames contain an incorrect spelling of the word ``cache.'')

@table @strong

@item Key Cache
A shared cache for all B-tree index blocks in the different NISAM
files. Uses hashing and reverse linked lists for quick caching of the
most recently used blocks and quick flushing of changed entries for a specific
table. (@file{mysys/mf_keycash.c})

@item Record Cache
This is used for quick scanning of all records in a table.
(@file{mysys/mf_iocash.c} and @file{isam/_cash.c})

@item Table Cache
This holds the most recently used tables. (@file{sql/sql_base.cc})

@item Hostname Cache
For quick lookup (with reverse name resolving). This is a must when you have a
slow DNS.
(@file{sql/hostname.cc})

@item Privilege Cache
To allow quick change between databases, the last used privileges are
cached for each user/database combination.
(@file{sql/sql_acl.cc})

@item Heap Table Cache
Many uses of @code{GROUP BY} or @code{DISTINCT} cache all found rows in
a @code{HEAP} table. (This is a very quick in-memory table with hash index.)

@item Join Buffer Cache
For every ``full join'' in a @code{SELECT} statement the rows found are
cached in a join cache.  (A ``full join'' here means there were no keys that
could be used to find rows for the next table in the list.) In the worst
case, one @code{SELECT} query can use many join caches.

@end table

@node join_buffer_size, flush tables, caching, Algorithms
@section How MySQL Uses the Join Buffer Cache

Basic information about the join buffer cache:

@itemize @bullet
@item
The size of each join buffer is determined by the value of the
@code{join_buffer_size} system variable.
@item
This buffer is used only when the join is of type @code{ALL} or
@code{index} (in other words, when no possible keys can be used).
@item
A join buffer is never allocated for the first non-const table,
even if it would be of type @code{ALL} or @code{index}.
@item
The buffer is allocated when we need to do a full join between two
tables, and freed after the query is done.
@item
Accepted row combinations of tables before the @code{ALL}/@code{index}
are stored in the cache and are used to compare against each read
row in the @code{ALL} table.
@item
We only store the used columns in the join buffer, not the whole rows.
@end itemize

Assume you have the following join:

@example
Table name      Type
t1              range
t2              ref
t3              @code{ALL}
@end example

The join is then done as follows:

@example
- While rows in t1 matching range
 - Read through all rows in t2 according to reference key
  - Store used fields from t1, t2 in cache
  - If cache is full
    - Read through all rows in t3
      - Compare t3 row against all t1, t2 combinations in cache
        - If row satisfies join condition, send it to client
    - Empty cache

- Read through all rows in t3
 - Compare t3 row against all stored t1, t2 combinations in cache
   - If row satisfies join condition, send it to client
@end example

The preceding description means that the number of times table @code{t3} is
scanned is determined as follows:

@example
S = size-of-stored-row(t1,t2)
C = accepted-row-combinations(t1,t2)
scans = (S * C)/join_buffer_size + 1
@end example

Some conclusions:

@itemize @bullet
@item
The larger the value of @code{join_buffer_size}, the fewer the scans of
@code{t3}.  If @code{join_buffer_size} is already large enough to hold all
previous row combinations, there is no speed to be gained by making it
larger.

@item
If there are several tables of join type @code{ALL} or @code{index}, then we
allocate one buffer of size @code{join_buffer_size} for each of them and use
the same algorithm described above to handle it.  (In other words, we store
the same row combination several times into different buffers.)

@end itemize


@node flush tables, Full-text Search, join_buffer_size, Algorithms
@section How MySQL Handles @code{FLUSH TABLES}

@itemize @bullet
@item
@code{FLUSH TABLES} is handled in @file{sql/sql_base.cc::close_cached_tables()}.

@item
The idea of @code{FLUSH TABLES} is to force all tables to be closed. This is
mainly to ensure that if someone adds a new table outside of MySQL (for
example, by copying files into a database directory with @code{cp}), all
threads will start using the new table. This will also ensure that all table
changes are flushed to disk (but of course not as optimally as simply
calling a sync for all tables)!

@item
When you do a @code{FLUSH TABLES}, the variable @code{refresh_version}
is incremented. Every time a thread releases a table, it checks if
the refresh version of the table (updated at open) is the same as
the current @code{refresh_version}.  If not, it will close it and broadcast
a signal on @code{COND_refresh} (to await any thread that is waiting for
all instances of a table to be closed).

@item
The current @code{refresh_version} is also compared to the open
@code{refresh_version} after a thread gets a lock on a table.  If the
refresh version is different, the thread will free all locks, reopen the
table and try to get the locks again.  This is just to quickly get all
tables to use the newest version.  This is handled by
@file{sql/lock.cc::mysql_lock_tables()} and
@file{sql/sql_base.cc::wait_for_tables()}.

@item
When all tables have been closed, @code{FLUSH TABLES} returns an okay
to the client.

@item
If the thread that is doing @code{FLUSH TABLES} has a lock on some tables,
it will first close the locked tables, then wait until all other threads
have also closed them, and then reopen them and get the locks.
After this it will give other threads a chance to open the same tables.

@end itemize

@node Full-text Search, floating-point types, flush tables, Algorithms
@section Full-text Search in MySQL

Hopefully, sometime there will be complete description of
full-text search algorithms.
For now, it's just unsorted notes.

@strong{Weighting in boolean mode}

The basic idea is as follows: In an expression of the form
@code{A or B or (C and D and E)}, either @code{A} or @code{B} alone
is enough to match the whole expression, whereas @code{C},
@code{D}, and @code{E} should @strong{all} match. So it's
reasonable to assign weight 1 to each of @code{A}, @code{B}, and
@code{(C and D and E)}. Furthermore, @code{C}, @code{D}, and @code{E}
each should get a weight of 1/3.

Things become more complicated when considering boolean
operators, as used in MySQL full-text boolean searching. Obviously, @code{+A +B}
should be treated as @code{A and B}, and @code{A B} -
as @code{A or B}. The problem is that @code{+A B} can @strong{not}
be rewritten in and/or terms (that's the reason why this---extended---set
of operators was chosen). Still, aproximations can be used.
@code{+A B C} can be approximated as @code{A or (A and (B or C))}
or as @code{A or (A and B) or (A and C) or (A and B and C)}.
Applying the above logic (and omitting mathematical
transformations and normalization) one gets that for
@code{+A_1 +A_2 ... +A_N B_1 B_2 ... B_M} the weights
should be: @code{A_i = 1/N}, @code{B_j=1} if @code{N==0}, and,
otherwise, in the first rewriting approach @code{B_j = 1/3},
and in the second one - @code{B_j = (1+(M-1)*2^M)/(M*(2^(M+1)-1))}.

The second expression gives a somewhat steeper increase in total weight as
number of matched @code{B_j} values increases, because it assigns higher
weights to individual @code{B_j} values. Also, the first expression is much
simpler, so it is the first one that is implemented in MySQL.


@node floating-point types, mysys functions, Full-text Search, Algorithms
@section @code{FLOAT} and @code{DOUBLE} data types and their representation.

@c This section written by Ingo Struewing

A quotation from the MySQL Reference Manual regarding numeric types:

"12.2 Numeric Types
...
For floating-point column types, MySQL uses four bytes for single-precision
values and eight bytes for double-precision values.

The @code{FLOAT} type is used to represent approximate numeric data
types. The SQL standard allows an optional specification of the precision
(but not the range of the exponent) in bits following the keyword
@code{FLOAT} in parentheses. The MySQL implementation also supports this
optional precision specification, but the precision value is used only
to determine storage size. A precision from 0 to 23 results in four-byte
single-precision @code{FLOAT} column. A precision from 24 to 53 results
in eight-byte double-precision @code{DOUBLE} column.

When the keyword @code{FLOAT} is used for a column type without a precision
specification, MySQL uses four bytes to store the values. MySQL also
supports variant syntax with two numbers given in parentheses following
the @code{FLOAT} keyword. The first number represents the display width
and the second number specifies the number of digits to be stored and
displayed following the decimal point (as with DECIMAL and NUMERIC). When
MySQL is asked to store a number for such a column with more decimal digits
following the decimal point than specified for the column, the value is
rounded to eliminate the extra digits when the value is stored.

In standard SQL, the @code{REAL} and @code{DOUBLE PRECISION} types do not
accept precision specifications. MySQL supports a variant syntax with
two numbers given in parentheses following the type name. The first
number represents the display width and the second number specifies
the number of digits to be stored and displayed following the decimal
point. As an extension to the SQL standard, MySQL recognizes @code{DOUBLE}
as a synonym for the @code{DOUBLE PRECISION} type. In contrast with the
standard's requirement that the precision for @code{REAL} be smaller than
that used for @code{DOUBLE PRECISION}, MySQL implements both as eight-byte
double-precision floating-point values (unless the server SQL mode includes
the @code{REAL_AS_FLOAT} option).

For maximum portability, code requiring storage of approximate numeric
data values should use @code{FLOAT} or @code{DOUBLE PRECISION} with no
specification of precision or number of decimal points."

The following discussion concentrates on the case where no display width
and decimals are given. This means that @code{FLOAT} is stored as whatever
the C type @code{float} is and @code{REAL} or @code{DOUBLE [PRECISION]}
is stored as whatever the C type @code{double} is. The field length is
selected by the MySQL code.

This document was created when Bug #4457 (Different results in SQL-Statements
for the same record) was fixed at the end of August 2004. Until then there
was some confusion in the double-to-string conversion at different places
in the code.

The bugfix for Bug #4937 (@code{INSERT + SELECT + UNION ALL + DATE to
VARCHAR(8)} conversion problem) produced a conversion function which was a
promising approach to the conversion problems. Unfortunately it was only
used for direct field conversions and not for function results etc. It
did not take small numbers (absolute value less than 1) and negative
numbers into account. It did not take the limited precision of @code{float} and
@code{double} data types into account.  The bugfix was developed in two steps:
The first attempt looked like this (in principle):

@example
length= sprintf(buff, "%.*g", field_length, nr);
if (length > field_length)
  length= sprintf(buff, "%.*g", field_length-5, nr);
@end example

If the @code{libc} conversion brings too much characters, the precision is
reduced by the space required for the scientific notation (1.234e+05). Thus
the @code{printf()} conversion is forced to switch to the scientific
notation, since the value would not fit otherwise. Or, if it was scientific
already, the precision was reduced and also uses less space. I left out some
important stuff around limit checking just to show the idea. This simple
algorithm should work quite well in most cases, but has been discarded
for the sake of performance. The double call to the slow @code{printf()}
conversion @code{%g} didn't seem reasonable, though it would only be
used for extreme values and small fields. During my explorations of the
code I didn't find places where @code{float} or @code{double} were to
be converted into small fields. Remeber that I talk only of conversions
where field length and precision are not given. In this case a sufficient
field length is selected at several places, except of a bug where it was
selected wrongly. If a field length is given, a different conversion is
used anyway. But since the code is quite complex, I don't claim to have
the full insigth and as such may be in error. Hence, let us look further:

The second attempt in the bugfix was like this:

@example
bool use_scientific_notation=TRUE;
if (field_length < 32 && nr > 1)
@{
  double e[]=@{1, 1e1, 1e2, 1e4, 1e8, 1e16 @}, p=1;
  for (int i=sizeof(e), j=1<<i-- ; j; i--,  j>>=1 )
  @{
    if (field_length & j)
      p*=e[i];
  @}
  use_scientific_notation=(p < nr);
@}
length= sprintf(buff, "%.*g", use_scientific_notation ?
                              field_length-5 : field_length, nr);
@end example

Here we evaluate if the string representation of a given number fits into
field_length characters. If not, we reduce the precision to make it fit.
Again, I left out important details. For example, the evaluation is done only
once per field for the sake of performance. The downside here is the
unconditional reduction of precision for field length > 31 (which doesn't
really matter), for negative numbers and for small numbers (absolute value
less than 1).

Both algorithms do not take the limited precision of @code{float}
and @code{double} values into account. This could lead to conversions
with ridiculous bogus precision output. For example a value of 0.7
converted with @code{%.30g} will give a lot of digits, which pretend
to tell about deviations from the value 0.7 and are completely absurd:
0.699999988079071044921875. To understand more about the @code{%g}
conversion, I quote from a comment introduced in the source at the beginning
of bugfixing #4937 (this has been removed later, since it mainly describes,
how the @code{printf()} conversion works. I think it's valuable enough to
include it here):

@example
/*
  Let's try to pretty print a floating point number. Here we use
  '%-*.*g' conversion string:
    '-' stands for right-padding with spaces, if such padding will take
  place
    '*' is a placeholder for the first argument, field_length, and
  signifies minimal width of result string. If result is less than
  field length it will be space-padded. Note, however, that we'll not
  pass spaces to Field_string::store(const char *, ...), due to
  strcend in the next line.
    '.*' is a placeholder for DBL_DIG and defines maximum number of
  significant digits in the result string. DBL_DIG is a hardware
  specific C define for maximum number of decimal digits of a floating
  point number, such that rounding to hardware floating point
  representation and back to decimal will not lead to loss of
  precision. I.e if DBL_DIG is 15, number 123456789111315 can be
  represented as double without precision loss.  As one can judge from
  this description, chosing DBL_DIG here is questionable, especially
  because it introduces a system dependency.
    'g' means that conversion will use [-]ddd.ddd (conventional) style,
  and fall back to [-]d.ddde[+|i]ddd (scientific) style if there is no
  enough space for all digits.
  Maximum length of result string (not counting spaces) is (I guess)
  DBL_DIG + 8, where 8 is 1 for sign, 1 for decimal point, 1 for
  exponent sign, 1 for exponent, and 4 for exponent value.
  XXX: why do we use space-padding and trim spaces in the next line?
*/
sprintf(to,"%-*.*g",(int) field_length,DBL_DIG,nr);
to=strcend(to,' ');
@end example

There is one small misapprehension in the comment. @code{%g} does not
switch to scientific notation when there is 'not enough space for all
digits'. As the commentator says, the field length gives the minimal
output length. @code{printf()} happily outputs more characters if required
to produce a result with 'precision' digits. In fact it switches to
scientific when the value can no longer be represented by 'precision'
digits in conventional notation. The man page says "Style e is used if the
exponent from its conversion is less than -4 or greater than or equal to
the precision." In explanation, a precision of 3 digits can print a value
of 345 in conventional notation, but 3456 needs scientific notation, as it
would require 4 digits (a precision of 4) in conventional notation. Thus,
it is printed as 3.46e+03 (rounded).

Since we don't want spaces in the output, we should not give a field
length, but always use @code{"%.*g"}. However, the precision matters,
as seen above. It is worth its own paragraph.

Since MySQL uses the machine-dependent binary representation of
@code{float} and @code{double} to store values in the database, we have
to care about these. Today, most systems use the IEEE standard 754 for
binary floating-point arithmetic.  It describes a representation for
single precision numbers as 1 bit for sign, 8 bits for biased exponent
and 23 bits for fraction and for double precision numbers as 1-bit sign,
11-bit biased exponent and 52-bit fraction. However, we can not rely in
the fact that every system uses this representation. Luckily, the ISO
C standard requires the standard C library to have a header @file{float.h}
that describes some details of the floating point representation on a
machine. The comment above describes the value @code{DBL_DIG}. There is
an equivalent value @code{FLT_DIG} for the C data type @code{float}.

So, whenever we print a floating-point value, we must not specify a
precision above @code{DBL_DIG} or @code{FLT_DIG} respectively. Otherwise
we produce a bogus precision, which is wrong. For the honor of the writer
of the first attempt above, I must say that his complete algorithm took
@code{DBL_DIG} into account, if however only for the second call to
@code{sprintf()}. But @code{FLT_DIG} has never been accounted for. At the
place of the conversions it was not even known, if the value has come from
a @code{float} or @code{double} field.

My attempt to solve the problems tries to take all this into account. I tried
to concentrate all @code{float}/@code{double}-to-string conversions in one
function, and to bring the knowledge about @code{float} versus @code{double}
to this function wherever it is called. This solution managed to keep
the test suite happy while solving the new problem of Bug #4457. Luckily,
the first was not a big problem, as the test cases have been very carefully
selected, so that they succeed as long as the machine uses IEEE 754 ;).

Nevertheless, the function is still not perfect. It is not possible to guess
how many sigificant digits a number has, and as such it is not simple to tell
how long the resulting string would be. This applies to numbers with an
absolute value smaller then 1. There are probably ways to figure this out, but
I doubt that we would win in terms of performance over the simple solution of
the first attempt, let alone the chance for new bugs. The compromise taken
here is to accept that the resulting string may exceed the destined field
length by five characters in the worst case.

@example
if (nr < 0.0)
@{
  abs_nr= -nr;
  extra_space= 1;
@}
else
@{
  abs_nr= nr;
  extra_space= 0;
@}
precision= is_float ? FLT_DIG : DBL_DIG;
if (precision > field_length)
  precision= field_length;
   
if (! initialized)
@{
  /* Better switch to scientific too early than too late. */
  double mult;
  mult= 1e0;
  for (length= 0; length < DBL_DIG; length++)
    mult/= 1e1;
  mult= 1e1 - mult;
   
  double val;
  val= 1.0;
  for (int idx= 0; idx < DBL_DIG+1; idx++)
  @{
    DBUG_PRINT("info",("double_to_string_conv: big[%d] %.*g",
                       idx, DBL_DIG+3, val));
    big_number[idx]= val;
    val*= mult;
  @}
  small_number[0]= 1e0;
  small_number[1]= 1e0;
  small_number[2]= 1e0;
  small_number[3]= 1e-1;
  small_number[4]= 1e-2;
  small_number[5]= 1e-3;
  small_number[6]= 1e-4;
  /* %g switches to scientific when exponent < -4. */
  for (int idx= 7; idx < DBL_DIG+1; idx++)
    small_number[idx]= 1e-4;
  initialized= TRUE;
@}
   
use_scientific_notation= (abs_nr != 0.0) &&
                         ((abs_nr >   big_number[precision]) ||
                          (abs_nr < small_number[precision]));
   
if (use_scientific_notation)
@{
  if (((nr >= 0.0) && ((nr >= 1e+100) || (nr <= 1e-100))) ||
      ((nr < 0.0) && ((nr <= -1e+100) || (nr >= -1e-100))))
    extra_space+= 6; /* .e+100 or .e-100 */
  else
    extra_space+= 5; /* .e+99  or .e-99 */
@}
   
if (field_length < extra_space)
  precision= 0;
else if (precision > (field_length - extra_space))
  precision= field_length - extra_space;
   
length= sprintf(buff, "%.*g", precision, nr);
@end example

This solution takes performance into account by initializing the limiting
numbers arrays only once into static space. It copes with negative
numbers and tries to decide even over small numbers. The latter has only
small implications, as the prefix 0.000 is exactly the same size as the
postfix e-100. But to know if scientific notation will be selected by
@code{sprintf()} allows for saving one digit when the exponent is larger
than -100.

The calculations for the big number array are less precise than in the second
attempt, but faster. The precision is sufficient for the guess whether
@code{sprintf()} uses scientific notation. There may be number to field length
combinations which exploit the gap, but these won't emerge anyway as I found
no situation where this function is called with small field lengths. Remember
again that it is not called with user supplied field lengths.

However in the current stable releases (including gamma) we have some
places where the field length is too small by one character. Thus, the
precision is sometimes by one digit smaller than @code{DBL_DIG} would
allow for. Consequently, we cannot use the simple algorithm in the stable
releases. There is a chance for doing it in a development release, though.

@strong{Addendum:}

There turned out to be a new solution to the "big number array" problem. We
have a statically initialized array @code{log_10}, which holds the necessary
values. But I did not check, if these values are safe. Even if computed by
the compiler, they could carry values slightly above the decimal powers,
which would be bad. In this case we needed to initialize by 9.99999999e+xxx,
where the number of nines is equal to @code{DBL_DIG}. This must be protected
by @code{#if DBL_DIG == yy}, so that a new @code{DBL_DIG} on a new platform
is detected. And the array is of limited length. We must at least protect
it by a @code{DBUG_ASSERT(sizeof(log_10)/sizeof(log_10[0]) > DBL_DIG}).

But all of this is probably completely unneccessary, since we are only
speaking of ceses where no user-supplied field length is given. So MySQL
selects the field length on its own. So it is totally possible, yes highly
desired that MySQL selects a field length, which allows for a maximum
of precision for all possible values. And these are @code{DBL_DIG+7} or
@code{FLT_DIG+6} respectively as far as IEEE 754 is used. In this case
we can have values of about +/-1e-307 to +/-1e+308 for @code{double} and
+/-1e-37 to +/-1e+38 for @code{float}.  That is, for example -1.<DBL_DIG-1
digits>e+100. For cases where a precision above IEEE 754 is possible, we
may need +8 instead. We can detect this with @code{#if DBL_MAX_10_EXP >=
1000}. So using a field length of @code{DBL_DIG+8} in all cases should
be sufficient for a simple @code{sprintf(buff, "%.*g", DBL_DIG, nr)}
or @code{sprintf(buff, "%.*g", FLT_DIG, nr)}, respectively. To be safe,
we should not use the machine dependend constants everywhere, but instead
concentrate them into definitions like these:

@example
#if (DBL_MAX_10_EXP > 9999) || (DBL_MIN_10_EXP < -9999)
#  error "Need new definition for UNSPECIFIED_DOUBLE_FIELD_LENGTH"
#elif (DBL_MAX_10_EXP > 999) || (DBL_MIN_10_EXP < -999)
#  define UNSPECIFIED_DOUBLE_FIELD_LENGTH (DBL_DIG+8)
#else
#  define UNSPECIFIED_DOUBLE_FIELD_LENGTH (DBL_DIG+7)
#endif

#if (FLT_MAX_10_EXP > 999) || (FLT_MIN_10_EXP < -999)
#error "Need new definition for UNSPECIFIED_FLOAT_FIELD_LENGTH"
#elif (FLT_MAX_10_EXP > 99) || (FLT_MIN_10_EXP < -99)
#  define UNSPECIFIED_FLOAT_FIELD_LENGTH (FLT_DIG+7)
#else
#  define UNSPECIFIED_FLOAT_FIELD_LENGTH (FLT_DIG+6)
#endif
@end example

These definitions should be used wherever an item or field of type
@code{float} or @code{double} without an explicit field length specification
is encountered. We have to propagate these lengths though all deviated
items and fields and to select the maximum of all field lengths wherever
in an expression or function two or more of them are used.

We need to treat the precision (@code{DBL_DIG}/@code{FLT_DIG}) similarly,
but have to select the smallest in expressions or functions.


@node mysys functions,  , floating-point types, Algorithms
@section Functions in the @code{mysys} Library

Functions in @code{mysys}: (For flags see @file{my_sys.h})

@table @code
@item int my_copy _A((const char *from, const char *to, myf MyFlags));
Copy file from @code{from} to @code{to}.

@item int my_rename _A((const char *from, const char *to, myf MyFlags));
Rename file from @code{from} to @code{to}.

@item int my_delete _A((const char *name, myf MyFlags));
Delete file @code{name}.

@item int my_redel _A((const char *from, const char *to, int MyFlags));
Delete @code{from} before rename of @code{to} to @code{from}.  Copies state
from old file to new file. If @code{MY_COPY_TIME} is set, sets old time.

@item int my_getwd _A((string buf, uint size, myf MyFlags));
@item int my_setwd _A((const char *dir, myf MyFlags));
Get and set working directory.

@item string my_tempnam _A((const char *dir, const char *pfx, myf MyFlags));
Make a unique temporary file name by using @code{dir} and adding something after
@code{pfx} to make the name unique.  The file name is made by adding a unique
six character string and @code{TMP_EXT} after @code{pfx}.
Returns pointer to @code{malloc()}'ed area for filename. Should be freed by
@code{free()}.

@item File my_open _A((const char *FileName,int Flags,myf MyFlags));
@item File my_create _A((const char *FileName, int CreateFlags, int AccsesFlags, myf MyFlags));
@item int my_close _A((File Filedes, myf MyFlags));
@item uint my_read _A((File Filedes, byte *Buffer, uint Count, myf MyFlags));
@item uint my_write _A((File Filedes, const byte *Buffer, uint Count, myf MyFlags));
@item ulong my_seek _A((File fd,ulong pos,int whence,myf MyFlags));
@item ulong my_tell _A((File fd,myf MyFlags));
Use instead of open, open-with-create-flag, close, read, and write
to get automatic error messages (flag @code{MYF_WME}) and only have
to test for != 0 if error (flag @code{MY_NABP}).

@item FILE *my_fopen _A((const char *FileName,int Flags,myf MyFlags));
@item FILE *my_fdopen _A((File Filedes,int Flags,myf MyFlags));
@item int my_fclose _A((FILE *fd,myf MyFlags));
@item uint my_fread _A((FILE *stream,byte *Buffer,uint Count,myf MyFlags));
@item uint my_fwrite _A((FILE *stream,const byte *Buffer,uint Count, myf MyFlags));
@item ulong my_fseek _A((FILE *stream,ulong pos,int whence,myf MyFlags));
@item ulong my_ftell _A((FILE *stream,myf MyFlags));
Same read-interface for streams as for files.

@item gptr _mymalloc _A((uint uSize,const char *sFile,uint uLine, myf MyFlag));
@item gptr _myrealloc _A((string pPtr,uint uSize,const char *sFile,uint uLine, myf MyFlag));
@item void _myfree _A((gptr pPtr,const char *sFile,uint uLine));
@item int _sanity _A((const char *sFile,unsigned int uLine));
@item gptr _myget_copy_of_memory _A((const byte *from,uint length,const char *sFile, uint uLine,myf MyFlag));
@code{malloc(size,myflag)} is mapped to these functions if not compiled
with @code{-DSAFEMALLOC}.

@item void TERMINATE _A((void));
Writes @code{malloc()} info on @code{stdout} if compiled with
@code{-DSAFEMALLOC}.

@item int my_chsize _A((File fd, ulong newlength, myf MyFlags));
Change size of file @code{fd} to @code{newlength}.

@item void my_error _D((int nr, myf MyFlags, ...));
Writes message using error number (see @file{mysys/errors.h}) on @code{stdout},
or using curses, if @code{MYSYS_PROGRAM_USES_CURSES()} has been called.

@item void my_message _A((const char *str, myf MyFlags));
Writes @code{str} on @code{stdout}, or using curses, if
@code{MYSYS_PROGRAM_USES_CURSES()} has been called.

@item void my_init _A((void ));
Start each program (in @code{main()}) with this.

@item void my_end _A((int infoflag));
Gives info about program.
If @code{infoflag & MY_CHECK_ERROR}, prints if some files are left open.
If @code{infoflag & MY_GIVE_INFO}, prints timing info and @code{malloc()} info
about program.

@item int my_copystat _A((const char *from, const char *to, int MyFlags));
Copy state from old file to new file.  If @code{MY_COPY_TIME} is set,
sets old time.

@item string my_filename _A((File fd));
Returns filename of open file.

@item int dirname _A((string to, const char *name));
Copy name of directory from filename.

@item int test_if_hard_path _A((const char *dir_name));
Test if @code{dir_name} is a hard path (starts from root).

@c Question: Does this really capitalize?

@item void convert_dirname _A((string name));
Convert dirname according to system.
On Windows, changes all characters to capitals and changes @samp{/} to @samp{\}.

@item string fn_ext _A((const char *name));
Returns pointer to extension in filename.

@item string fn_format _A((string to,const char *name,const char *dsk,const char *form,int flag));

Format a filename with replacement of library and extension and
convert between different systems.
The @code{to} and @code{name} parameters may be identical.
Function doesn't change name if @code{name} != @code{to}.
@code{flag} may be:

@multitable @columnfractions .10 .90
@item 1 @tab Force replace filnames library with 'dsk'
@item 2 @tab Force replace extension with 'form' */
@item 4 @tab Force unpack filename (replace @code{~} with home directory)
@item 8 @tab Pack filename as short as possible for output to user
@end multitable

All open requests should always use at least
@code{open(fn_format(temp_buffer, name, "", "", 4), ...)} to unpack home and
convert filename to system-form.

@item string fn_same _A((string toname, const char *name, int flag));
Copies directory and extension from @code{name} to @code{toname} if needed.
Copying can be forced by same flags used in @code{fn_format()}.

@item int wild_compare _A((const char *str, const char *wildstr));
Compare if @code{str} matches @code{wildstr}. @code{wildstr} can contain
@samp{*} and @samp{?} as wildcard characters.
Returns 0 if @code{str} and @code{wildstr} match.

@item void get_date _A((string to, int timeflag));
Get current date in a form ready for printing.

@item void soundex _A((string out_pntr, string in_pntr))
Makes @code{in_pntr} to a 5 char long string.  All words that sound
alike have the same string.

@item int init_key_cache _A((ulong use_mem, ulong leave_this_much_mem));
Use caching of keys in MISAM, PISAM, and ISAM.
@code{KEY_CACHE_SIZE} is a good size.
Remember to lock databases for optimal caching.

@item void end_key_cache _A((void));
End key caching.
@end table

@node MySQL column types, Charsets, Algorithms, Top
@chapter The different column types in MySQL

This needs to be extended...

@menu
* VARCHAR::                     VARCHAR type
@end menu

@node VARCHAR,  , MySQL column types, MySQL column types
@section VARCHAR type

@itemize @bullet
@item
In old tables (from MySQL 4.1 and below) VARCHAR fields have type
MYSQL_TYPE_VAR_STRING, which works exactly like a CHAR with the
exception that if you do an ALTER TABLE it's converted to a true
VARCHAR (MYSQL_TYPE_VARCHAR).
(This means that old tables will work as before for users)
@item
Apart from the above case, there is not anymore any automatic changes
from CHAR to VARCHAR or from VARCHAR to CHAR. MySQL will remember the
used type and stick to it.
@item
VARCHAR is implemented in field.h and field.cc through the
new class Field_varstring.
@item
MyISAM implements VARCHAR both for dynamic length and fixed length
rows (as signaled with the ROW_FORMAT flag)
@item
The main difference between VARCHAR and CHAR is that VARCHAR stores end
space. (If end space doesn't fit into the column, this is an error in
strict mode). Note that end space are not significant in compare or for
unique; In this case VARCHAR works just like CHAR.
@item
In table->record there is reserved a fixed amount of space for
the varchar lengths (1 or 2 bytes) + data.
@item
If VARCHAR storage length <= 255 then we use 1 byte length, else a 2
byte length. This gives us 65535 as a maximum size for VARCHAR (for
multi-byte character sets the maximum size is of course smaller).
@item  
The number of bytes used to store the length is in the field
Field_varchar->length_bytes. Note that internally this can be 2 even if
Field_varchar->field_length < 256 (for example for a shortened key to a
varchar(256)).
@item
There is a new macro: HA_VARCHAR_PACKLENGTH(field_length) that can be
used on field->length in write_row / read_row to check how many length
bytes are used. (In this context we can't have a field_length < 256 with
a 2 byte pack length)
@item
When creating a key for the handler, HA_KEYTYPE_VARTEXT1 and
HA_KEYTYPE_BINARY1 are used for a key on a column that has a 1 byte
length prefix and HA_KEYTYPE_VARTEXT2 and HA_KEYTYPE_BINARY2 for a
column that has a 2 byte length prefix.  (In the future we will probably
delete HA_KEYTYPE_BINARY# as this can be instead be done by just using
the binary characterset with HA_KEYTYPE_VARTEXT#)
@item
When sending a key to the handler for index_read() or records_in_range,
we always use a 2 byte length for the VARCHAR to make things simpler.
(The intention is in 5.1 change CHAR's to also use a 2 byte length for
these functions, as this will speed up and simplify the key handling
code on the handler side)
@item
The test case 'mysql-test/include/varchar.inc' should be include in the
code that tests the handler, see t/myisam.test for how to use this.  You
should verify the result against the one in mysql-test/t/myisam.result'
to ensure that you get the correct results.
@item
Clients sees both the old and new VARCHAR type as MYSQL_TYPE_VAR_STRING,
it will never (at least for 5.0) see MYSQL_TYPE_VARCHAR.  This is to
ensure that old clients will work as before.
@item
If one runs MySQL 5.0 with the --new option, then MySQL will show old
VARCHAR columns as 'CHAR' in SHOW CREATE TABLE. (This is useful when
testing if a table is using the new VARCHAR type or not).
@end itemize

@node Charsets, selects, MySQL column types, Top
@chapter Charsets and Related Issues

@menu
* CHARSET_INFO::                @code{CHARSET_INFO} Structure
@end menu

@node CHARSET_INFO,  , Charsets, Charsets
@section @code{CHARSET_INFO} Structure

@node selects, transformations, Charsets, Top
@chapter How MySQL Performs Different Selects

@menu
* select steps::                Steps of Select Execution
* select select_result::        @code{select_result} Class
* select simple::               @code{SIMPLE} or @code{PRIMARY SELECT}
* select structure::            Structure Of Complex Select
* select union::                Non-Subquery @code{UNION} Execution
* select derived::              Derived Table Execution
* select subquery::             Subqueries
* select select engine::        Single Select Engine
* select union engine::         Union Engine
* select special engines::      Special Engines
* selectexplain::               Explain Execution
@end menu

@node select steps, select select_result, selects, selects
@section Steps of Select Execution

Every select is performed in these base steps:
@itemize @bullet
@item
@code{JOIN::prepare}
@itemize @bullet
@item
Initialization and linking @code{JOIN} structure to @code{st_select_lex}.
@item
@code{fix_fields()} for all items (after @code{fix_fields()}, we know
everything about item).
@item
Moving @code{HAVING} to @code{WHERE} if possible.
@item
Initialization procedure if there is one.
@end itemize
@item
@code{JOIN::optimize}
@itemize @bullet
@item
Single select optimization.
@item
Creation of first temporary table if needed.
@end itemize
@item
@code{JOIN::exec}
@itemize @bullet
@item
Performing select (a second temporary table may be created).
@end itemize
@item
@code{JOIN::cleanup}
@itemize @bullet
@item
Removing all temporary tables, other cleanup.
@end itemize
@item
@code{JOIN::reinit}
@itemize @bullet
@item
Prepare all structures for execution of @code{SELECT} (with
@code{JOIN::exec}).
@end itemize
@end itemize

@node select select_result, select simple, select steps, selects
@section @code{select_result} Class

This class has a very important role in @code{SELECT} performance with
@code{select_result} class and
classes inherited from it (usually called with a @code{select_} prefix). This
class provides the interface for transmitting results.

The key methods in this class are the following:

@itemize @bullet
@item
@code{send_fields} sends given item list headers (type, name, etc.).
@item
@code{send_data} sends given item list values as row of table of result.
@item
@code{send_error} is used mainly for error interception,
making some operation and then @code{::send_error} will be called.
@end itemize

For example, there are the following @code{select_result} classes:

@itemize @bullet
@item 
@code{select_send} used for sending results though network layer.
@item 
@code{select_export} used for exporting data to file.
@item
@code{multi_delete} used for multi-delete.
@item
@code{select_insert} used for @code{INSERT} ... @code{SELECT} ...
@item
@code{multi_update} used for multi-update.
@item
@code{select_singlerow_subselect} used for row and scalar subqueries..
@item
@code{select_exists_subselect} used for
@code{EXISTS}/@code{IN}/@code{ALL}/@code{ANY}/@code{SOME} subqueries.
@item
@code{select_max_min_finder_subselect} used for min/max subqueries
(@code{ALL}/@code{ANY} subquery optimization).
@end itemize

@node select simple, select structure, select select_result, selects
@section @code{SIMPLE} or @code{PRIMARY SELECT}

For performing single primary select, @code{SELECT} uses the
@code{mysql_select} function, which does:
@itemize @bullet
@item
allocate @code{JOIN}
@item
@code{JOIN::prepare}
@item
@code{JOIN::optimize}
@item
@code{JOIN::exec}
@item
@code{JOIN::cleanup}
@end itemize

In previous versions of MySQL, all @code{SELECT} operations were performed
with the help of this function and @code{mysql_select()} was not divided
into parts.

@node select structure, select union, select simple, selects
@section Structure Of Complex Select

There are two structures that describe selects:

@itemize @bullet
@item
@code{st_select_lex} (@code{SELECT_LEX}) for representing @code{SELECT} itself
@item
@code{st_select_lex_unit} (@code{SELECT_LEX_UNIT}) for grouping several selects in a bunch
@end itemize

The latter item represents @code{UNION} operation (the absence of @code{UNION} is a union
with only one @code{SELECT} and this structure is present in any case). In the
future, this
structure will be used for @code{EXCEPT} and @code{INTERSECT} as well.

For example:
@example
(SELECT ...) UNION (SELECT ... (SELECT...)...(SELECT...UNION...SELECT))
   1           2      3           4             5        6       7
@end example

will be represented as:

@example
------------------------------------------------------------------------
                                                                 level 1
SELECT_LEX_UNIT(2)
|
+---------------+
|               |
SELECT_LEX(1)   SELECT_LEX(3)
                |
--------------- | ------------------------------------------------------
                |                                                level 2
                +-------------------+
                |                   |
                SELECT_LEX_UNIT(4)  SELECT_LEX_UNIT(6)
                |                   |
                |                   +--------------+
                |                   |              |
                SELECT_LEX(4)       SELECT_LEX(5)  SELECT_LEX(7)

------------------------------------------------------------------------
@end example

Note: Single subquery 4 has its own @code{SELECT_LEX_UNIT}.

The uppermost @code{SELECT_LEX_UNIT} (#2 in example) is stored in LEX.
The first and uppermost @code{SELECT_LEX} (#1 in example) is stored in LEX, too.
These two structures always exist.

At the time of creating or performing any @code{JOIN::*} operation,
@code{LEX::current_select} points to an appropriate @code{SELECT_LEX}.

Only during parsing of global @code{ORDER BY} and @code{LIMIT} clauses (for
the whole @code{UNION}), @code{LEX::current_select} points to
@code{SELECT_LEX_UNIT} of this unit, in order to store this parameter in
this @code{SELECT_LEX_UNIT}. @code{SELECT_LEX} and @code{SELECT_LEX_UNIT}
are inherited from @code{st_select_lex_node}.


@node select union, select derived, select structure, selects
@section Non-Subquery @code{UNION} Execution

Non-subquery unions are performed with the help of @code{mysql_union()}. For
now, it is divided into the following steps:

@itemize @bullet

@item
@code{st_select_lex_unit::prepare} (the same procedure can be called for
single @code{SELECT} for derived table => we have support for it in this
procedure, but we will not describe it here):

@itemize @bullet

@item
Create @code{select_union} (inherited from @code{select_result}) which will
write select results in this temporary table, with empty temporary
table entry. We will need this object to store in every @code{JOIN} structure
link on it, but we have not (yet) temporary table structure.

@item
Allocate @code{JOIN} structures and execute @code{JOIN::prepare()} for every
@code{SELECT} to get full information about types of elements of
@code{SELECT} list (results).  Merging types of result fields and storing
them in special Items (@code{Item_type_holder}) will be done in this loop,
too. Result of this operation (list of types of result fields) will be
stored in @code{st_select_lex_unit::types}).

@item
Create a temporary table for storing union results (if @code{UNION} without
@code{ALL} option, 'distinct' parameter will be passed to the table creation
procedure).

@item
Assign a temporary table to the @code{select_union} object created in the first step.

@end itemize

@item
@code{st_select_lex_unit::exec}

@itemize @bullet

@item
Delete rows from the temporary table if this is not the first call.

@item
if this is the first call, call @code{JOIN::optimize} else
@code{JOIN::reinit} and then @code{JOIN::exec} for all @code{SELECT}s
(@code{select_union} will write a result for the temporary table). If union
is cacheable and this is not the first call, the method will do nothing.

@item
Call @code{mysql_select} on temporary table with global @code{ORDER BY} and
@code{LIMIT} parameters after collecting results from all @code{SELECT}s.
A special @code{fake_select_lex} (@code{SELECT_LEX}) which is created for
every @code{UNION} will be passed for this procedure (this @code{SELECT_LEX}
also can be used to store global @code{ORDER BY} and @code{LIMIT} parameters
if brackets used in a query).

@end itemize

@end itemize

@node select derived, select subquery, select union, selects
@section Derived Table Execution

``Derived tables'' is the internal name for subqueries in the @code{FROM}
clause.

The processing of derived tables is now included in the table opening
process (@code{open_and_lock_tables()} call). Routine of execution derived
tables and substituting temporary table instead of it
(@code{mysql_handle_derived()}) will be called just after opening and
locking all real tables used in query (including tables used in derived
table query).

If @code{lex->derived_tables} flag is present, all @code{SELECT_LEX}
structures will be scanned (there is a list of all @code{SELECT_LEX}
structures in reverse order named @code{lex->all_selects_list}, the first
@code{SELECT} in the query will be last in this list).

There is a pointer for the derived table, @code{SELECT_LEX_UNIT} stored in
the @code{TABLE_LIST} structure (@code{TABLE_LIST::derived)}. For any table
that has this pointer, @code{mysql_derived()} will be called.

@code{mysql_derived()}:

@itemize @bullet
@item
Creates @code{union_result} for writing results in this table (with empty
table entry, same as for @code{UNION}s).
@item
call @code{unit->prepare()} to get list of types of result fields (it work
correctly for single @code{SELECT}, and do not create temporary table for
@code{UNION} processing in this case).
@item
Creates a temporary table for storing results.
@item
Assign this temporary table to @code{union_result} object.
@item
Calls @code{mysql_select} or @code{mysql_union} to execute the query.
@item
If it is not explain, then cleanup @code{JOIN} structures after execution
(@code{EXPLAIN} needs data of optimization phase and cleanup them after
whole query processing).
@item
Stores pointer to this temporary table in @code{TABLE_LIST} structure, then
this table will be used by outer query.
@item
Links this temporary table in @code{thd->derived_tables} for removing after
query execution. This table will be closed in @code{close_thread_tables} if
its second parameter (@code{bool skip_derived}) is true.
@end itemize


@node select subquery, select select engine, select derived, selects
@section Subqueries

In expressions, subqueries (that is, subselects) are represented by
@code{Item} inherited from @code{Item_subselect}.

To hide difference in performing single @code{SELECT}s and @code{UNION}s,
@code{Item_subselect} uses two different engines, which provide uniform
interface for access to underlying @code{SELECT} or @code{UNION}
(@code{subselect_single_select_engine} and @code{subselect_union_engine},
both are inherited from @code{subselect_engine}).

The engine will be created at the time @code{Item_subselect} is constructed
(@code{Item_subselect::init} method).

On @code{Item_subselect::fix_fields()}, @code{engine->prepare()} will be called.

Before calling any value-getting method (@code{val}, @code{val_int},
@code{val_str}, @code{bring_value} (in case of row result))
@code{engine->exec()} will be called, which executes the query or just does
nothing if subquery is cacheable and has already been executed.

Inherited items have their own select_result classes. There are
two types of them:

@itemize @bullet
@item
@code{select_singlerow_subselect}, to store values of given rows in
@code{Item_singlerow_subselect} cache on @code{send_data()} call, and report
error if @code{Item_subselect} has 'assigned' attribute.
@item
@code{select_exists_subselect} just store 1 as value of
@code{Item_exists_subselect} on @code{send_data()} call. Since
@code{Item_in_subselect} and @code{Item_allany_subselect} are inherited from
@code{Item_exists_subselect,} they use the same @code{select_result} class.
@end itemize

@code{Item_subselect} will never call the @code{cleanup()} procedure for
@code{JOIN}. Every @code{JOIN::cleanup} will call @code{cleanup()} for inner
@code{JOIN}s. The uppermost @code{JOIN::cleanup} will be called by
@code{mysql_select()} or @code{mysql_union()}.

@node select select engine, select union engine, select subquery, selects
@section Single Select Engine

subselect_single_select_engine:
@itemize @bullet
@item
@code{constructor} allocate @code{JOIN} and store pointers on
@code{SELECT_LEX} and @code{JOIN}.
@item
@code{prepare()} call @code{JOIN::prepare}.
@item
@code{fix_length_and_dec()} prepare cache and receive type and
parameters of returning items (called only by
@code{Item_singlerow_subselect}).
@item
@code{exec()} drop 'assigned' flag of @code{Item_subselect}. If this is the
first time, call @code{JOIN::optimize} and @code{JOIN::exec()}, else do
nothing or @code{JOIN::reinit()} @code{JOIN::exec()} depending on type of
subquery.
@end itemize

@node select union engine, select special engines, select select engine, selects
@section Union Engine

@code{subselect_union_engine}:
@itemize @bullet
@item
@code{constructor} just store pointer to @code{st_select_lex_union}
(@code{SELECT_LEX_UNION}).
@item
@code{prepare()} call @code{st_select_lex_unit::prepare}.
@item
@code{fix_length_and_dec()} prepare cache and receive type and
parameters (maximum of length) of returning items (called
only by @code{Item_singlerow_subselect}).
@item
@code{exec()} call @code{st_select_lex_unit::exec()}.
@code{st_select_lex_unit::exec()}
can drop 'assigned' flag of @code{Item_subselect} if 
@code{st_select_lex_unit::item} is not 0.
@end itemize

@node select special engines, selectexplain, select union engine, selects
@section Special Engines

There are special engines used for optimization purposes. These
engines do not have a full range of features. They can only fetch data.
The normal engine can be replaced with such special engines only during the
optimization process.

Now we have two such engines:

@itemize @bullet
@item
@code{subselect_uniquesubquery_engine} used for:

@example
left_expression IN (SELECT primary_key FROM table WHERE conditions)
@end example

This looks for the given value once in a primary index, checks the
@code{WHERE} condition, and returns ``was it found or not?''
@item
@code{subselect_indexsubquery_engine} used for:

@example
left_expression IN (SELECT any_key FROM table WHERE conditions)
@end example

This first looks up the value of the left expression in an index (checking
the @code{WHERE} condition), then if value was not found, it checks for
@code{NULL} values so that it can return @code{NULL} correctly (only if a
@code{NULL} result makes sense, for example if an @code{IN} subquery is the
top item of the @code{WHERE} clause then @code{NULL} will not be sought)

@end itemize

The decision about replacement of the engine happens in @code{JOIN::optimize}, after calling
@code{make_join_readinfo}, when we know what the best index choice is.

@node selectexplain,  , select special engines, selects
@section Explain Execution

For an @code{EXPLAIN} statement, for every @code{SELECT}, @code{mysql_select} will be called
with option @code{SELECT_DESCRIBE}.

For main @code{UNION}, @code{mysql_explain_union} will be called.

For every @code{SELECT} in a given
union, @code{mysql_explain_union} will call @code{mysql_explain_select}.

@code{mysql_explain_select} will call @code{mysql_select} with option
@code{SELECT_DESCRIBE}.

@code{mysql_select} creates a @code{JOIN} for select if it does not already
exist (it might already exist because if it called for subselect
@code{JOIN} can be created in @code{JOIN::optimize} of outer query when it
decided to calculate the value of the subquery). Then it calls
@code{JOIN::prepare}, @code{JOIN::optimize}, @code{JOIN::exec} and
@code{JOIN::cleanup} as usual.

@code{JOIN::exec} is called for @code{SELECT} with @code{SELECT_DESCRIBE}
option call @code{select_describe}.

@code{select_describe} returns the user description of @code{SELECT} and
calls @code{mysql_explain_union} for every inner @code{UNION}.

PROBLEM: how it will work with global query optimization?

@node transformations, Client/Server Protocol, selects, Top
@chapter How MySQL Transforms Subqueries

@code{Item_subselect} virtual method @code{select_transformer} is used to
rewrite subqueries. It is called from @code{Item_subselect::init} (which is
called just after call to @code{fix_fields()} method for all items in
@code{JOIN::prepare}).

@menu
* transformation IN::           @code{Item_in_subselect::select_transformer}
* transformations all any::     @code{Item_allany_subselect}
* transformations singlerow::   @code{Item_singlerow_subselect}
@end menu

@node transformation IN, transformations all any, transformations, transformations
@section @code{Item_in_subselect::select_transformer}

@code{Item_in_subselect::select_transformer} is divided into two parts, for
the scalar left part and the row left part.

@menu
* transformation scalar IN::    Scalar @code{IN} Subquery
* transformations row IN::      Row @code{IN} Subquery
@end menu

@node transformation scalar IN, transformations row IN, transformation IN, transformation IN
@subsection Scalar @code{IN} Subquery

To rewrite a scalar @code{IN} subquery, the method used is
@code{Item_in_subselect::single_value_transformer}. Scalar @code{IN}
subquery will be replaced with @code{Item_in_optimizer}.

@code{Item_in_optimizer} item is a special boolean function. On a value
request (one of @code{val}, @code{val_int}, or @code{val_str} methods) it
evaluates left expression of @code{IN} by storing its value in cache item
(one of @code{Item_cache*} items), then it tests the cache to see whether it
is @code{NULL}. If left expression (cache) is @code{NULL}, then
@code{Item_in_optimizer} returns @code{NULL}, else it evaluates
@code{Item_in_subselect}.

Example queries.
@example
a) SELECT * from t1 where t1.a in (SELECT t2.a FROM t2);
b) SELECT * from t1 where t1.a in (SELECT t2.a FROM t2 GROUP BY t2.a);
@end example

@itemize @bullet
@item
@code{Item_in_subselect} inherits the mechanism for getting a value from
@code{Item_exists_subselect}.
@item
@code{Select_transformer} stores a reference to the left expression in its
conditions:

@example
(in WHERE and HAVING in case 'a' and in HAVING in case 'b')
@end example
@item
Item from item list of this select (@code{t2.a}) can be referenced with a
special reference (@code{Item_ref_null_helper} or @code{Item_null_helper}).
This reference informs @code{Item_in_optimizer} whether item (@code{t2.a})
is @code{NULL} by setting the 'was_null' flag.
@item
The return value from @code{Item_in_subselect} will be evaluated as follows:
@itemize @bullet
@item
If TRUE, return true
@item
If NULL, return null (that is, unknown)
@item
If FALSE, and 'was_null' is set, return null
@item
Return FALSE
@end itemize
@end itemize

<left_expression> IN (SELECT <item> ...) will be represented as
follows:
@example
                        +-----------------+
                        |Item_in_optimizer|
                        +-----------------+
                                 |
           +---------------------+------------+
           |                                  |
+-----------------------+             +-----------------+
|   <left_expression>   |             |Item_in_subselect|
|                       |             +-----------------+
+-----------------------+                      |
|<left_expression cache>|          +-----------+-----------+
|                       |          |                       |
+-----------------------+          |                       |
           ^                 +----------+        +--------------------+
           +<<<<<<<<<<<<<<<<<| Item_ref |    +<<<|Item_ref_null_helper|
                             +----------+    V   +--------------------+
                                             V   +--------------------+
                                             +>>>|       <item>       |
                                                 +--------------------+
@end example
where @code{<<<<<<<<<} is reference in meaning of @code{Item_ref}.

@code{Item_ref} is used to point to @code{<left_expression cache>}, because
at the time of transformation we know only the address of variable where the
cache pointer will be stored.

If the select statement has an @code{ORDER BY} clause, it will be wiped out,
because there is no sense in @code{ORDER BY} without @code{LIMIT} here.

If @code{IN} subquery union, the condition of every select in the
@code{UNION} will be changed individually.

If a condition needs to be added to the @code{WHERE} clause,
it will be presented as @code{(item OR item IS NULL)} and
@code{Item_is_not_null_test(item)} will be added to the @code{HAVING}
clause. @code{Item_is_not_null_test} registers @code{NULL} value the
way @code{Item_ref_null_helper} does it, and returns FALSE if argument
is @code{NULL}.  With the above trick, we will register @code{NULL} value
of @code{Item} even for the case of index optimization of a @code{WHERE}
clause (case 'a' in the following example).

The following are examples of @code{IN} transformations:

@itemize @bullet

@item Example 1:

@example
<left_expression> IN (SELECT <item> FROM t WHERE <where_exp>)
@end example

If returning @code{NULL} correctly would make sense, the above will become:

@example
(SELECT 1 FROM t
  WHERE
    <where_exp> and
    (Item_ref(<cached_left_expression>)=<item> or
     <Item> is null)
  HAVING Item_is_not_null_test(<item>))
@end example

When subquery is marked as the top item of the @code{WHERE} clause, it will
become:

@example
(SELECT 1 FROM t
  WHERE
     <where_exp> and
     Item_ref(<cached_left_expression>)=<item>)
@end example

@item Example 2:

@example
<left_expression> IN (SELECT <item> FROM t
                           HAVING <having_expr>
                           ORDER BY 1)
@end example

will be represented as

@example
(SELECT <item> as ref_null_helper FROM t
   HAVING <having_exp> AND
     Item_ref(<cached_left_expression>) = Item_ref_null_helper(item))
@end example

@item Example 3:

@example
<left_expression> IN (SELECT <item> UNION ...)
@end example

will become

@example
(SELECT 1
   HAVING Item_ref(<cached_left_expression>)=
          <Item_null_helper(<Item>)>
 UNION ...)
@end example

(@code{HAVING} without @code{FROM} is a syntax error, but a @code{HAVING}
condition is checked even for subquery without @code{FROM})

@item Example 4:

@example
<left_expression> IN (select <item>)
@end example

will be completely replaced with @code{<left_expression> = <item>}

@end itemize

Now conditions @code{(WHERE (a) or HAVING (b))} will be changed, depending on
the select, in the following way:

If subquery contains a @code{HAVING} clause, @code{SUM()} function  or
@code{GROUP BY} (example 1), then the item
list will be unchanged and @code{Item_ref_null_helper} reference will be
created on item list element. A condition will be added to the @code{HAVING}.

If the subquery does not contain @code{HAVING}, @code{SUM()} function or
@code{GROUP BY} (example 2), then:

@itemize @bullet
@item
@code{item list} will be replaced with 1.
@item
@code{left_expression cache> = <item> or is null <item>} will be added to
the @code{WHERE} clause and a special @code{is_not_null(item)} will be added
to the @code{HAVING}, so null values will be registered. If returning
@code{NULL} wouldn't make correct sense, then only @code{left_expression
cache> = <item>} will be added to the @code{WHERE} clause.  If this subquery
does not contain a @code{FROM} clause or if the subquery contains
@code{UNION} (example 3), then @code{left_expression cache> =
Item_null_helper(<item>)} will be added to the @code{HAVING} clause.
@end itemize

A single select without a @code{FROM} clause will be reduced to just
@code{<left_expression> = <item>} without use of @code{Item_in_optimizer}.


@node transformations row IN,  , transformation scalar IN, transformation IN
@subsection Row @code{IN} Subquery

To rewrite a row @code{IN} subquery, the method used is
@code{Item_in_subselect::row_value_transformer}. It works in almost the same way as
the scalar analog, but works with @code{Item_cache_row} for caching left expression
and uses references for elements of @code{Item_cache_row}.
To refer to item list it uses @code{Item_ref_null_helper(ref_array+i)}.

Subquery with @code{HAVING}, @code{SUM()} function, or @code{GROUP BY} will
transformed in the following way:

@example
ROW(l1, l2, ... lN) IN (SELECT i1, i2, ... iN FROM t HAVING <having_expr>)
@end example

will become:

@example
(SELECT i1, i2, ... iN FROM t
   HAVING <having_expr> and
     <cache_l0> = <Item_ref_null_helper(ref_array[0]> AND
     <cache_l1> = <Item_ref_null_helper(ref_array[1])> AND
     ...
     <cache_lN-1> = <Item_ref_null_helper(ref_array[N-1]>)
@end example

@code{SELECT} without @code{FROM} will be transformed in this way, too.

It will be the same for other subqueries, except for the @code{WHERE} clause.


@node transformations all any, transformations singlerow, transformation IN, transformations
@section @code{Item_allany_subselect}

@code{Item_allany_subselect} is inherited from @code{Item_in_subselect}.
@code{ALL}/@code{ANY}/@code{SOME} use the same algorithm (and the same
method of @code{Item_in_subselect}) as scalar @code{IN}, but use a different
function instead of @code{=}.

@code{ANY}/@code{SOME} use the same function that was listed after the left
expression.

@code{ALL} uses an inverted function, and all subqueries passed as arguments
to @code{Item_func_not_all} (@code{Item_func_not_all} is a special
@code{NOT} function used in optimization, see following).

But before above transformation ability of independent
@code{ALL}/@code{ANY}/@code{SOME} optimization will be checked (query is
independent, operation is one of @code{<}, @code{=<}, @code{>}, @code{>=},
returning correct @code{NULL} have no sense (top level of @code{WHERE}
clause) and it is not row subquery).

For such queries, the following transformation can be done:

@example
val >  ALL (SELECT...) -> val >  MAX (SELECT...)
val <  ALL (SELECT...) -> val <  MIN (SELECT...)
val >  ANY (SELECT...) -> val >  MIN (SELECT...)
val <  ANY (SELECT...) -> val <  MAX (SELECT...)
val >= ALL (SELECT...) -> val >= MAX (SELECT...)
val <= ALL (SELECT...) -> val <= MIN (SELECT...)
val >= ANY (SELECT...) -> val >= MIN (SELECT...)
val <= ANY (SELECT...) -> val <= MAX (SELECT...)
@end example

@code{ALL} subqueries already have @code{NOT} before them. This problem can
be solved with help of special @code{NOT}, which can bring 'top' tag to its
argument and correctly process @code{NULL} if it is 'top' item (return TRUE
if argument is @code{NULL} if it is 'top' item). Let's call this operation
@code{_NOT_}. Then we will have following table of transformation:

@example
val >  ALL (SELECT...) -> _NOT_ val >= MAX (SELECT...)
val <  ALL (SELECT...) -> _NOT_ val <= MIN (SELECT...)
val >  ANY (SELECT...) ->       val <  MIN (SELECT...)
val <  ANY (SELECT...) ->       val >  MAX (SELECT...)
val >= ALL (SELECT...) -> _NOT_ val >  MAX (SELECT...)
val <= ALL (SELECT...) -> _NOT_ val <  MIN (SELECT...)
val >= ANY (SELECT...) ->       val <= MIN (SELECT...)
val <= ANY (SELECT...) ->       val >= MAX (SELECT...)
@end example

If subquery does not contain grouping and aggregate function, above subquery
can be rewritten with @code{MAX()}/@code{MIN()} aggregate function, for
example:

@example
val > ANY (SELECT item ...) -> val < (SELECT MIN(item)...)
@end example

For queries with aggregate function and/or grouping, special
@code{Item_maxmin_subselect} will be used. This subquery will return
maximum (minimum) value of result set.


@node transformations singlerow,  , transformations all any, transformations
@section @code{Item_singlerow_subselect}

@code{Item_singlerow_subselect} will be rewritten only if it contains no
@code{FROM} clause, and it is not part of @code{UNION}, and it is a scalar
subquery. For now, there will be no conversion of subqueries with field or
reference on top of item list (on the one hand we can't change the name of
such items, but on the other hand we should assign to it the name of the
whole subquery which will be reduced);

The following will not be reduced:

@example
SELECT a;
SELECT 1 UNION SELECT 2;
SELECT 1 FROM t1;
@end example

The following select will be reduced:

@example
SELECT 1;
SELECT a+2;
@end example

Such a subquery will be completely replaced by its expression from item
list and its @code{SELECT_LEX} and @code{SELECT_LEX_UNIT} will be removed from
@code{SELECT_LEX}'s tree.

But every @code{Item_field} and @code{Item_ref} of that expression will be
marked for processing by a special @code{fix_fields()} procedure. The
@code{fix_fields()} procedures for such @code{Items} will be performed in
the same way as for items of an inner subquery. Also, if this expression is
@code{Item_fields} or @code{Item_ref}, then the name of this new item will
be the same as the name of this item (but not @code{(SELECT ...)}). This is
done to prevent broken references on such items from more inner subqueries.


@node Client/Server Protocol, Replication, transformations, Top
@chapter MySQL Client/Server Protocol

@menu
* raw packet without compression::  Raw Packet Without Compression
* raw packet with compression::  Raw Packet With Compression
* basic packets::               Basic Packets
* communication::               Communication
* fieldtype codes::             Fieldtype Codes
* protocol functions::          Functions Used to Implement the Protocol
* protocol version 2::          Another Description of the Protocol
* 4.1 protocol changes::        Changes to 4.0 Protocol in 4.1
* 4.1 field packet::            4.1 Field Description Packet
* 4.1 field desc::              4.1 Field Description Result Set
* 4.1 OK packet::               4.1 OK Packet
* 4.1 end packet::              4.1 End Packet
* 4.1 error packet::            4.1 Error Packet
* 4.1 prep init::               4.1 Prepared Statement Init Packet
* 4.1 long data::               4.1 Long Data Handling
* 4.1 execute::                 4.1 Execute
* 4.1 binary result::           4.1 Binary Result Set
@end menu

@node raw packet without compression, raw packet with compression, Client/Server Protocol, Client/Server Protocol
@section Raw Packet Without Compression

@example
+-----------------------------------------------+
| Packet Length | Packet no     | Data          |
| 3 Bytes       | 1 Byte        | n Bytes       |
+-----------------------------------------------+
@end example

@table @asis
@item 3 Byte packet length
The length is calculated with int3store
See include/global.h for details.
The max packetsize can be 16MB.

@item 1 Byte packet no
If no compression is used the first 4 bytes of each packet is the header
of the packet. The packet number is incremented for each sent packet.
The first packet starts with 0.
@item n Byte data 

@end table

The packet length can be recalculated with:

@example
length = byte1 + (256 * byte2) + (256 * 256 * byte3)
@end example


@node raw packet with compression, basic packets, raw packet without compression, Client/Server Protocol
@section Raw Packet With Compression

@example
+---------------------------------------------------+
| Packet Length | Packet no | Uncomp. Packet Length |
| 3 Bytes       | 1 Byte    | 3 Bytes               |
+---------------------------------------------------+
@end example

@table @asis
@item 3 Byte packet length
The length is calculated with int3store
See include/global.h for details.
The max packetsize can be 16MB.

@item 1 Byte packet no
@item 3 Byte uncompressed packet length
@end table

If compression is used the first 7 bytes of each packet
is the header of the packet.


@node basic packets, communication, raw packet with compression, Client/Server Protocol
@section Basic Packets

@menu
* OK packet::                   OK Packet
* error packet::                Error Packet
@end menu


@node OK packet, error packet, basic packets, basic packets
@subsection OK Packet

For details, see @file{sql/net_pkg.cc::send_ok()}.

@example
+-----------------------------------------------+
| Header        | No of Rows    | Affected Rows |
|               | 1 Byte        | 1-8 Byte      |
|-----------------------------------------------|
| ID (last_insert_id)   | Status | Length       |
| 1-8 Byte              | 2 Byte | 1-8 Byte     |
|-----------------------------------------------|
| Messagetext                                   |
| n Byte                                        |
+-----------------------------------------------+
@end example

@table @asis
@item Header
@item 1 byte number of rows ? (always 0 ?)
@item 1-8 bytes affected rows
@item 1-8 byte id (last_insert_id) 
@item 2 byte Status (usually 0)
@item If the OK-packege includes a message:
@item 1-8 bytes length of message
@item n bytes messagetext
@end table


@node error packet,  , OK packet, basic packets
@subsection Error Packet

@example
+-----------------------------------------------+
| Header        | Status code   | Error no      |
|               | 1 Byte        | 2 Byte        |
|-----------------------------------------------|
| Messagetext                          | 0x00   |
| n Byte                               | 1 Byte |
+-----------------------------------------------+
@end example

@table @asis
@item Header
@item 1 byte status code (0xFF = ERROR)
@item 2 byte error number (is only sent to new 3.23 clients.
@item n byte errortext
@item 1 byte 0x00
@end table


@node communication, fieldtype codes, basic packets, Client/Server Protocol
@section Communication

@example
> Packet from server to client
< Paket from client tor server

	Login
	------
		> 1. packet	
		Header
		1 byte protocolversion
		n byte serverversion
		1 byte 0x00
		4 byte threadnumber 
		8 byte crypt seed 
		1 byte 0x00
		2 byte CLIENT_xxx options (see include/mysql_com.h
			that is supported by the server
		1 byte number of current server charset
		2 byte server status variables (SERVER_STATUS_xxx flags)
		13 byte 0x00 (not used yet).

		< 2. packet	
		Header
		2 byte CLIENT_xxx options
		3 byte max_allowed_packet for the client
		n byte username
		1 byte 0x00
		8 byte crypted password
		1 byte 0x00
		n byte databasename
		1 byte 0x00 

		> 3. packet	
		OK-packet


	Command
	--------
		< 1. packet	
		Header
		1 byte command type (e.g.0x03 = query)
		n byte query

	Result set (after command)
	--------------------------
		> 2. packet	
		Header
		1-8 byte field_count (packed with net_store_length())
		
		If field_count == 0 (command): 
		1-8 byte affected rows
		1-8 byte insert id
		2 bytes server_status (SERVER_STATUS_xx) 		
		
		If field_count == NULL_LENGTH (251)
		LOAD DATA LOCAL INFILE

		If field_count > 0 Result Set:

		> n packets	
		Header Info
		Column description: 5 data object /column
		(See code in unpack_fields())
		
		Columninfo for each column:
			1 data block table_name
			    1 byte length of block
			    n byte data
			1 data block field_name
			    1 byte length of block...
			    n byte data
			1 data block display length of field
			    1 byte length of block
			    3 bytes display length of filed
			1 data block type field of type (enum_field_types)
			    1 byte length of block
			    1 bytexs field of type
			1 data block flags
			    1 byte length of block
			    2 byte flags for the columns (NOT_NULL_FLAG, ZEROFILL_FLAG....)
			    1 byte decimals

		if table definition:
			1 data block default value

		Actual result (one packet per row):
		4 byte header
		1-8 byte length of data
		n data
@end example
 
@node fieldtype codes, protocol functions, communication, Client/Server Protocol
@section Fieldtype Codes

@example
                display_length  |enum_field_type        |flags
                ----------------------------------------------------
Blob            03 FF FF 00     |01 FC                  |03 90 00 00
Mediumblob      03 FF FF FF     |01 FC                  |03 90 00 00
Tinyblob        03 FF 00 00     |01 FC                  |03 90 00 00
Text            03 FF FF 00     |01 FC                  |03 10 00 00
Mediumtext      03 FF FF FF     |01 FC                  |03 10 00 00
Tinytext        03 FF 00 00     |01 FC                  |03 10 00 00
Integer         03 0B 00 00     |01 03                  |03 03 42 00
Mediumint       03 09 00 00     |01 09                  |03 00 00 00
Smallint        03 06 00 00     |01 02                  |03 00 00 00
Tinyint         03 04 00 00     |01 01                  |03 00 00 00
Varchar         03 XX 00 00     |01 FD                  |03 00 00 00
Enum            03 05 00 00     |01 FE                  |03 00 01 00
Datetime        03 13 00 00     |01 0C                  |03 00 00 00
Timestamp       03 0E 00 00     |01 07                  |03 61 04 00
Time            03 08 00 00     |01 0B                  |03 00 00 00
Date            03 0A 00 00     |01 0A                  |03 00 00 00
@end example

@node protocol functions, protocol version 2, fieldtype codes, Client/Server Protocol
@section Functions Used to Implement the Protocol

@c This should be merged with the above one and changed to texi format

@example

Raw packets
-----------

- The my_net_xxxx() functions handles the packaging of a stream of data
  into a raw packet that contains a packet number, length and data.

- This is implemented for the server in sql/net_serv.cc.
  The client file, libmysql/net.c, is symlinked to this file

The important functions are:

my_net_write()		Store a packet (= # number of bytes) to be sent
net_flush()		Send the packets stored in the buffer
net_write_command()	Send a command (1 byte) + packet to the server.
my_net_read()		Read a packet


Include files
-------------

- include/mysql.h is included by all MySQL clients.  It includes the
  MYSQL and MYSQL_RES structures.
- include/mysql_com.h is include by mysql.h and mysql_priv.h (the
  server) and includes a lot of common functions and structures to
  handle the client/server protocol.


Packets from server to client:
-----------------------------

sql/net_pkg.cc:

 - Sending of error packets
 - Sending of OK packets (= end of data)
 - Storing of values in a packet


sql/sql_base.cc:

 - Function send_fields() sends the field description to the client.

sql/sql_show.cc:

 - Sends results for a lot of SHOW commands, including:
   SHOW DATABASES [like 'wildcard']
   SHOW TABLES    [like 'wildcard']


Packets from client to server:
------------------------------

This is done in libmysql/libmysql.c

The important ones are:

- mysql_real_connect()          Connects to a mysqld server
- mysql_real_query()            Sends a query to the server and
                                reads the OK packet or columns header.
- mysql_store_result()          Read a result set from the server to memory
- mysql_use_result()            Read a result set row by row from the server.

- net_safe_read()               Read a packet from the server with
                                error handling.
- net_field_length()            Reads the length of a packet string.
- simple_command()              Sends a command/query to the server.



Connecting to mysqld (the MySQL server)
---------------------------------------

- On the client side: libmysql/libmysql.c::mysql_real_connect().
- On the server side: sql/sql_parse.cc::check_connections()

The packets sent during a connection are as follows

Server:  Send greeting package (includes server capabilites, server
	 version and a random string of bytes to be used to scramble
	 the password.
Client:  Sends package with client capabilites, user name, scrambled
	 password, database name

Server:  Sends ok package or error package.

Client:  If init command specified, send it t the server and read
	 ok/error package.


Password functions
------------------

The passwords are scrambled to a random number and are stored in hex
format on the server.

The password handling is done in sql/password.c. The important
function is 'scramble()', which takes the a password in clear text
and uses this to 'encrypt' the random string sent by the server
to a new message.

The encrypted message is sent to the server which uses the stored
random number password to encrypt the random string sent to the
client. If this is equal to the new message the client sends to the
server then the password is accepted.
@end example

@node protocol version 2, 4.1 protocol changes, protocol functions, Client/Server Protocol
@section Another Description of the Protocol

@c This should be merged with the above one and changed to texi format.

@example
*****************************
*
* PROTOCOL OVERVIEW
*
*****************************

The MySQL protocol is relatively simple, and is designed for high performance 
through minimization of overhead, and extensibility through versioning and 
options flags. It is a request-response protocol, and does not allow 
multitasking or multiplexing over a single connection. There are two packet
formats, 'raw' and 'compressed' (which is used when both client and
server support zlib compression, and the client requests that data be
compressed):

* RAW PACKET, shorter than 16 M *

+-----------------------------------------------+
| Packet Length | Packet no     | Data          |
| 3 Bytes       | 1 Byte        | n Bytes       |
+-----------------------------------------------+
^                               ^
|          'HEADER'             |
+-------------------------------+


 * Packet Length: Calculated with int3store. See include/global.h for 
                  details. The basic computation is length = byte1 + 
                  (256 * byte2) + (256 * 256 * byte3). The max packetsize 
                  can be 16MB.

 * Packet no:     The packet number is incremented for each sent packet.
                  The first packet for each query from the client
		  starts with 0.

 * Data:          Specific to the operation being performed. Most often
                  used to send string data, such as a SQL query.

* COMPRESSED PACKET *

+---------------------------------------------------+-----------------+
| Packet Length | Packet no | Uncomp. Packet Length | Compressed Data |
| 3 Bytes       | 1 Byte    | 3 Bytes               | n bytes         |
+---------------------------------------------------+-----------------+
^                                                   ^
|                   'HEADER'                        |
+---------------------------------------------------+
 
 * Packet Length: Calculated with int3store. See include/my_global.h for 
                  details. The basic computation is length = byte1 + 
                  (256 * byte2) + (256 * 256 * byte3). The max packetsize 
                  can be 16MB.

 * Packet no:     The packet number is incremented for each sent packet.
                  The first packet starts with 0.

 * Uncomp. Packet Length: The length of the original, uncompressed packet
   If this is zero then the data is not compressed.
   
 * Compressed Data: The original packet, compressed with zlib compression


When using the compressed protocol, the client/server will only compress
send packets where the new packet is smaller than the not compressed one.
In other words, some packets may be compressed while others will not.

The 'compressed data' is one or more packets in *RAW PACKET* format.

*****************************
*
* FLOW OF EVENTS
*
*****************************

To understand how a client communicates with a MySQL server, it is easiest 
to start with a high-level flow of events. Each event section will then be
followed by details of the exact contents of each type of packet involved
in the event flow.

*                          *
* CONNECTION ESTABLISHMENT *
*                          *

Clients connect to the server via a TCP/IP socket (port 3306 by default), a 
Unix Domain Socket, or named pipes (on Windows). Once connected, the 
following connection establishment sequence is followed:

+--------+                                                           +--------+
| Client |                                                           | Server |
+--------+                                                           +--------+
    |                                                                     |
    |    Handshake initialisation, including MySQL server version,        |
    |    protocol version and options supported, as well as the seed      |
    |    for the password hash                                            |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |
    |    Client options supported, max packet size for client             |
    |    username, password crypted with seed from server, database       |
    |    name.                                                            |
    |                                                                     |
    |   -------------------------------------------------------------->   |
    |                                                                     |
    |    'OK' packet if authentication succeeds, 'ERROR' packet if        |
    |    authentication fails.                                            |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |



* HANDSHAKE INITIALISATION PACKET *


+--------------------------------------------------------------------+
| Header        | Prot. Version | Server Version String | 0x00       |  
|               | 1 Byte        | n bytes		| 1 byte     |
|--------------------------------------------------------------------|
| Thread Number | Crypt Seed | 0x00    | CLIENT_xxx options          |
|               |            |         | supported by server         |
| 4 Bytes       | 8 Bytes    | 1 Byte  | 2 Bytes                     |
|--------------------------------------------------------------------|
| Server charset no.  | Server status variables | 0x00 padding       |
| 1 Byte              | 2 Bytes                 | 13 bytes           |
+--------------------------------------------------------------------+

 * Protocol version (currently '10')
 * Server Version String (e.g. '4.0.5-beta-log').  Can be any length as
   it's followed by a 0 byte.
 * Thread Number - ID of server thread handling this connection
 * Crypt seed - seed used to crypt password in auth packet from client
 * CLIENT_xxx options - see include/mysql_com.h
 * Server charset no. - Index of charset in use by server
 * Server status variables - see include/mysql_com.h
 * The padding bytes are reserverd for future extensions to the protocol

* CLIENT AUTH PACKET *


+--------------------------------------------------------------------+
| Header        | CLIENT_xxx options supported | max_allowed_packet  |
|               | by client                    | for client          |
|               | 4 Bytes                      | 4 bytes             |
|--------------------------------------------------------------------|
| Character set | Reserved for the future			     |
| 1 Bytes       | 23 bytes                                           |
|--------------------------------------------------------------------|
| User Name | 0x00   | Crypted Password | 0x00   | Database Name     |
| n Bytes   | 1 Byte | 8 Bytes          | 1 Byte | n Bytes           |
|--------------------------------------------------------------------|
| 0x00                                                               |
| 1 Byte                                                             |
+--------------------------------------------------------------------+

 * CLIENT_xxx options that this client supports:

#define CLIENT_LONG_PASSWORD    1       /* new more secure passwords */
#define CLIENT_FOUND_ROWS       2       /* Found instead of affected rows */
#define CLIENT_LONG_FLAG        4       /* Get all column flags */
#define CLIENT_CONNECT_WITH_DB  8       /* One can specify db on connect */
#define CLIENT_NO_SCHEMA        16      /* Don't allow database.table.column */
#define CLIENT_COMPRESS         32      /* Can use compression protocol */
#define CLIENT_ODBC             64      /* Odbc client */
#define CLIENT_LOCAL_FILES      128     /* Can use LOAD DATA LOCAL */
#define CLIENT_IGNORE_SPACE     256     /* Ignore spaces before '(' */
#define CLIENT_INTERACTIVE      1024    /* This is an interactive client */
#define CLIENT_SSL              2048     /* Switch to SSL after handshake */
#define CLIENT_IGNORE_SIGPIPE   4096     /* IGNORE sigpipes */
#define CLIENT_TRANSACTIONS     8192    /* Client knows about transactions */

 * max_allowed_packet for the client (in 'int3store' form)
 * User Name - user to authenticate as.  Is followed by a null byte.
 * Crypted Password - password crypted with seed given in packet from
                      server, see scramble() in sql/password.c
 * Database name (optional) - initial database to use once connected
   Is followed by a null byte

At the end of every client/server exchange there is either an 'OK' packet
or an 'ERROR' packet sent from the server. To determine whether a packet is
an 'OK' packet, or an 'ERROR' packet, check if the first byte (after the 
header) is 0xFF. If it has the value of 0xFF, the packet is an 'ERROR'
packet.


* OK PACKET *

For details, see sql/net_pkg.cc::send_ok()

+-----------------------------------------------+
| Header        | No of Rows    | Affected Rows |
|               | 1 Byte        | 1-9 Byte      |
|-----------------------------------------------|
| ID (last_insert_id)   | Status | Length       |
| 1-9 Byte              | 2 Byte | 1-9 Byte     |
|-----------------------------------------------|
| Messagetext                                   |
| n Byte                                        |
+-----------------------------------------------+

 * Number of rows, always 0 
 * Affected rows
 * ID (last_insert_id) - value for auto_increment column (if any) 
 * Status (usually 0)

In general, in the MySQL protocol, fields in a packet that that 
represent numeric data, such as lengths, that are labeled as '1-9' 
bytes can be decoded by the following logic:

	If the first byte is '251', the
        corresponding column value is NULL (only appropriate in 
        'ROW DATA' packets).

	If the first byte is '252', the value stored can be read
        from the following 2 bytes as a 16-bit integer.
                

        If the first byte is '253' the value stored can be read
        from the following 4 bytes as a 32-bit long integer

          
        If the first byte is '254', the value stored can be read
        from the following 8 bytes as a 64-byte long
                
	Otherwise (values 0-250), the value stored is the value of the
	first byte itself.


If the OK-packet includes a message:

 * Length of message
 * Message Text


* ERROR PACKET *

+-----------------------------------------------+
| Header        | Status code   | Error no      |
|               | 1 Byte        | 2 Byte        |
|-----------------------------------------------|
| Messagetext                          |        |
| n Byte                               |        |
+-----------------------------------------------+

 * Status code (0xFF = ERROR)
 * Error number (is only sent to 3.23 and newer clients)
 * Error message text (ends at end of packet)

Note that the error message is not null terminated.
The client code can however assume that the packet ends with a null
as my_net_read() will always add an end-null to all read packets to
make things easier for the client.

Example:

Packet dump of client connecting to server:

+------------------------- Protocol Version (10)
|
|  +---------------------- Server Version String (0x00 terminated)
|  |
|  |
0a 34 2e 30 2e 35 2d 62     . 4 . 0 . 5 - b 
65 74 61 2d 6c 6f 67 00     e t a - l o g . 
15 00 00 00 2b 5a 65 6c     . . . . + Z e l 
 |           |
 |           +------------ First 4 bytes of crypt seed
 | 
 +------------------------ Thread Number

+------------------------- Last 4 bytes of crypt seed
|
|                +-------- CLIENT_XXX Options supported by server
|                |
|              +-+--+ +--- Server charset index
|              |    | |
6f 69 41 46 00 2c 28 08     o i A F . , ( . 
02 00 00 00 00 00 00 00     . . . . . . . . 
|  |
|  +---------------------- 0x00 padding begins
|
+------------------------- Server status (0x02 = 
                           SERVER_STATUS_AUTOCOMMIT)

00 00 00 00 00 00 00 00     . . . . . . . . 

* Client Authentication Response (Username 'test', no database
  selected) *

    +--------------------- Packet Length (0x13 = 19 bytes)
    |
    |     +--------------- Packet Sequence #
    |     |
    |     |   +----------- CLIENT_XXX Options supported by client 
          |   |
+---+---+ | +-+-+
|       | | |   |
13 00 00 01 03 00 1e 00     . . . . . . . . 
00 74 65 73 74 00 48 5e     . t e s t . H ^
   |          |   |
   +----+-----+   +------- Scrambled password, 0x00 terminated
        |
        +----------------- Username, 0x00 terminated
  
57 4a 4e 41 4a 4e 00 00     W J N A J N . . 
00                          . 


>From this point on, the server waits for 'commands' from the client
which include queries, database shutdown, quit, change user, etc (see
the COM_xxxx values in include/mysql_com.h for the latest 
command codes). 

*                    *
* COMMAND PROCESSING *
*                    *

+--------+                                                           +--------+
| Client |                                                           | Server |
+--------+                                                           +--------+
    |                                                                     |
    |    A command packet, with a command code, and string data           |
    |    when appropriate (e.g. a query), (see the COM_xxxx values        |
    |    in include/mysql_com.h for the command codes)                    |
    |                                                                     |
    |   -------------------------------------------------------------->   |
    |                                                                     |
    |    A 'RESULT' packet if the command completed successfully,         |
    |    an 'ERROR' packet if the command failed. 'RESULT' packets        |
    |    take different forms (see the details following this chart)      |
    |    depending on whether or not the command returns rows.            |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |
    |    n 'FIELD PACKET's (if rows are returned)                         |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |
    |    'LAST DATA' packet                                               |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |
    |    n 'ROW PACKET's (if rows are returned)                           |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |
    |    'LAST DATA' packet                                               |
    |                                                                     |
    |   <--------------------------------------------------------------   |
    |                                                                     |


* Command Packet *

+------------------------------------------------------+
| Header        | Command type | Query (if applicable) |
|               | 1 Byte       | n Bytes               |
+------------------------------------------------------+

 * Command type:  (e.g.0x03 = query, see the COM_xxxx values in 
                   include/mysql_com.h)
 * Query (if applicable)

Note that my_net_read() null-terminates all packets on the
receiving side of the channel to make it easier for the code
examining the packets.

The current command codes are:

   0x00   COM_SLEEP
   0x01   COM_QUIT
   0x02   COM_INIT_DB
   0x03   COM_QUERY
   0x04   COM_FIELD_LIST
   0x05   COM_CREATE_DB
   0x06   COM_DROP_DB
   0x07   COM_REFRESH
   0x08   COM_SHUTDOWN
   0x09   COM_STATISTICS
   0x0a   COM_PROCESS_INFO
   0x0b   COM_CONNECT
   0x0c   COM_PROCESS_KILL
   0x0d   COM_DEBUG
   0x0e   COM_PING
   0x0f   COM_TIME
   0x10   COM_DELAYED_INSERT
   0x11   COM_CHANGE_USER
   0x12   COM_BINLOG_DUMP
   0x13   COM_TABLE_DUMP 
   0x14   COM_CONNECT_OUT
   0x15   COM_REGISTER_SLAVE

* Result Packet *

Result packet for a command returning _no_ rows:

+-----------------------------------------------+
| Header        | Field Count   | Affected Rows |
|               | 1-9 Bytes     | 1-9 Bytes     |
|-----------------------------------------------|
| ID (last_insert_id)   | Server Status         |
| 1-9 Bytes             | 2 Bytes               |
+-----------------------------------------------+

 * Field Count: Has value of '0' for commands returning _no_ rows
 * Affected rows: Count of rows affected by INSERT/UPDATE/DELETE, etc.
 * ID: value of auto_increment column in row (if any).  0 if 
 * Server Status: Usually 0

Result packet for a command returning rows:

+-------------------------------+
| Header        | Field Count   |
|               | 1-9 Bytes     |
+-------------------------------+

 * Field Count: number of columns/fields in result set,
                 (packed with net_store_length() in sql/net_pkg.cc)

This is followed by as many packets as the number of fields ('Field Count')
that contain the metadata for each column/field (see unpack_fields() in 
libmysql/libmysql.c):


* FIELD PACKET *

+-----------------------------------------------+
| Header        | Table Name		        |
|               | length-coded-string           |
|-----------------------------------------------|
| Field Name					|
| length-code-string				|
|-----------------------------------------------|
| Display length of field
| length-coded-binary (4 bytes)			|
|-----------------------------------------------|
| Field Type (enum_field_types in mysql_com.h)  |
| length-coded-binary (2 bytes)			|
|-----------------------------------------------|
| Field Flags	                | Decimal Places|
| length-coded-binary (3 bytes) | 1 Byte        |
+--------------+-------------+------------------+

 * A length coded string is a string where we first have a packet
   length (1-9 bytes, packed_with net_store_length()) followed
   by a string.
 * A length coded binary is a length (1 byte) followed by an integer
   value in low-byte-first order.  For the moment this type is always
   fixed length in this packet.

 * Table Name - the name of the table the column comes from
 * Field Name - the name of the column/field
 * Display length of field - length of field
 * Field Type - Type of field, see enum_field_types in 
                include/mysql_com.h

   Current field types are:

      0x00   FIELD_TYPE_DECIMAL 
      0x01   FIELD_TYPE_TINY
      0x02   FIELD_TYPE_SHORT  
      0x03   FIELD_TYPE_LONG
      0x04   FIELD_TYPE_FLOAT  
      0x05   FIELD_TYPE_DOUBLE
      0x06   FIELD_TYPE_NULL
      0x07   FIELD_TYPE_TIMESTAMP
      0x08   FIELD_TYPE_LONGLONG
      0x09   FIELD_TYPE_INT24
      0x0a   FIELD_TYPE_DATE   
      0x0b   FIELD_TYPE_TIME
      0x0c   FIELD_TYPE_DATETIME
      0x0d   FIELD_TYPE_YEAR
      0x0e   FIELD_TYPE_NEWDATE
      0xf7   FIELD_TYPE_ENUM
      0xf8   FIELD_TYPE_SET
      0xf9   FIELD_TYPE_TINY_BLOB
      0xfa   FIELD_TYPE_MEDIUM_BLOB
      0xfb   FIELD_TYPE_LONG_BLOB
      0xfc   FIELD_TYPE_BLOB
      0xfd   FIELD_TYPE_VAR_STRING
      0xfe   FIELD_TYPE_STRING
      0xff   FIELD_TYPE_GEOMETRY

 * Field Flags - NOT_NULL_FLAG, PRI_KEY_FLAG, xxx_FLAG in 
                 include/mysql_com.h


Note that the packet format in 4.1 has slightly changed to allow more values.


* ROW PACKET *

+-----------------------------------------------+
| Header        | Data Length   | Column Data   | ....for each column
|               | 1-9 Bytes     | n Bytes       |
+-----------------------------------------------+

 * Data Length: (packed with net_store_length() in sql/net_pkg.cc)
                
		If 'Data Length' == 0, this is an 'ERROR PACKET'.
		
 * Column Data: String representation of data. MySQL always sends result set
                data as strings.

* LAST DATA PACKET *

Packet length is < 9 bytes, and first byte is 0xFE

+--------+
| 0xFE   |
| 1 Byte |
+--------+

Examples:

***********
*
* INITDB Command
*
***********

A client issuing an 'INITDB' (select the database to use) command,
followed by an 'OK' packet with no rows and no affected rows from
the server:

* INITDB (select database to use) 'COMMAND' Packet *

    +--------------------- Packet Length (5 bytes)
    |
    |     +--------------- Packet Sequence #
    |     |
    |     |  +------------ Command # (INITDB = 0x02)
          |  |
+---+---+ |  | +---------- Beginning of query data
|       | |  | |
05 00 00 00 02 74 65 73     . . . . . t e s 
74                          t 

* 'OK' Packet with no rows, and no rows affected *

    +--------------------- Packet Length (3 bytes)
    |
    |     +--------------- Packet Sequence #
    |     | 
+---+---+ |
|       | |
03 00 00 01 00 00 00        . . . . . . .


***********
*
* SELECT query example
*
***********

Client issuing a 'SELECT *' query on the following table:

    CREATE TABLE number_test (minBigInt bigint, 
                              maxBigInt bigint, 
                              testBigInt bigint)

* 'COMMAND' Packet with QUERY (select ...) *

    +--------------------- Packet Length (26)
    |
    |     +--------------- Packet Sequence #
    |     |
    |     |  +------------ Command # (QUERY = 0x03)
          |  |
+---+---+ |  | +---------- Beginning of query data
|       | |  | |
1a 00 00 00 03 53 45 4c     . . . . . S E L 
45 43 54 20 2a 20 66 72     E C T . * . f r 
6f 6d 20 6e 75 6d 62 65     o m . n u m b e 
72 5f 74 65 73 74           r _ t e s t 


and receiving an 'OK' packet with a 'FIELD COUNT' of 3


* 'OK' Packet with 3 fields *

    +--------------------- Packet Length (3 bytes)
    |
    |     +--------------- Packet Sequence #
    |     | 
+---+---+ |
|       | |
01 00 00 01 03              . . . . . 

Followed immediately by 3 'FIELD' Packets. Note, the individual packets 
are delimitted by =======, so that all fields can be annotated in the first
'FIELD' packet example:

=============================================================

    +--------------------- Packet Length (0x1f = 31 bytes)
    |
    |     +--------------- Packet Sequence #
    |     | 
    |     |  +------------ Block Length (0x0b = 11 bytes)
    |     |  |   
+---+---+ |  |  +--------- Table Name (11 bytes long)
|       | |  |  |
1f 00 00 02 0b 6e 75 6d     . . . . . n u m  
62 65 72 5f 74 65 73 74     b e r _ t e s t 

 +------------------------ Block Length (9 bytes)
 |
 |  +--------------------- Column Name (9 bytes long)
 |  |
09 6d 69 6e 42 69 67 49     . m i n B i g I     
6e 74 03 14 00 00 01 08     n t . . . . . .
       | |       | |  |
       | +---+---+ |  +--- Field Type (0x08 = FIELD_TYPE_LONGLONG)
       |     |     |
       |     |     +------ Block Length (1)
       |     |
       |     +--------------- Display Length (0x14 = 20 chars)
       |
       +------------------ Block Length (3)

 +------------------------ Block Length (2)
 |
 |   +-------------------- Field Flags (0 - no flags set)
 |   | 
 | +---+  +--------------- Decimal Places (0)
 | |   |  |
02 00 00 00                 . . . .                                  

=============================================================

'FIELD' packet for the 'number_Test.maxBigInt' column

1f 00 00 03 0b 6e 75 6d     . . . . . n u m
62 65 72 5f 74 65 73 74     b e r _ t e s t
09 6d 61 78 42 69 67 49     . m a x B i g I
6e 74 03 14 00 00 01 08     n t . . . . . .
02 00 00 00                 . . . .
        
=============================================================                    

'FIELD' packet for the 'number_test.testBigInt' column

20 00 00 04 0b 6e 75 6d     . . . . . n u m
62 65 72 5f 74 65 73 74     b e r _ t e s t 
0a 74 65 73 74 42 69 67     . t e st B i g
49 6e 74 03 14 00 00 01     I n t . . . . .
08 02 00 00 00              . . . . .
============================================================= 

Followed immediately by one 'LAST DATA' packet:

fe 00                       . .

Followed immediately by 'n' row packets (in this case, only
one packet is sent from the server, for simplicity's sake):


    +--------------------- Packet Length (0x52 = 82 bytes)
    |
    |     +--------------- Packet Sequence #
    |     | 
    |     |  +------------ Data Length (0x14 = 20 bytes)
    |     |  |   
+---+---+ |  |  +--------- String Data '-9223372036854775808'
|       | |  |  |          (repeat Data Length/Data sequence)

52 00 00 06 14 2d 39 32     . . . . . - 9 2
32 33 33 37 32 30 33 36     2 3 3 7 2 0 3 6
38 35 34 37 37 35 38 30     8 5 4 7 7 5 8 0
38 13 39 32 32 33 33 37     8 . 9 2 2 3 3 7
32 30 33 36 38 35 34 37     2 0 3 6 8 5 4 7
37 35 38 30 37 0a 36 31     7 5 8 0 7 . 6 1
34 37 34 38 33 36 34 37     4 7 4 8 3 6 4 7

Followed immediately by one 'LAST DATA' packet:

fe 00                       . .
@end example


@c The Index was empty, and ugly, so I removed it. (jcole, Sep 7, 2000)

@c @node Index
@c @unnumbered Index

@c @printindex fn

@c @node 4.1 protocol,,,
@c @chapter MySQL 4.1 protocol

@node 4.1 protocol changes, 4.1 field packet, protocol version 2, Client/Server Protocol
@section Changes to 4.0 Protocol in 4.1

All basic packet handling is identical to 4.0. When communication
with an old 4.0 or 3.x client we will use the old protocol.

The new things that we support with 4.1 are:

@itemize @bullet
@item
Warnings
@item
Prepared statements
@item
Binary protocol (is be faster than the current protocol that
converts everything to strings)
@end itemize


What has changed in 4.1 are:

@itemize @bullet
@item
A lot of new field information (catalog, database, real table name etc)
@item
The 'ok' packet has more status fields
@item
The 'end' packet (send last for each result set) now contains some
extra information
@item
New protocol for prepared statements.  In this case all parameters and
results will sent as binary (low-byte-first).
@end itemize


@node 4.1 field packet, 4.1 field desc, 4.1 protocol changes, Client/Server Protocol
@section 4.1 Field Description Packet

The field description packet is sent as a response to a query that
contains a result set.  It can be distinguished from an OK packet by
the fact that the first byte can't be 0 for a field packet.
@xref{4.1 OK packet}.

The header packet has the following structure:

@multitable @columnfractions .10 .90
@item Size @tab Comment
@item 1-9  @tab Number of columns in result set (never 0)
@item 1-9  @tab Extra information sent be some command (SHOW COLUMNS
uses this to send the number of rows in the table)
@end multitable

This packet is always followed by a field description set.
@xref{4.1 field desc}.

@node 4.1 field desc, 4.1 OK packet, 4.1 field packet, Client/Server Protocol
@section 4.1 Field Description Result Set

The field description result set contains the meta info for a result set.

@multitable @columnfractions .20 .80
@item Type   @tab Comment
@item string @tab Catalog name (for 5.x)
@item string @tab Database name
@item string @tab Table name alias (or table name if no alias)
@item string @tab Real table name
@item string @tab Alias for column name (or column name if not used)

@item 12 byte @tab Fixed length fields in one field part:
@itemize @bullet
@item 2 byte int - Character set number
@item 4 byte int - Length of column definition
@item 1 byte int - Enum value for field type
@item 3 byte int - 2 byte column flags (NOT_NULL_FLAG etc..) + 1 byte number of decimals.
@item 2 byte int - zero (reserved for future use)
@end itemize

@item string int @tab Default value, only set when using mysql_list_fields().
@end multitable


@node 4.1 OK packet, 4.1 end packet, 4.1 field desc, Client/Server Protocol
@section 4.1 OK Packet

The OK packet is the first that is sent as an response for a query
that didn't return a result set.

The OK packet has the following structure:

@multitable @columnfractions .10 .90
@item Size @tab Comment
@item 1	  @tab  0 ; Marker for OK packet
@item 1-9 @tab	Affected rows
@item 1-9 @tab  Last insert id (0 if one wasn't used)
@item 2   @tab  Server status; Can be used by client to check if we are inside an transaction
@item 2	  @tab  Warning count
@item 1-9 @tab  Message length (optional)
@item xxx @tab  Message (optional)
@end multitable

Size 1-9 means that the parameter is packed in to 1-9 bytes depending on
the value.  (See function sql/net_pkg.cc::net_store_length).

The message is optional.  For example, for multiple-line @code{INSERT}, it
contains a string for how many rows were inserted / deleted.


@node 4.1 end packet, 4.1 error packet, 4.1 OK packet, Client/Server Protocol
@section 4.1 End Packet

The end packet is sent as the last packet for

@itemize @bullet
@item
End of field information
@item
End of parameter type information
@item
End of result set
@end itemize

The end packet has the following structure:

@multitable @columnfractions .10 .90
@item Size @tab Comment
@item 1	   @tab 254  ; Marker for EOF packet
@item 2	   @tab Warning count
@item 2	   @tab Status flags (For flags like SERVER_STATUS_MORE_RESULTS)
@end multitable

Note that a normal packet may start with byte 254, which means
'length stored in 9 bytes'.  One can different between these cases
by checking the packet length < 9 bytes (in which case it's and end
packet).


@node 4.1 error packet, 4.1 prep init, 4.1 end packet, Client/Server Protocol
@section 4.1 Error Packet

The error packet is sent when something goes wrong.
The error packet has the following structure:

@multitable @columnfractions .10 .90
@item Size  @tab Comment
@item 1	    @tab 255  Error packet marker
@item 2	    @tab Error code
@item 1	    @tab '#' marker that SQLSTATE follows
@item 6     @tab SQLSTATE code (000000 for many messages)
@item 1-512 @tab Null terminated error message
@end multitable

The client/server protocol is designed in such a way that a packet
can only start with 255 if it's an error packet.


@node 4.1 prep init, 4.1 long data, 4.1 error packet, Client/Server Protocol
@section 4.1 Prepared Statement Init Packet

The client issues COM_PREPARE packet with statement string to prepare.
The packet has the following format:

@multitable @columnfractions .30 .70
@item Size @tab Comment
@item 1 byte            @tab COM_PREPARE packet code
@item #                 @tab Statement string 
@end multitable

This is the server return packet to COM_PREPARE command:
(packet length is always '9').

@multitable @columnfractions .10 .90
@item Size @tab Comment
@item 1    @tab 0 ; Marker for OK packet
@item 4	   @tab Statement handler id
@item 2	   @tab Number of columns in result set
@item 2	   @tab Number of parameters in query
@end multitable

After this, there is a packet that contains the following for each
parameter in the query:

@multitable @columnfractions .10 .90
@item Size @tab Comment
@item 2	@tab Enum value for field type. (MYSQL_TYPE_UNKNOWN if not known)
@item 2 @tab 2 byte column flags (NOT_NULL_FLAG etc)
@item 1 @tab Number of decimals
@item 4 @tab Max column length.
@end multitable

Note that the above is not yet in 4.1 but will be added this month.

As MySQL can have a parameter 'anywhere' it will in many cases not be
able to provide the optimal information for all parameters.

If number of columns, in the header packet, is not 0 then the
prepared statement will contain a result set. In this case the packet
is followed by a field description result set. @xref{4.1 field desc}.


@node 4.1 long data, 4.1 execute, 4.1 prep init, Client/Server Protocol
@section 4.1 Long Data Handling

This is used by mysql_send_long_data() to set any parameter to a string
value.  One can call mysql_send_long_data() multiple times for the
same parameter; The server will concatenate the results to a one big
string.

The server will not require an end packet for the string.
mysql_send_long_data() is responsible updating a flag that all data
has been sent. (Ie;  That the last call to mysql_send_long_data() has
the 'last_data' flag set).

This packet is sent from client -> server:

@multitable @columnfractions .10 .90
@item Size @tab Comment
@item 4	@tab Statement handler
@item 2 @tab Parameter number
@item 2 @tab Type of parameter  (not used at this point)
@item # @tab data (Rest of packet)
@end multitable

The server will NOT send an @code{ok} or @code{error} packet in
responce for this.  If there is any errors (like to big string), one
will get the error when calling execute.

@node 4.1 execute, 4.1 binary result, 4.1 long data, Client/Server Protocol
@section 4.1 Execute

On execute we send all parameters to the server in a COM_EXECUTE
packet.

The packet contains the following information:

@multitable @columnfractions .30 .70
@item Size @tab Comment
@item 1 byte            @tab COM_EXECUTE packet code
@item 4 bytes           @tab statement id
@item 1 byte            @tab Flags, reserved for future use. In 5.0 is used
to send 'open cursor' request to the server.  In 4.1 is always 0.
@item 4 bytes           @tab iteration count. Reserved for future use. In
4.1 is always 1.
@item (param_count+7)/8 @tab Null bit map; if parameter N is null,  
bit @code{1 << (N & 7)} of @code{N/8}th byte is set. 
@item 1	                @tab new_parameter_bound flag.  Is set to 1 for
first execute or if one has rebound the parameters.
@item 2*param_count     @tab Type of parameters (only given if
new_parameter_bound flag is 1). Each type is encoded in first 15 bits
(low-byte-first), the last bit is set if type is unsigned.
@item #                 @tab Parameter data, repeated for each parameter
that are NOT NULL and not used with mysql_send_long_data().
@end multitable

The null-bit-map is for all parameters (including parameters sent with
'mysql_send_long_data). If parameter 0 is NULL, then bit 0 in the
null-bit-map should be 1 (ie:  first byte should be 1)

The parameters are stored the following ways:

@multitable @columnfractions .20 .10 .70
@item Type    @tab Size @tab Comment
@item tinyint @tab 1	@tab One byte integer
@item short   @tab 2	@tab
@item int     @tab 4	@tab
@item longlong @tab 8	@tab
@item float   @tab 4	@tab
@item double  @tab 8	@tab
@item string  @tab 1-9 + # @tab Packed string length + string
@end multitable

The result for this will be either an OK packet or a binary result
set.

@node 4.1 binary result,  , 4.1 execute, Client/Server Protocol
@section 4.1 Binary Result Set

A binary result are sent the following way.

For each result row:

@itemize @bullet
@item
null bit map with first two bits set to 01 (bit 0,1 value 1)
@item
parameter data, repeated for each not null result column.
@end itemize

The idea with the reserving two bits in the null map is that we can
use standard error (first byte 255) and OK packets (first byte 0)
to end a result sets.

Except that the null-bit-map is shifted two steps, the server is
sending the data to the client the same way that the server is sending
bound parameters to the client.  The server is always sending the data
as type given for 'column type' for respective column.  It's up to the
client to convert the parameter to the requested type.

DATETIME, DATE and TIME are sent to the server in a binary format as follows:

@multitable @columnfractions .20 .10 .70
@item Type    @tab Size @tab Comment
@item date    @tab 1 + 0-11 @tab Length + 2 byte year, 1 byte MMDDHHMMSS, 4 byte billionth of a second
@item datetime    @tab 1 + 0-11 @tab Length + 2 byte year, 1 byte MMDDHHMMSS, 4 byte billionth of a second
@item time    @tab 1 + 0-14 @tab Length + sign (0 = pos, 1= neg), 4 byte days, 1 byte HHMMDD, 4 byte billionth of a second
@end multitable

The first byte is a length byte and then comes all parameters that are
not 0. (Always counted from the beginning).

@node Replication, MyISAM Record Structure, Client/Server Protocol, Top
@chapter Replication

@menu
* Replication files::           Main Code Files
* Replication binary log::      The Binary Log
* Replication threads::         Replication Threads
* Replication deals with::      How Replication Deals With...
* Replication event sending::   How a Slave Asks Its Master to Send Its Binary Log
* Replication packets::         Network Packets in Detail
* Replication event format::    Replication Event Format in Detail
* Replication plans::           Plans for MySQL 5.0
@end menu

This chapter describes MySQL replication principles and code, as
it is in version 4.1.1.

MySQL replication works like this: Every time the master executes
a query that updates data (@code{UPDATE}, @code{INSERT},
@code{DELETE}, etc.), it packs this query into an @strong{event}, which
consists of the query plus a few bytes of information
(timestamp, thread id of the thread which issued the query etc.,
defined later in this chapter). Then the master writes this event to a
file (the ``binary log''). When the slave is connected, the master
re-reads its binary log and sends the events to the slaves. The slave
unpacks the event and executes the query.

@node Replication files, Replication binary log, Replication, Replication
@section Main Code Files

These file are all in the @file{sql} directory:

@itemize @bullet
@item @file{log.cc}: creating/writing/deleting a binlog.
@item @file{log_event.*}: all event types and their methods.
@item @file{slave.*}: all the slave threads' code.
@item @file{sql_repl.*}: all SQL commands related to replication
(@code{START SLAVE}, @code{CHANGE MASTER TO}). Also all the master's
high-level code about replication (binlog sending,
a.k.a. @code{COM_BINLOG_DUMP}). For example, binlog sending code is in
@file{sql_repl.cc}, but uses low-level commands (single event reading)
which are in @file{log_event.cc}.
@item @file{repl_failsafe.*}: unfinished code about failsafe
(master election if the primary master fails). This file will probably
be heavily reworked. Presently it's almost unused.
@end itemize

@node Replication binary log, Replication threads, Replication files, Replication
@section The Binary Log

When started with @code{--log-bin}, @code{mysqld} creates a binary log
(``binlog'')
of all updates. Only updates that really change the data are
written (a @code{DELETE} issued on an empty table won't be written to
the binary log). Every query is written in a packed form: an event.
The binary log is
a sequence of @strong{events}.
The @file{mysqlbinlog} utility can be used to print human-readable
data from the binary log.

@example
[guilhem@@gbichot2 1]$ mysqlbinlog gbichot2-bin.005
# at 4
#030710 21:55:35 server id 1  log_pos 4         Start: binlog v 3, server v 4.0.14-debug-log created 030710 21:55:35 at startup
# at 79
#030710 21:55:59 server id 1  log_pos 79        Query   thread_id=2     exec_time=16    error_code=0
SET TIMESTAMP=1057866959;
drop database test;
# at 128
#030710 21:56:20 server id 1  log_pos 128       Query   thread_id=2     exec_time=0     error_code=0
SET TIMESTAMP=1057866980;
create database test;
# at 179
#030710 21:57:00 server id 1  log_pos 179       Query   thread_id=2     exec_time=1     error_code=0
use test;
SET TIMESTAMP=1057867020;
create table u(a int primary key, b int, key(b), foreign key (b) references u(a));
# at 295
#030710 21:57:19 server id 1  log_pos 295       Query   thread_id=2     exec_time=0     error_code=0
SET TIMESTAMP=1057867039;
drop table u;
# at 342
#030710 21:57:24 server id 1  log_pos 342       Query   thread_id=2     exec_time=0     error_code=0
SET TIMESTAMP=1057867044;
create table u(a int primary key, b int, key(b), foreign key (b) references u(a)) type=innodb;
# at 470
#030710 21:57:52 server id 1  log_pos 470       Query   thread_id=2     exec_time=0     error_code=0
SET TIMESTAMP=1057867072;
insert into u values(4,NULL);
# at 533
#030710 21:57:59 server id 1  log_pos 533       Query   thread_id=2     exec_time=0     error_code=0
SET TIMESTAMP=1057867079;
insert into u values(3,4);
# at 593
#030710 21:58:34 server id 1  log_pos 593       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1057867114;
delete from u;
# at 641
#030710 21:58:57 server id 1  log_pos 641       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1057867137;
drop table u;
# at 688
#030710 21:59:18 server id 1  log_pos 688       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1057867158;
create table v(c int primary key) type=innodb;
# at 768
#030710 21:59:24 server id 1  log_pos 768       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1057867164;
create table u(a int primary key, b int, key(b), foreign key (b) references v(c)) type=innodb;
# at 896
#030710 21:59:47 server id 1  log_pos 896       Query   thread_id=8     exec_time=0     error_code=0
SET TIMESTAMP=1057867187;
DROP TABLE IF EXISTS u;
# at 953
#030710 21:59:47 server id 1  log_pos 953       Query   thread_id=8     exec_time=0     error_code=0
SET TIMESTAMP=1057867187;
CREATE TABLE u (
  a int(11) NOT NULL default '0',
  b int(11) default NULL,
  PRIMARY KEY  (a),
  KEY b (b),
  CONSTRAINT `0_41` FOREIGN KEY (`b`) REFERENCES `v` (`c`)
) TYPE=InnoDB;
# at 1170
#030710 21:59:47 server id 1  log_pos 1170      Query   thread_id=8     exec_time=0     error_code=0
SET TIMESTAMP=1057867187;
DROP TABLE IF EXISTS v;
# at 1227
#030710 21:59:47 server id 1  log_pos 1227      Query   thread_id=8     exec_time=0     error_code=0
SET TIMESTAMP=1057867187;
CREATE TABLE v (
  c int(11) NOT NULL default '0',
  PRIMARY KEY  (c)
) TYPE=InnoDB;
# at 1345
#030710 22:00:06 server id 1  log_pos 1345      Query   thread_id=9     exec_time=0     error_code=0
SET TIMESTAMP=1057867206;
drop table u,v;
# at 1394
#030710 22:00:29 server id 1  log_pos 1394      Query   thread_id=13    exec_time=0     error_code=0
SET TIMESTAMP=1057867229;
create table v(c int primary key) type=innodb;
# at 1474
#030710 22:00:32 server id 1  log_pos 1474      Query   thread_id=13    exec_time=0     error_code=0
SET TIMESTAMP=1057867232;
create table u(a int primary key, b int, key(b), foreign key (b) references v(c)) type=innodb;
# at 1602
#030710 22:00:44 server id 1  log_pos 1602      Query   thread_id=16    exec_time=0     error_code=0
SET TIMESTAMP=1057867244;
drop table v,u;
# at 1651
#030710 22:00:51 server id 1  log_pos 1651      Query   thread_id=16    exec_time=0     error_code=0
SET TIMESTAMP=1057867251;
CREATE TABLE v (
  c int(11) NOT NULL default '0',
  PRIMARY KEY  (c)
) TYPE=InnoDB;
# at 1769
#030710 22:12:50 server id 1  log_pos 1769      Stop
@end example

Here are the possible types of events:

@example
enum Log_event_type
@{
  START_EVENT = 1, QUERY_EVENT =2, STOP_EVENT=3, ROTATE_EVENT = 4,
  INTVAR_EVENT=5, LOAD_EVENT=6, SLAVE_EVENT=7, CREATE_FILE_EVENT=8,
  APPEND_BLOCK_EVENT=9, EXEC_LOAD_EVENT=10, DELETE_FILE_EVENT=11,
  NEW_LOAD_EVENT=12, RAND_EVENT=13, USER_VAR_EVENT=14
@};

enum Int_event_type
@{
  INVALID_INT_EVENT = 0, LAST_INSERT_ID_EVENT = 1, INSERT_ID_EVENT = 2
@};
@end example

@table @code

@item START_EVENT

Written when @code{mysqld} starts.

@item STOP_EVENT

Written when @code{mysqld} stops.

@item QUERY_EVENT

Written when an updating query is done.

@item ROTATE_EVENT

Written when @code{mysqld} switches to a
new binary log (because someone issued @code{FLUSH LOGS} or the
current binary log's size becomes too large.
The maximum size is determined as described in @ref{Slave I/O thread}.

@item CREATE_FILE_EVENT

Written when a @code{LOAD DATA INFILE} statement starts.

@item APPEND_BLOCK_EVENT

Written for each loaded block.

@item DELETE_FILE_EVENT

Written if the load finally failed

@item EXECUTE_LOAD_EVENT

Written if the load finally succeeded.

@item SLAVE_EVENT

Not used yet.

@item INTVAR_EVENT, RAND_EVENT, USER_VAR_EVENT

Written every time a query or @code{LOAD DATA} used them. They are written
together with the @code{QUERY_EVENT} or the events written by the @code{LOAD
DATA INFILE}. @code{INTVAR_EVENT} is in fact two types:
@code{INSERT_ID_EVENT} and @code{LAST_INSERT_ID_EVENT}.

@item INSERT_ID_EVENT

Used to tell the slave the value that should be used for an
@code{auto_increment} column for the next query.

@item LAST_INSERT_ID_EVENT

Used to tell the slave the value that should be used for the
@code{LAST_INSERT_ID()} function if the next query uses it.

@item RAND_EVENT

Used to tell the slave the value it should use for the @code{RAND()}
function if the next query uses it.

@item USER_VAR_EVENT

Used to tell the slave the value it should use for a user variable if the
next query uses it.

@end table

The event's format is described in detail in @ref{Replication event format}.

There is a C++ class for every type of event (@code{class Query_log_event}
etc).
Prototypes are in @file{sql/log_event.h}.
Code for methods of these classes is in @file{log_event.cc}.
Code to create, write, rotate, or delete a binary log is in @file{log.cc}.

@node Replication threads, Replication deals with, Replication binary log, Replication
@section Replication Threads

@menu
* Slave I/O thread::            The Slave I/O Thread
* Slave SQL thread::            The Slave SQL Thread
* Replication two threads::     Why 2 Threads?
* Replication Binlog Dump thread::  The @code{Binlog Dump} Thread
@end menu

Every time replication is started on the slave @code{mysqld}, i.e.
when @code{mysqld} is started with some replication options
(@code{--master-host=this_hostname} etc.) or some
existing @code{master.info} and @code{relay-log.info} files, or when
the user does @code{START SLAVE} on the slave, two threads are
created on the slave, in @file{slave.cc}:

@example
extern "C" pthread_handler_decl(handle_slave_io,arg)
@{ ... @}

extern "C" pthread_handler_decl(handle_slave_sql,arg)
@{ ... @}
@end example

@node Slave I/O thread, Slave SQL thread, Replication threads, Replication threads
@subsection The Slave I/O Thread

The I/O thread connects to the master using a user/password.
When it has managed to connect, it asks the master for its binary
logs:

@example
    thd->proc_info = "Requesting binlog dump";
    if (request_dump(mysql, mi, &suppress_warnings))
@end example

Then it enters this loop:

@example
    while (!io_slave_killed(thd,mi))
    @{
      <cut>
      thd->proc_info = "Reading master update";
      ulong event_len = read_event(mysql, mi, &suppress_warnings);
      <cut>
      thd->proc_info = "Queueing event from master";
      if (queue_event(mi,(const char*)mysql->net.read_pos + 1,
                      event_len))
      @{
        sql_print_error("Slave I/O thread could not queue event
                         from master");
        goto err;
      @}
      flush_master_info(mi);
      if (mi->rli.log_space_limit && mi->rli.log_space_limit <
          mi->rli.log_space_total &&
          !mi->rli.ignore_log_space_limit)
        if (wait_for_relay_log_space(&mi->rli))
        @{
          sql_print_error("Slave I/O thread aborted while
                           waiting for relay log space");
          goto err;
        @}
      <cut>
    @}
@end example

@code{read_event()} calls @code{net_safe_read()} to read what the
master has sent over the network. @code{queue_event()} writes the read
event to the relay log, and also updates the counter which keeps track
of the space used by all existing relay
logs. @code{flush_master_info()} writes to the @file{master.info} file
the new
position up to which the thread has read in the master's binlog. Finally, if
relay logs take too much space, the I/O thread blocks until the SQL
thread signals it's okay to read and queue more events.
The @code{<cut>} code handles network failures and reconnections.

When the relay log gets too large,
it is ``rotated'': The I/O thread stops writing to it, closes it,
opens a new relay log and writes to the new one. The old one is kept,
until the SQL thread (see below) has finished executing it, then it is
deleted.
The meaning of ``too large'' is determined as follows:

@itemize @bullet
@item
@code{max_relay_log_size}, if @code{max_relay_log_size} > 0
@item
@code{max_binlog_size}, if @code{max_relay_log_size} = 0
or MySQL is older than 4.0.14
@end itemize

@node Slave SQL thread, Replication two threads, Slave I/O thread, Replication threads
@subsection The Slave SQL Thread

@example
  while (!sql_slave_killed(thd,rli))
  @{
    thd->proc_info = "Processing master log event";
    DBUG_ASSERT(rli->sql_thd == thd);
    THD_CHECK_SENTRY(thd);
    if (exec_relay_log_event(thd,rli))
    @{
      // do not scare the user if SQL thread was simply killed or stopped
      if (!sql_slave_killed(thd,rli))
        sql_print_error("Error running query, slave SQL thread
                         aborted. Fix the problem, and restart
                         the slave SQL thread with "SLAVE START".
                         We stopped at log '%s' position %s",
                         RPL_LOG_NAME, llstr(rli->master_log_pos, llbuff));
      goto err;
    @}
  @}
@end example

@code{exec_relay_log_event()} reads an event from the relay log (by calling
@code{next_event()}). @code{next_event()} will start reading the next relay
log file if the current one is finished; it will also wait if there is
no more relay log to read (because the I/O thread is stopped or the master has
nothing more to send to the slave).
Finally @code{exec_relay_log_event()} executes the read event
(all @code{::exec_event()} methods in @file{log_event.cc}) (mostly
this execution goes through @code{sql_parse.cc}), thus updating
the slave database and writing to @file{relay-log.info} the new
position up to which it has executed in the relay log.
The @code{::exec_event()} methods in @file{log_event.cc} will take care
of filter options like @code{replicate-do-table} and such.

When the SQL thread hits the end of the relay log, it checks whether a new
one exists (that is, whether a rotation has occurred). If so, it deletes the
already-read relay log and starts reading the new one. Otherwise, it just
waits until there's more data in the relay log.

@node Replication two threads, Replication Binlog Dump thread, Slave SQL thread, Replication threads
@subsection Why 2 Threads?

In MySQL 3.23, we had only one thread on the slave, which did the whole
job: read one event from the connection to the master, executed it,
read another event, executed it, etc.

In MySQL 4.0.2 we split the job into two threads, using a relay log file
to exchange between them.

This makes code more complicated. We have to deal with the relay log
being written at the end, read at another position, at the same time.
Plus handling the detection of EOF on the relay log, switching to the
new relay log. Also the SQL thread must do different reads, depending
on whether the relay log it is reading

@itemize @bullet
@item
is being written to by the I/O thread;
then the relay log is partly in memory, not all on disk, and mutexes
are needed to avoid confusion between threads.
@item
has already been rotated (the I/O thread is not writing to
it anymore), in which case it is a normal file that no other threads
touches.
@end itemize

The advantages of having 2 threads instead of one:
@itemize @bullet
@item
@strong{Helps having a more up-to-date slave}.
Reading a query is fast, executing it is slow.
If the master dies (burns), there are good chances that the I/O thread has
caught almost all updates issued on the master, and saved them in the
relay log, for use by the SQL thread.
@item
@strong{Reduces the required master-slave connection time}.
If the slave has not been connected for a long time, it is very
late compared to the master. It means the SQL thread will have a lot
of executing to do. So with the single-thread read-execute-read-execute
technique, the slave will have to be connected for a long time to be
able to fetch all updates from the master. Which is stupid, as for a
significant part of the time, the connection will be idle, because the
single thread is busy executing the query.
Whereas with 2 threads, the I/O thread will fetch the binlogs from the
master in a shorter time. Then the connection is not needed anymore,
and the SQL thread can continue executing the relay log.
@end itemize

@node Replication Binlog Dump thread,  , Replication two threads, Replication threads
@subsection The @code{Binlog Dump} Thread

This thread is created by the master when it receives a
@code{COM_BINLOG_DUMP} request.

@example
void mysql_binlog_send(THD* thd, char* log_ident, my_off_t pos,
                       ushort flags)
@{
  <cut>
  if ((file=open_binlog(&log, log_file_name, &errmsg)) < 0)
  @{
    my_errno= ER_MASTER_FATAL_ERROR_READING_BINLOG;
    goto err;
  @}
  if (pos < BIN_LOG_HEADER_SIZE || pos > my_b_filelength(&log))
  @{
    errmsg= "Client requested master to start replication from
             impossible position";
    my_errno= ER_MASTER_FATAL_ERROR_READING_BINLOG;
    goto err;
  @}

  my_b_seek(&log, pos);                 // Seek will done on next read
  <cut>
  // if we are at the start of the log
  if (pos == BIN_LOG_HEADER_SIZE)
  @{
    // tell the client log name with a fake rotate_event
    if (fake_rotate_event(net, packet, log_file_name, &errmsg))
    @{
      my_errno= ER_MASTER_FATAL_ERROR_READING_BINLOG;
      goto err;
    @}
    <cut>
  @}

  while (!net->error && net->vio != 0 && !thd->killed)
  @{
    pthread_mutex_t *log_lock = mysql_bin_log.get_log_lock();

    while (!(error = Log_event::read_log_event(&log, packet, log_lock)))
    @{
      <cut>
      if (my_net_write(net, (char*)packet->ptr(), packet->length()) )
      @{
        errmsg = "Failed on my_net_write()";
        my_errno= ER_UNKNOWN_ERROR;
        goto err;
      @}
      <cut>
@end example

If this thread starts reading from the beginning of a binlog, it is
possible that the slave does not know the binlog's name (for example
it could have just asked ``give me the FIRST binlog''). Using
@code{fake_rotate_event()}, the master
tells the slave the binlog's name (required for @file{master.info} and
@code{SHOW SLAVE STATUS}) by building a @code{Rotate_log_event} and
sending this event to the slave. In this event the slave will find the
binlog's name. This event has zeros in the timestamp (shows up as
written in year ``1970'' when reading the relay log with @code{mysqlbinlog}).

@node Replication deals with, Replication event sending, Replication threads, Replication
@section How Replication Deals With...

@menu
* Replication auto-increment::  @code{auto_increment} Columns, @code{LAST_INSERT_ID()}
* Replication user variables::  User Variables (Since 4.1)
* Replication system variables::  System Variables
* Replication misc functions::  Some Functions
* Replication UDF functions::   Non-repeatable UDF Functions
* Replication prepared statements::  Prepared Statements
* Replication temp tables::     Temporary Tables
* Replication load data::       @code{LOAD DATA [LOCAL] INFILE} (Since 4.0)
@end menu

This section describes how replication handles various problematic issues.

@node Replication auto-increment, Replication user variables, Replication deals with, Replication deals with
@subsection @code{auto_increment} Columns, @code{LAST_INSERT_ID()}

When a query inserts into such a column, or uses
@code{LAST_INSERT_ID()}, one or two @code{Intvar_log_event} are
written to the binlog just before the @code{Query_log_event}.

@node Replication user variables, Replication system variables, Replication auto-increment, Replication deals with
@subsection User Variables (Since 4.1)

When a query uses a user variable, a @code{User_var_log_event} is
written to the binlog just before the @code{Query_log_event}.

@node Replication system variables, Replication misc functions, Replication user variables, Replication deals with
@subsection System Variables

Example: @code{SQL_MODE}, @code{FOREIGN_KEY_CHECKS}. Not dealt
with. Guilhem is working on it for version 5.0.

@node Replication misc functions, Replication UDF functions, Replication system variables, Replication deals with
@subsection Some Functions

@code{USER()}, @code{LOAD_FILE()}. Not dealt
with. Will be solved with row-level binlogging (presently we have
query-level binlogging, but in the future we plan to support row-level
binlogging too).

@node Replication UDF functions, Replication prepared statements, Replication misc functions, Replication deals with
@subsection Non-repeatable UDF Functions

``Non repeatable'' means that they have a sort of randomness, for
example they depend on the machine (to generate a unique ID for example).
Not dealt with. Will be solved with row-level binlogging.

@node Replication prepared statements, Replication temp tables, Replication UDF functions, Replication deals with
@subsection Prepared Statements

For the moment, a substituted normal query is written to the master's
binlog. Using prepared statements on the slave as well is on the TODO.

@node Replication temp tables, Replication load data, Replication prepared statements, Replication deals with
@subsection Temporary Tables

Temporary tables depend on the thread which created them, so any query
event which uses such tables is marked with the
@code{LOG_EVENT_THREAD_SPECIFIC_F} flag. All events have in their
header the id of the thread which created them, so the slave knows
which temporary table the query refers to.

When the slave is stopped (@code{STOP SLAVE} or even @code{mysqladmin
shutdown}), the in-use replicated temporary tables are not dropped (like
clients' temporary tables are). This way, when the slave restarts they
are still available.

When a connection using temporary tables terminates on the master, the
master automatically writes some @code{DROP TEMPORARY TABLE} statements for
them so that they are dropped on the slave as well.

When the master brutally dies, then restarts, it drops all temporary
tables which remained in @code{tmpdir}, but without writing it to the
binlog, so these temporary tables are still on the slave, and they
will not be dropped before the next slave's @code{mysqld} restart. To
avoid this, the slave drops all replicated temporary tables when it
executes a @code{Start_log_event} read from the master. Indeed such an
event means the master's @code{mysqld} has restarted so all preceding
temporary tables have been dropped.

Presently we have a bug: if the slave @code{mysqld} is stopped while it was
replicating a temporary table, then at restart it deletes this table (like a
normal temporary table), which may cause a problem if subsequent queries on
the master refer to this table.


@node Replication load data,  , Replication temp tables, Replication deals with
@subsection @code{LOAD DATA [LOCAL] INFILE} (Since 4.0)

The master writes the loaded file to the binlog, but in small blocks rather
than all at once.  The slave creates a temporary file, the concatenation of
each block. When the slave reads the final @code{Execute_load_log_event}, it
loads all temporary files into the table and deletes the temporary files. If
the final event was instead a @code{Delete_file_log_event} then these
temporary files are deleted without loading.

@node Replication event sending, Replication packets, Replication deals with, Replication
@section How a Slave Asks Its Master to Send Its Binary Log

The slave server
must open a normal connection to its master. The MySQL account used
to connect to the master must have the @code{REPLICATION SLAVE}
privilege on the master.
Then the slave must send the @code{COM_BINLOG_DUMP} command, as in this
example taken from function @code{request_dump()}:

@example
static int request_dump(MYSQL* mysql, MASTER_INFO* mi,
                        bool *suppress_warnings)
@{
  char buf[FN_REFLEN + 10];
  int len;
  int binlog_flags = 0; // for now
  char* logname = mi->master_log_name;
  DBUG_ENTER("request_dump");

  // TODO if big log files: Change next to int8store()
  int4store(buf, (longlong) mi->master_log_pos);
  int2store(buf + 4, binlog_flags);
  int4store(buf + 6, server_id);
  len = (uint) strlen(logname);
  memcpy(buf + 10, logname,len);
  if (simple_command(mysql, COM_BINLOG_DUMP, buf, len + 10, 1))
  @{
     // act on errors
  @}
@}
@end example

Here variable @code{buf} contains the arguments for
@code{COM_BINLOG_DUMP}. It's the concatenation of:

@itemize @bullet
@item 4 bytes:
the position in the master's binlog from which we want to start
(i.e. ``please master send me the binlog, starting from this
position'').
@item 2 bytes:
0 for the moment.
@item 4 bytes:
this slave's server id. This is used by the master to delete old
@code{Binlog Dump} threads which were related to this slave (see
function @code{kill_zombie_dump_threads()} for details).
@item variable-sized part:
the name of the binlog we want. The dump will start from this binlog,
at the position indicated in the first four bytes.
@end itemize

Then send the command, and start reading the incoming packets from the
master, like @code{read_event()} does (using @code{net_safe_read()}
like explained below).
One should also, to be safe, handle all possible cases of network
problems, disconnections/reconnections, malformed events.

@node Replication packets, Replication event format, Replication event sending, Replication
@section Network Packets in Detail

The communication protocol between the master and
slave is the one that all other normal connections use, as described earlier
in this document.
@xref{Client/Server Protocol}.
So after the @code{COM_BINLOG_DUMP} command has been
sent, the communication between the master and slave is
a sequence of packets, each of which contains an event. In
@code{slave.cc}, function @code{read_event()}, one has an example:
@code{net_safe_read()} is called; it is able to detect wrong
packets. After @code{net_safe_read()}, the event is ready to be
interpreted; it starts at pointer @code{(char*) mysql->net.read_pos +
1}. That is, @code{(char*) mysql->net.read_pos + 1} is the first byte of
the event's timestamp, etc.

@node Replication event format, Replication plans, Replication packets, Replication
@section Replication Event Format in Detail

@menu
* Replication common header::   The Common Header
* Replication event headers::   The ``Post-headers'' (Event-specific Headers)
@end menu

@node Replication common header, Replication event headers, Replication event format, Replication event format
@subsection The Common Header

Each event starts with a header of size @code{LOG_EVENT_HEADER_LEN=19}
(defined in @file{log_event.h}), which contains:

@table @strong

@item timestamp
4 bytes, seconds since 1970.

@item event type
1 byte. 1 means @code{START_EVENT}, 2 means @code{QUERY_EVENT}, etc (these
numbers are defined in an @code{enum Log_event_type} in @file{log_event.h}).

@item server ID
4 bytes. The server ID of the @code{mysqld} which created this
event. When using circular replication (with option
@code{--log-slave-updates} on), we use this server ID to avoid
endless loops. Suppose tthat M1, M2, and M3 have server ID values of 1, 2, and
3, and that they are replicating in circular fashion:
M1 is the master for M2, M2 is the master for M3, and M3 is that master for
M1. The master/server relationships look like this:

@example
M1---->M2
^      |
|      |
+--M3<-+
@end example

A client sends an @code{INSERT} query to M1. Then this is executed on
M1, then written in the binary log of M1, and the event's server ID is
1. The event is sent to M2, which executes it and writes it to the
binary log of M2; the event written still has server ID 1 (because
that is the ID of the server that originally created the event).
The event is sent to M3,
which executes it and writes it to the binary log of M3, with server ID
1. This last event is sent to M1, which sees ``server ID = 1'' and
understands this event comes from itself, so has to be ignored.

@item event total size
4 bytes. Size of this event in bytes. Most events are 10-1000 bytes,
except when using @code{LOAD DATA INFILE} (where events contain the
loaded file, so they can be big).

@item position of the event in the binary log
4 bytes. Offset in bytes of the event in the binary log, as returned by
@code{tell()}. It is the offset in the binary log where this event was
created @code{in the first place}. That is, it is copied as-is to the
relay log.
It is used on the slave, for @code{SHOW SLAVE STATUS} to be able to show
coordinates of the last executed event @strong{in the master's coordinate
system}. If this value were not stored in the event, we could not know these
coordinates because the slave cannot invoke @code{tell()} for the master's
binary log.

@item flags
2 bytes of flags. Almost unused for now. The only one which is used
in 4.1 is @code{LOG_EVENT_THREAD_SPECIFIC_F}, which is used only by
@file{mysqlbinlog} (not by the replication code at all) to be able to
deal properly with temporary tables. @file{mysqlbinlog} prints
queries from the binary log, so that one can feed these queries into
@file{mysql} (the command-line interpreter), to achieve incremental
backup recovery.
But if the binary log looks like this:
@example
<thread id 1>
create temporary table t(a int);
<thread id 2>
create temporary table t(a int)
@end example
(two simultaneous threads used temporary tables with the same name,
which is allowed as temporary tables are visible only in the thread
which created them),
then simply feeding this into @file{mysql} will lead to the ``table t
already exists'' error.
This is why events which use temporary tables are marked with the
flag, so that @file{mysqlbinlog} knows it has to set the
pseudo_thread_id before, like this:
@example
SET PSEUDO_THREAD_ID=1;
create temporary table t(a int);
SET PSEUDO_THREAD_ID=2;
create temporary table t(a int);
@end example
This way there is no confusion for the server which receives these
queries.
Always printing @code{SET PSEUDO_THREAD_ID}, even when temporary
tables are not used, would cause no bug, it would just slow down.
@end table

@node Replication event headers,  , Replication common header, Replication event format
@subsection The ``Post-headers'' (Event-specific Headers)

After the common header, each event has an event-specific header
of fixed size (0 or more bytes) and a variable-sized part (0 or
more bytes). It's easy for the slave to know the size of the variable-sized
part: it is the event's size (contained in the common header) minus
the size of the common header, minus the size of the event-specific
header.

@table @code

@item START_EVENT
In MySQL 4.0 and 4.1, such events are written only for the first binary log
since @code{mysqld} startup. Binlogs created afterwards (by
@code{FLUSH LOGS}) do not contain this event.
In MySQL 5.0 we will change this; all binary logs will start with a
@code{START_EVENT}, but there will be a way to distinguish between a
@code{START_EVENT} created at @code{mysqld} startup and other
@code{START_EVENT}s; such distinction is needed because the first
category of @code{START_EVENT}, which means the master has started,
should trigger some cleaning tasks on the slave (suppose the master
died brutally and restarted: the slave must delete old replicated
temporary tables).

@itemize @bullet

@item 2 bytes:
The binary log format version. This is 3 in MySQL 4.0 and
4.1; it will be 4 in MySQL 5.0.

@item 50 bytes:
The MySQL server's version (example: 4.0.14-debug-log).

@item 4 bytes:
Timestamp in seconds when this event was created (this is the
moment when the binary log was created). In fact this is useless
information as we already have the timestamp in the common header, so
this useless timestamp should NOT be used, because we plan to change
its meaning soon.

@item No variable-sized part.

@end itemize

@item QUERY_EVENT

@itemize @bullet

@item 4 bytes:
The thread ID of the thread that issued this query. Needed
for temporary tables. This is also useful for a DBA for knowing who
did what on the master.

@item 4 bytes:
The time in seconds which the query took for execution. Only
useful for inspection by the DBA.

@item 1 byte:
The length of the name of the database which was the default
database when the query was executed (later in the event we store this
name; this is necessary for queries like @code{INSERT INTO t
VALUES(1)} which don't specify the database, relying on the default
database previously selected by @code{USE}).

@item 2 bytes:
The error code which the query got on the master. Error codes
are defined in @file{include/mysqld_error.h}. 0 means no error. How
come queries with a non-zero error code can exist in the binary log? This
is mainly due to the non-transactional nature of @code{MyISAM} tables. If an
@code{INSERT SELECT} fails after inserting 1000 rows
(for example, with a duplicate-key violation),
then we have to write this query to the binary log, because it truly
modified the @code{MyISAM} table. For transactional tables, there should be no
event with a non-zero error code (though it can happen, for example if
the connection was interrupted (Control-C)).
The slave checks the error code: After executing the query itself, it
compares the error code it got with the error code in the event, and
if they are different it stops replicating (unless
@code{--slave-skip-errors} was used).

@item Variable-sized part:
The concatenation of the name of the default database
(null-terminated) and the query.
The slave knows the size of the name of the default database (it's in
the event-specific header) so by subtraction it can know the size of
the query.

@end itemize

@item STOP_EVENT
No event-specific header, no variable-sized part. It just means
``Stop'' and the event's type says it all. This event is purely for
informational purposes, it is not even queued into the relay log.

@item ROTATE_EVENT
This event is information for the slave to know the name of the next
binary log it is going to receive.

@itemize @bullet

@item 8 bytes:
Useless, alway contains the number 4 (meaning the next event starts at
position 4 in the next binary log).

@item variable-sized part:
The name of the next binary log.

@end itemize

@item INTVAR_EVENT

@itemize @bullet

@item 8 bytes:
the value to be used for the @code{auto_increment} counter or
@code{LAST_INSERT_ID()}. 8 bytes corresponds to the size of MySQL's @code{BIGINT} type.

@item No variable-sized part.

@end itemize

@item LOAD_EVENT
This is an event for internal use. One should only need to be able to
read @code{CREATE_FILE_EVENT} (see below).

@item SLAVE_EVENT
This event is never written so it cannot exist in a binlog. It was
meant for failsafe replication which will be reworked.

@item CREATE_FILE_EVENT
@code{LOAD DATA INFILE} is not written to the binlog like other queries;
it is written in the form of a @code{CREATE_FILE_EVENT}; the command
does not appear in clear-text in the binlog, it's in a packed format.
This event tells the slave to create a temporary file and fill it with
a first data block. Later, zero or more
@code{APPEND_BLOCK_EVENT} events append blocks to this temporary
file. @code{EXEC_LOAD_EVENT} tells the slave to load the temporary
file into the table, or @code{DELETE_FILE_EVENT} tells the slave
not to do the load and to delete the temporary file.
@code{DELETE_FILE_EVENT} occurs is when the
@code{LOAD DATA} failed on the master: on the master we start to write
loaded blocks to the binlog before the end of the command. If for
some reason there is an error, we have to tell the slave to abort the
load.
The format for this event is more complicated than for others, because
the command has many options. Unlike other events, fixed headers and
variable-sized parts are intermixed; this is due to the history of the
@code{LOAD DATA INFILE} command.

@itemize @bullet

@item 4 bytes:
The thread ID of the thread that issued this @code{LOAD DATA INFILE}. Needed
for temporary tables. This is also useful for a DBA for knowing who
did what on the master.

@item 4 bytes:
The time in seconds which the @code{LOAD DATA INFILE} took for execution. Only
useful for inspection by the DBA.

@item 4 bytes:
The number of lines to skip at the beginning of the file (option
@code{IGNORE number LINES} of @code{LOAD DATA INFILE}).

@item 1 byte:
The size of the name of the table which is to be loaded.

@item 1 byte:
The size of the name of the database where this table is.

@item 4 bytes:
The number of columns to be loaded (option
@code{(col_name,...)}). Will be non-zero only if the columns to load
were explicitly mentioned in the command.

@item 4 bytes:
An ID for this file (1, 2, 3, etc). This is necessary in case several
@code{LOAD DATA INFILE} commands have been run in parallel on the
master: in that case the binlog contains events for the first command
and for the second command intermixed; the ID is used to resolve to
which file the blocks in @code{APPEND_BLOCK_EVENT} must be appended,
and which file must be loaded by the @code{EXEC_LOAD_EVENT} event, and
which file must be deleted by the @code{DELETE_FILE_EVENT}.

@item 1 byte:
The size of the field-terminating string (@code{FIELDS TERMINATED BY}
option).

@item variable-sized part:
The field-terminating string (null-terminated).

@item 1 byte:
The size of the field-enclosing string (@code{FIELDS ENCLOSED BY}
option).

@item variable-sized part:
The field-enclosing string (null-terminated).

@item 1 byte:
The size of the line-terminating string (@code{LINES TERMINATED BY}
option).

@item variable-sized part:
The line-terminating string (null-terminated).

@item 1 byte:
The size of the line-starting string (@code{LINES STARTING BY}
option).

@item variable-sized part:
The line-starting string (null-terminated).

@item 1 byte:
The size of the escaping string (@code{FIELDS ESCAPED BY}
option).

@item variable-sized part:
The escaping string (null-terminated).

@item 1 byte:
Flags: @code{OPT_ENCLOSED_FLAG} (@code{FIELD OPTIONALLY ENCLOSED BY}
option), @code{REPLACE_FLAG} (@code{LOAD DATA INFILE REPLACE}),
@code{IGNORE_FLAG} (@code{LOAD DATA INFILE IGNORE}),
@code{DUMPFILE_FLAG} (unused).
All these are defined in @file{log_event.h}.

@item 1 byte:
The size of the name of the first column to load.

@item etc

@item 1 byte:
The size of the name of the last column to load.

@item Variable-sized part:
The name of the first column to load (null-terminated).

@item etc

@item Variable-sized part:
The name of the last column to load (null-terminated).

@item Variable-sized part:
The name of the table which is to be loaded (null-terminated).

@item Variable-sized part:
The name of the database containing the table (null-terminated).

@item Variable-sized part:
The name of the file which was loaded (that's the original name, from
the master) (null-terminated).

@item Variable-sized part:
The block of raw data to load.
@end itemize

Here is a concrete example:
@example
On the master we have file '/m/tmp/u.txt' which contains:
>1,2,3
>4,5,6
>7,8,9
>10,11,12

And we issue this command on the master:
load data infile '/m/tmp/u.txt' replace into table x fields
terminated by ',' optionally enclosed by '"' escaped by '\\'
lines starting by '>' terminated by '\n' ignore 2 lines (a,b,c);

Then in the master's binlog we have this event (hexadecimal dump):
00000180:                     db4f 153f 0801 0000  .........O.?....
00000190: 006f 0000 0088 0100 0000 0004 0000 0000  .o..............
000001a0: 0000 0002 0000 0001 0403 0000 0003 0000  ................
000001b0: 0001 2c01 2201 0a01 3e01 5c06 0101 0161  ..,."...>.\....a
000001c0: 0062 0063 0078 0074 6573 7400 2f6d 2f74  .b.c.x.test./m/t
000001d0: 6d70 2f75 2e74 7874 003e 312c 322c 330a  mp/u.txt.>1,2,3.
000001e0: 3e34 2c35 2c36 0a3e 372c 382c 390a 3e31  >4,5,6.>7,8,9.>1
000001f0: 302c 3131 2c31 32db 4f15 3f0a 0100 0000  0,11,12.O.?.....
00000200: 1700 0000 f701 0000 0000 0300 0000       ..............
@end example

@itemize @bullet
@item
Line 180: timestamp db4f153f, event's type (08), server id (01 0000
00).
@item
Line 190: event's size (6f 0000 00), position in the binlog (88 0100
00) (that's 392 in decimal base), flags (00 00), thread id (04 0000
00), time it took (00 0000 00).
@item
Line 1a0: number of lines to skip at the beginning of the file (02
0000 00), size of the table's name (01), size of the database's name
(04), number of columns to load (03 0000 00), the file's id (03 0000
00).
@item
Line 1b0: size of the field terminating string (01), field terminating
string (2c i.e. ,), size of the field enclosing string (01),
field enclosing string (22 i.e. "), size of the line
terminating string (01), line terminating string (0a i.e. newline),
size of the line starting string (01), line starting string (3e
i.e. >), size of the escaping string (01), escaping string (5c
i.e. backslash), flags (06) (that's @code{OPT_ENCLOSED_FLAG} |
@code{REPLACE_FLAG}), size of the name of the first column to load
(01), size of the name of the second column to load (01), size of the
name of the third column to load (01), name of the first column to
load (61 00 i.e. "a").
@item
Line 1c0: name of the second column to load (62 00), name of the third
column to load (63 00), name of the table to load (78 00), name of the
database to load (74 6573 7400), name of the file loaded on the master (2f6d
2f74 6d70 2f75 2e74 7874 00).
@item
Line 1d0 and following: raw data to load (3e 312c 322c 330a 3e34 2c35
2c36 0a3e 372c 382c 390a 3e31 302c 3131 2c31 32). The next byte is the
beginning of the @code{EXEC_LOAD_EVENT} event.
@end itemize


@item APPEND_BLOCK_EVENT

@itemize @bullet

@item 4 bytes:
The ID of the file this block should be appended to.

@item Variable-sized part:
the raw data to load.

@end itemize

@item EXEC_LOAD_EVENT

@itemize @bullet

@item 4 bytes:
the ID of the file to be loaded.

@item No variable-sized part.

@end itemize

@item DELETE_FILE_EVENT

@itemize @bullet

@item 4 bytes:
The ID of the file to be deleted.

@item No variable-sized part.

@end itemize

@item NEW_LOAD_EVENT
For internal use.

@item RAND_EVENT
@code{RAND()} in MySQL uses 2 seeds to compute the random number.
@itemize @bullet

@item 8 bytes:
Value for the first seed.
@item 8 bytes:

Value for the second seed.
@item No variable-sized part.


@end itemize

@item USER_VAR_EVENT

@itemize @bullet

@item 4 bytes:
the size of the name of the user variable.

@item variable-sized part:
A concatenation. First is the name of the user variable.
Second is one byte, non-zero if the content of the variable is the SQL
value @code{NULL}, ASCII 0 otherwise.
If this bytes was ASCII 0, then the following parts exist in the event.
Third is one byte, the type of the user variable, which corresponds to
elements of @code{enum Item_result} defined in
@file{include/mysql_com.h}.
Fourth is 4 bytes, the number of the character set of the user
variable (needed for a string variable).
Fifth is 4 bytes, the size of the user variable's value (corresponds
to member @code{val_len} of class @code{Item_string}).
Sixth is variable-sized: for a string variable it is the string, for a
float or integer variable it is its value in 8 bytes.
@end itemize

@end table

@node Replication plans,  , Replication event format, Replication
@section Plans for MySQL 5.0

We plan (Guilhem is presently working on it) to add more information
in the events. For example, the number of rows the query modified.
We also plan to have a more dynamic binlog format, i.e. if we need to
add 1 more byte in the header, replication between an old and a new
server would still be possible.

@node MyISAM Record Structure, The .MYI file, Replication, Top
@chapter @code{MyISAM} Record Structure

@menu
* MyISAM introduction::         Introduction
* MyISAM column attributes::    Physical Attributes of Columns
* MyISAM more information::     Where to Look For More Information
@end menu

@node MyISAM introduction, MyISAM column attributes, MyISAM Record Structure, MyISAM Record Structure
@section Introduction

When you say:

@example
CREATE TABLE Table1 ...
@end example

MySQL creates files named @file{Table1.MYD} ("MySQL Data"), @file{Table1.MYI}
("MySQL Index"), and @file{Table1.frm} ("Format"). These files will be in the
directory:

@example
/<datadir>/<database>/
@end example

For example, if you use Linux, you might find the files in the
@file{/usr/local/var/test} directory (assuming
your database name is @code{test}).
if you use Windows, you might find the files in the
@file{\mysql\data\test\} directory.

Let's look at the @file{.MYD} Data file (@code{MyISAM} SQL Data file) more
closely.  There are three possible formats --- fixed, dynamic, and packed.
First, let's discuss the fixed format.

@table @strong

@item Page Size
Unlike most DBMSs, MySQL doesn't store on disk using pages. Therefore
you will not see filler space between rows. (Reminder: This does not
refer to @code{BDB} and @code{InnoDB} tables, which do use pages).

@item Record Header
The minimal record header is a set of flags:
@itemize @bullet
@item
"X bit"  =  0 if row is deleted, = 1 if row is not deleted
@item
"Null Bits"  =  0 if column is not @code{NULL}, = 1 if column is @code{NULL}
@item
"Filler Bits"  = 1
@end itemize
@end table

The length of the record header is thus:

@example
(1 + number of NULL columns + 7) / 8 bytes
@end example

After the header, all columns are stored in
the order that they were created, which is the
same order that you would get from @code{SHOW COLUMNS}.

Here's an example. Suppose you say:

@example
CREATE TABLE Table1 (column1 CHAR(1), column2 CHAR(1), column3 CHAR(1));
INSERT INTO Table1 VALUES ('a', 'b', 'c');
INSERT INTO Table1 VALUES ('d', NULL, 'e');
@end example

A @code{CHAR(1)} column takes precisely one byte (plus one bit of overhead
that is assigned to every column --- I'll describe the details of
column storage later). So the file @file{Table1.MYD} looks like this:

@strong{Hexadecimal Display of @file{Table1.MYD} file}

@example
F1 61 62 63 00 F5 64 00 66 00              ... .abc..d e.
@end example

Here's how to read this hexadecimal-dump display:

@itemize @bullet
@item
The hexadecimal numbers @code{F1 61 62 63 00 F5 64 20 66 00} are byte
values and the column on the right is an attempt to show the
same bytes in ASCII.
@item
The @code{F1} byte means that there are no null fields in the first row.
@item
The @code{F5} byte means that the second column of the second row is
@code{NULL}.
@end itemize

(It's probably easier to understand the flag setting if you restate
@code{F5} as @code{11110101 binary}, and (a) notice that the third flag bit from the
right is @code{on}, and (b) remember that the first flag bit is the X bit.)

There are complications --- the record header is more complex if there
are variable-length fields --- but the simple display shown in the
example is exactly what you'd see if you looked at the MySQL Data file
with a debugger or a hexadecimal file dumper.

So much for the fixed format. Now, let's discuss the dynamic format.

The dynamic file format is necessary if rows can vary in size. That will be
the case if there are @code{BLOB} columns, or "true" @code{VARCHAR} columns.
(Remember that MySQL may treat @code{VARCHAR} columns as if they're
@code{CHAR} columns, in which case the fixed format is used.) A dynamic row
has more fields in the header.  The important ones are "the actual length",
"the unused length", and "the overflow pointer". The actual length is the
total number of bytes in all the columns. The unused length is the total
number of bytes between one physical record and the next one. The overflow
pointer is the location of the rest of the record if there are multiple
parts.

For example, here is a dynamic row:

@example
03, 00             start of header
04                 actual length
0c                 unused length
01, fc             flags + overflow pointer
****               data in the row
************       unused bytes
                   <-- next row starts here)
@end example

In the example, the actual length and the unused length
are short (one byte each) because the table definition
says that the columns are short --- if the columns were
potentially large, then the actual length and the unused
length could be two bytes each, three bytes each, and so 
on. In this case, actual length plus unused length is 10
hexadecimal (sixteen decimal), which is a minimum.

As for the third format --- packed --- we will only say
briefly that: 
@itemize @bullet
@item
Numeric values are stored in a form that depends on the 
range (start/end values) for the data type.
@item
All columns are packed using either Huffman or enum coding.
@end itemize

For details, see the source files @file{/myisam/mi_statrec.c}
(for fixed format), @file{/myisam/mi_dynrec.c} (for dynamic
format), and @file{/myisam/mi_packrec.c} (for packed format).

Note: Internally, MySQL uses a format much like the fixed format 
which it uses for disk storage. The main differences are:

@enumerate
@item
@code{BLOB} values have a length and a memory pointer rather than being
stored inline.
@item
"True @code{VARCHAR}" (a column storage which will be fully implemented in
version 5.0) will have a 16-bit length plus the data.
@item
All integer or floating-point numbers are stored with the low byte first. 
Point (3) does not apply for @code{ISAM} storage or internals.
@end enumerate


@node MyISAM column attributes, MyISAM more information, MyISAM introduction, MyISAM Record Structure
@section Physical Attributes of Columns

Next I'll describe the physical attributes of each column in a row.
The format depends entirely on the data type and the size of the
column, so, for every data type, I'll give a description and an example.

@c TODO: this should be reformatted - the types each should be preceded
@c by @item, not a blank line.

@table @strong

@item The character data types

@code{CHAR}
@itemize @bullet
@item
Storage: fixed-length string with space padding on the right.
@item
Example: a @code{CHAR(5)} column containing the value @code{'A'} looks like:@*
@code{hexadecimal 41 20 20 20 20} --  (length = 5, value = @code{'A@ @ @ @ '})
@end itemize

@code{VARCHAR}
@itemize @bullet
@item
Storage: variable-length string with a preceding length.
@item
Example: a @code{VARCHAR(7)} column containing @code{'A'} looks like:@*
@code{hexadecimal 01 41}  --  (length = 1, value = @code{'A'})
@end itemize

@item The numeric data types

Important: MySQL almost always stores multi-byte binary numbers with 
the low byte first. This is called "little-endian" numeric storage;
it's normal on Intel x86 machines; MySQL uses it even for non-Intel
machines so that databases will be portable.

@code{TINYINT}
@itemize @bullet
@item
Storage: fixed-length binary, always one byte.
@item
Example: a @code{TINYINT} column containing @code{65} looks like:@*
@code{hexadecimal 41}  --  (length = 1, value = 65)
@end itemize

@code{SMALLINT}
@itemize @bullet
@item
Storage: fixed-length binary, always two bytes.
@item
Example: a @code{SMALLINT} column containing @code{65} looks like:@*
@code{hexadecimal 41 00}  --  (length = 2, value = 65)
@end itemize

@code{MEDIUMINT}
@itemize @bullet
@item
Storage: fixed-length binary, always three bytes.
@item
Example: a @code{MEDIUMINT} column containing @code{65} looks like:@*
@code{hexadecimal 41 00 00}  --  (length = 3, value = 65)
@end itemize

@code{INT}
@itemize @bullet
@item
Storage: fixed-length binary, always four bytes.
@item
Example: an @code{INT} column containing @code{65} looks like:@*
@code{hexadecimal 41 00 00 00}  --  (length = 4, value = 65)
@end itemize

@code{BIGINT}
@itemize @bullet
@item
Storage: fixed-length binary, always eight bytes.
@item
Example: a @code{BIGINT} column containing @code{65} looks like:@*
@code{hexadecimal 41 00 00 00 00 00 00 00}  --  (length = 8, value = 65)
@end itemize

@code{FLOAT}
@itemize @bullet
@item
Storage: fixed-length binary, always four bytes.
@item
Example: a @code{FLOAT} column containing approximately @code{65} looks like:@*
@code{hexadecimal 00 00 82 42}  --  (length = 4, value = 65)
@end itemize

@code{DOUBLE PRECISION}
@itemize @bullet
@item
Storage: fixed-length binary, always eight bytes.
@item
Example: a @code{DOUBLE PRECISION} column containing approximately @code{65} looks like:@*
@code{hexadecimal 00 00 00 00 00 40 50 40}  --  (length = 8, value = 65)
@end itemize

@code{REAL}
@itemize @bullet
@item
Storage: same as @code{FLOAT}, or same as @code{DOUBLE PRECISION}, depending
on the setting of the @code{--ansi} option.
@end itemize

@code{DECIMAL}
@itemize @bullet
@item
Storage: fixed-length string, with a leading byte for the sign, if any.
@item
Example: a @code{DECIMAL(2)} column containing @code{65} looks like:@*
@code{hexadecimal 20 36 35}  --  (length = 3, value = @code{' 65'})
@item
Example: a @code{DECIMAL(2) UNSIGNED} column containing @code{65} looks like:@*
@code{hexadecimal 36 35}  --  (length = 2, value = @code{'65'})
@item
Example: a @code{DECIMAL(4,2) UNSIGNED} column containing @code{65} looks like:@*
@code{hexadecimal 36 35 2E 30 30}  --  (length = 5, value = @code{'65.00'})
@end itemize

@code{NUMERIC}
@itemize @bullet
@item
Storage: same as @code{DECIMAL}.
@end itemize

@code{BOOL}
@itemize @bullet
@item
Storage: same as @code{TINYINT}.
@end itemize

@item The temporal data types

@code{DATE}
@itemize @bullet
@item
Storage: 3 byte integer, low byte first.
Packed as: 'day + month*32 + year*16*32'
@item
Example: a @code{DATE} column containing @code{'1962-01-02'} looks like:@*
@code{hexadecimal 22 54 0F}
@end itemize

@code{DATETIME}
@itemize @bullet
@item
Storage: eight bytes.
@item
Part 1 is a 32-bit integer containing year*10000 + month*100 + day.
@item
Part 2 is a 32-bit integer containing hour*10000 + minute*100 + second.
@item
Example: a @code{DATETIME} column for @code{'0001-01-01 01:01:01'} looks like:@*
@code{hexadecimal B5 2E 11 5A 02 00 00 00}
@end itemize

@code{TIME}
@itemize @bullet
@item
Storage: 3 bytes, low byte first.
This is stored as seconds:  days*24*3600+hours*3600+minutes*60+seconds
@item
Example: a @code{TIME} column containing @code{'1 02:03:04'} (1 day 2 hour 3 minutes and 4 seconds) looks like:@*
@code{hexadecimal 58 6E 01}
@end itemize

@code{TIMESTAMP}
@itemize @bullet
@item
Storage: 4 bytes, low byte first.
Stored as unix @code{time()}, which is seconds since the Epoch
(00:00:00 UTC, January 1, 1970).
@item
Example: a @code{TIMESTAMP} column containing @code{'2003-01-01 01:01:01'} looks like:@*
@code{hexadecimal 4D AE 12 23}
@end itemize

@c TODO: this is for YEAR(4)? What about YEAR(2)?

@code{YEAR}
@itemize @bullet
@item
Storage: same as unsigned @code{TINYINT} with a base value of 0 = 1901.
@end itemize

@item Others

@code{SET}
@itemize @bullet
@item
Storage: one byte for each eight members in the set.
@item
Maximum length: eight bytes (for maximum 64 members).
@item
This is a bit list. The least significant bit corresponds to the
first listed member of the set.
@item
Example: a @code{SET('A','B','C')} column containing @code{'A'} looks like:@*
@code{01} --  (length = 1, value = 'A')
@end itemize

@code{ENUM}
@itemize @bullet
@item
Storage: one byte if less than 256 alternatives, else two bytes.
@item
This is an index. The value 1 corresponds to the first listed
alternative. (Note: @code{ENUM} always reserves the value 0 for an erroneous
value. This explains why @code{'A'} is 1 instead of 0.)
@item
Example: an @code{ENUM('A','B','C')} column containing @code{'A'} looks like:@*
@code{01}  --  (length = 1, value = 'A')
@end itemize

@item The Large-Object data types

Warning: Because @code{TINYBLOB}'s preceding length is one byte long (the
size of a @code{TINYINT}) and @code{MEDIUMBLOB}'s preceding length is three
bytes long (the size of a @code{MEDIUMINT}), it's easy to think there's
some sort of correspondence between the the @code{BLOB} and @code{INT}
types. There isn't --- a @code{BLOB}'s preceding length is not four bytes
long (the size of an @code{INT}).

@code{TINYBLOB}
@itemize @bullet
@item
Storage: variable-length string with a preceding one-byte length.
@item
Example: a @code{TINYBLOB} column containing @code{'A'} looks like:@*
@code{hexadecimal 01 41}  --  (length = 2, value = 'A')
@end itemize

@code{TINYTEXT}
@itemize @bullet
@item
Storage: same as @code{TINYBLOB}.
@end itemize

@code{BLOB}
@itemize @bullet
@item
Storage: variable-length string with a preceding two-byte length.
@item
Example: a @code{BLOB} column containing @code{'A'} looks like:@*
@code{hexadecimal 01 00 41}  --  (length = 2, value = 'A')
@end itemize

@code{TEXT}
@itemize @bullet
@item
Storage: same as @code{BLOB}.
@end itemize

@code{MEDIUMBLOB}
@itemize @bullet
@item
Storage: variable-length string with a preceding length.
@item
Example: a @code{MEDIUMBLOB} column containing @code{'}A' looks like:@*
@code{hexadecimal 01 00 00 41}  --  (length = 4, value = 'A')
@end itemize

@code{MEDIUMTEXT}
@itemize @bullet
@item
Storage: same as @code{MEDIUMBLOB}.
@end itemize

@code{LONGBLOB}
@itemize @bullet
@item
Storage: variable-length string with a preceding four-byte length.
@item
Example: a @code{LONGBLOB} column containing @code{'A'} looks like:@*
@code{hexadecimal 01 00 00 00 41}  --  (length = 5, value = 'A')
@end itemize

@code{LONGTEXT}
@itemize @bullet
@item
Storage: same as @code{LONGBLOB}.
@end itemize

@end table

@node MyISAM more information,  , MyISAM column attributes, MyISAM Record Structure
@section Where to Look For More Information

@strong{References:}

Most of the formatting work for @code{MyISAM} columns is visible
in the program @file{/sql/field.cc} in the source code directory.
And in the @code{MyISAM} directory, the files that do formatting
work for different record formats are: @file{/myisam/mi_statrec.c},
@file{/myisam/mi_dynrec.c}, and @file{/myisam/mi_packrec.c}.


@node The .MYI file, InnoDB Record Structure, MyISAM Record Structure, Top
@chapter The @file{.MYI} file

@menu
* MyISAM files::                @code{MyISAM} Files
@end menu

@c TODO: change some of the @strong things to real headings.

A @file{.MYI} file for a @code{MyISAM} table contains the table's indexes.

The @file{.MYI} file has two parts: the header information and
the key values. So the next sub-sections will be
"The @file{.MYI} Header" and "The @file{.MYI} Key Values".

@strong{The @file{.MYI} Header}

A @file{.MYI} file begins with a header, with information
about options, about file sizes, and about the "keys".
In MySQL terminology, a "key" is something that you
create with @code{CREATE [UNIQUE] INDEX}.

Program files which read and write @file{.MYI} headers
are in the @file{./myisam} directory: @file{mi_open.c} has the routines
that write each section of the header, @file{mi_create.c}
has a routine that calls the @file{mi_open.c} routines
in order, and @file{myisamdef.h}  has structure
definitions corresponding to what we're about
to describe.

These are the main header sections:

@example
Section                       Occurrences
-------                       -----------
state                         Occurs 1 time
base                          Occurs 1 time
keydef (including keysegs)    Occurs once for each key
recinfo                       Occurs once for each field
@end example

Now we will look at each of these sections, showing each field.

We are going to use an example table throughout the description.
To make the example table, we executed these statements:

@example
  CREATE TABLE T (S1 CHAR(1), S2 CHAR(2), S3 CHAR(3));
  CREATE UNIQUE INDEX I1 ON T (S1);
  CREATE INDEX I2 ON T (S2,S3);
  INSERT INTO T VALUES ('1', 'aa', 'b');
  INSERT INTO T VALUES ('2', 'aa', 'bb');
  INSERT INTO T VALUES ('3', 'aa', 'bbb');
  DELETE FROM T WHERE S1 = '2';
@end example

We took a hexadecimal dump of the resulting file, @file{T.MYI}.

In all the individual descriptions below, the column labeled
``Dump From Example File'' has the exact bytes that are in
@file{T.MYI}. You can verify that by executing the
same statements and looking at a hexadecimal dump yourself.
With Linux this is possible using @code{od -h T.MYI}; with Windows
you can use the command-line debugger.

Along with the typical value, we may include a comment.
The comment usually explains why the value is what it is.
Sometimes the comment is derived from the comments in the
source code.

@strong{state}

This section is written by @file{mi_open.c}, @code{mi_state_info_write()}.

@example
Name                         Size Dump From Example File  Comment
----                         ---- ----------------------  -------

file_version                  4   FE FE 07 01             from myisam_file_magic
options                       2   00 02                   HA_OPTION_COMPRESS_RECORD
                                                          etc.
header_length                 2   01 A2                   this header example has
                                                          0x01A2 bytes
state_info_length             2   00 B0                   = MI_STATE_INFO_SIZE
                                                          defined in myisamdef.h
base_info_length              2   00 64                   = MI_BASE_INFO_SIZE
                                                          defined in myisamdef.h
base_pos                      2   00 D4                   = where the base
                                                          section starts
key_parts                     2   00 03                   a key part is a column
                                                          within a key
unique_key_parts              2   00 00                   key-parts+unique-parts
keys                          1   02                      here are 2 keys --
                                                          I1 and I2
uniques                       1   00                      number of hash unique
                                                          keys used internally
                                                          in temporary tables
                                                          (nothing to do with
                                                          'UNIQUE' definitions)
language                      1   08                      "language for indexes"
max_block_size                1   01
fulltext_keys                 1   00                      # of fulltext keys.
                                                          = 0 if version <= 4.0
not_used                      1   00                      to align to 8-byte
                                                          boundary

state->open_count             2   00 01
state->changed                1   39                      set if table updated;
                                                          reset if shutdown (so
                                                          one can examine this
                                                          to see if there was an
                                                          update without proper
                                                          shutdown)
state->sortkey                1   FF                      "sorted by this key"
                                                          (not used)
state->state.records          8   00 00 00 00 00 00 00 02 number of actual,
                                                          un-deleted, records
state->state.del              8   00 00 00 00 00 00 00 01 # of deleted records
state->split                  8   00 00 00 00 00 00 00 03 # of "chunks" (e.g.
                                                          records or spaces left
                                                          after record deletion)
state->dellink                8   00 00 00 00 00 00 00 07 "Link to next removed
                                                          "block". Initially =
                                                          HA_OFFSET_ERROR
state->state.key_file_length  8   00 00 00 00 00 00 0c 00 2048
state->state.data_file_length 8   00 00 00 00 00 00 00 15 = size of .MYD file
state->state.empty            8   00 00 00 00 00 00 00 00
state->state.key_empty        8   00 00 00 00 00 00 00 00
state->auto_increment         8   00 00 00 00 00 00 00 00
state->checksum               8   00 00 00 00 00 00 00 00
state->process                4   00 00 09 E6             from getpid(). process
                                                          of last update
state->unique                 4   00 00 00 0B             initially = 0
state->status                 4   00 00 00 00
state->update_count           4   00 00 00 04             updated for each write
                                                          lock (there were 3
                                                          inserts + 1 delete,
                                                          total 4 operations)
state->key_root               8   00 00 00 00 00 00 04 00 offset in file where
                                                          I1 keys start, can be
                                                          = HA_OFFSET_ERROR
                                  00 00 00 00 00 00 08 00 state->key_root occurs
                                                          twice because there
                                                          are two keys
state->key_del                8   FF FF FF FF FF FF FF FF delete links for keys
                                                          (occurs many times if
                                                          many delete links)
state->sec_index_changed      4   00 00 00 00             sec_index = secondary
                                                          index (presumably)
                                                          not currently used
state->sec_index_used         4   00 00 00 00             "which extra indexes
                                                          are in use"
                                                          not currently used
state->version                4   3F 3F EB F7             "timestamp of create"
state->key_map                8   00 00 00 03             "what keys are in use"
state->create_time            8   00 00 00 00 3F 3F EB F7 "time when database
                                                          created" (actually:
                                                          time when file made)
state->recover_time           8   00 00 00 00 00 00 00 00 "time of last recover"
state->check_time             8   00 00 00 00 3F 3F EB F7 "time of last check"
state->rec_per_key_rows       8   00 00 00 00 00 00 00 00
state->rec_per_key_parts      4   00 00 00 00             (key_parts = 3, so
                                  00 00 00 00              rec_per_key_parts
                                  00 00 00 00              occurs 3 times)
@end example


@strong{base}

This section is written by @file{mi_open.c}, @code{mi_base_info_write()}.
The corresponding structure in @file{myisamdef.h} is @code{MI_BASE_INFO}.

In our example @file{T.MYI} file, the first byte of the @code{base} section
is at offset 0x00d4. That's where it's supposed to be, according
to the header field @code{base_pos} (above).

@example
Name                         Size Dump From Example File  Comment
----                         ---- ----------------------  -------

base->keystart               8    00 00 00 00 00 00 04 00 keys start at offset
                                                          1024 (0x0400)
base->max_data_file_length   8    00 00 00 00 00 00 00 00
base->max_key_file_length    8    00 00 00 00 00 00 00 00
base->records                8    00 00 00 00 00 00 00 00
base->reloc                  8    00 00 00 00 00 00 00 00
base->mean_row_length        4    00 00 00 00
base->reclength              4    00 00 00 07             length(s1)+length(s2)
                                                          +length(s3)=7
base->pack_reclength         4    00 00 00 07
base->min_pack_length        4    00 00 00 07
base->max_pack_length        4    00 00 00 07
base->min_block_length       4    00 00 00 14
base->fields                 4    00 00 00 04             4 fields: 3 defined,
                                                          plus 1 extra
base->pack_fields            4    00 00 00 00
base->rec_reflength          1    04
base->key_reflength          1    04
base->keys                   1    02                      was 0 at start
base->auto_key               1    00
base->pack_bits              2    00 00
base->blobs                  2    00 00
base->max_key_block_length   2    04 00                   length of block = 1024
                                                          bytes (0x0400)
base->max_key_length         2    00 10                   including length of
                                                          pointer
base->extra_alloc_bytes      2    00 00
base->extra_alloc_procent    1    00
base->raid_type              1    00
base->raid_chunks            2    00 00
base->raid_chunksize         4    00 00 00 00
[extra] i.e. filler          6    00 00 00 00 00 00
@end example

@strong{keydef}

This section is written by @file{mi_open.c}, @code{mi_keydef_write()}.
The corresponding structure in @file{myisamdef.h} is @code{MI_KEYDEF}.

This is a multiple-occurrence structure. Since
there are two indexes in our example (I1 and I2), we will see
that @code{keydef} occurs two times below. There is a subordinate
structure, @code{keyseg}, which also occurs multiple times (once
within the @code{keydef} for I1 and two times within the @code{keydef} for
I2).

@example
Name                         Size Dump From Example File  Comment
----                         ---- ----------------------  -------

/* key definition for I1 */

keydef->keysegs              1    01                      there is 1 keyseg (for
                                                          column S1).
keydef->key_alg              1    01                      algorithm = Rtree or
                                                          Btree
keydef->flag                 2    00 49                   HA_NOSAME +
                                                          HA_SPACE_PACK_USED +
                                                          HA_NULL_PART_KEY
keydef->block_length         2    04 00                   i.e. 1024
key def->keylength           2    00 06                   field-count+sizeof(S1)
                                                          sizeof(ROWID)
keydef->minlength            2    00 06
keydef->maxlength            2    00 06
  /* keyseg for S1 in I1 */
  keyseg->type               1    01                      /* I1(S1) size(S1)=1,
                                                             column = 1 */
                                                          = HA_KEYTYPE_TEXT
  keyseg->language           1    08
  keyseg->null_bit           1    02
  keyseg->bit_start          1    00
  keyseg->bit_end            1    00
  [0] i.e. filler            1    00
  keyseg->flag               2    00 14                   HA_NULL_PART +
                                                          HA_PART_KEY
  keyseg->length             2    00 01                   length(S1) = 1
  keyseg->start              4    00 00 00 01             offset in the row
  keyseg->null_pos           4    00 00 00 00

/* key definition for I2 */

keydef->keysegs              1    02                      keysegs=2, for columns
                                                          S2 and S3
keydef->key_alg              1    01                      algorithm = Rtree or
                                                          Btree
keydef->flag                 2    00 48                   HA_SPACE_PACK_USED +
                                                          HA_NULL_PART_KEY
keydef->block_length         2    04 00                   i.e. 1024
key def->keylength           2    00 0B                   field-count+ sizeof(all fields)+
                                                            sizeof(RID)
keydef->minlength            2    00 0B
keydef->maxlength            2    00 0B
  /* keyseg for S2 in I2 */
  keyseg->type               1    01                      /* I2(S2) size(S2)=2,
                                                             column = 2 */
  keyseg->language           1    08
  keyseg->null_bit           1    04
  keyseg->bit_start          1    00
  keyseg->bit_end            1    00
  [0] i.e. filler            1    00
  keyseg->flag               2    00 14                   HA_NULL_PART +
                                                          HA_PART_KEY
  keyseg->length             2    00 02                   length(S2) = 2
  keyseg->start              4    00 00 00 02
  keyseg->null_pos           4    00 00 00 00
  /* keyseg for S3 in I2 */
  keyseg->type               1    01                      /* I2(S3) size(S3)=3,
                                                             column = 3 */
  keyseg->language           1    08
  keyseg->null_bit           1    08
  keyseg->bit_start          1    00
  keyseg->bit_end            1    00
  [0] i.e. filler            1    00
  keyseg->flag               2    00 14                   HA_NULL_PART +
                                                          HA_PART_KEY
  keyseg->length             2    00 03                   length(S3) = 3
  keyseg->start              4    00 00 00 04
  keyseg->null_pos           4    00 00 00 00
@end example

@strong{recinfo}

The @code{recinfo} section is written by @file{mi_open.c},
@code{mi_recinfo_write()}.
The corresponding structure in @file{myisamdef.h} is @code{MI_COLUMNDEF}.

This is another multiple-occurrence structure. It appears once
for each field that appears in a key, including an extra field
that appears at the start and has flags (for deletion and for
null fields).

@example
Name                         Size Dump From Example File  Comment
----                         ---- ----------------------  -------

recinfo->type                2    00 00                   extra
recinfo->length              2    00 01
recinfo->null_bit            1    00
recinfo->null_pos            2    00 00

recinfo->type                2    00 00                   I1 (S1)
recinfo->length              2    00 01
recinfo->null_bit            1    02
recinfo->null_pos            2    00 00

recinfo->type                2    00 00                   I2 (S2)
recinfo->length              2    00 02
recinfo->null_bit            1    04
recinfo->null_pos            2    00 00

recinfo->type                2    00 00                   I2 (S3)
recinfo->length              2    00 03
recinfo->null_bit            1    08
recinfo->null_pos            2    00 00
@end example

We are now at offset 0xA2 within the file @file{T.MYI}.
Notice that the value of the third field in the header,
@code{header_length}, is 0xA2. Anything following this point,
up till the first key value, is filler.

@strong{The @file{.MYI} Key Values}

And now we look at the part which is not the information header:
we look at the key values. The key values are in blocks (MySQL's
term for pages). A block contains values from only one index. To
continue our example: there is a block for the I1 key values, and
a block for the I2 key values.

According to the header information (@code{state->key_root} above), the I1
block starts at offset 0x0400 in the file, and the I2 block
starts at offset 0x0800 in the file.

At offset 0x0400 in the file, we have this:

@example
Name                         Size Dump From Example File  Comment
----                         ---- ----------------------  -------

(block header)               2    00 0E                   = size (inclusive)
                                                          (first bit of word =
                                                          0 meaning this is a
                                                          B-Tree leaf, see the
                                                          mi_test_if_nod macro)
(first key value)            2    01 31                   Value is "1" (0x31).
(first key pointer)          4    00 00 00 00             Pointer is to Record
                                                          #0000.
(second key value)           2    01 33                   Value is "3" (0x33).
(second key pointer)         4    00 00 00 02             Pointer is to Record
                                                          #0002.
(junk)                       1010 .. .. .. .. .. .. ..    rest of the 1024-byte
                                                          block is unused
@end example

At offset 0800x in the file, we have this:

@example
Name                         Size Dump From Example File  Comment
----                         ---- ----------------------  -------

(block header)               2    00 18                   = size (inclusive)
(first key value)            7    01 61 61 01 62 20 20    Value is "aa/b  "
(first key pointer)          4    00 00 00 00             Pointer is to Record
                                                          #0000.
(second key value)           7    01 61 61 01 62 62 62    Value is "aa/bbb"
(second key pointer)         4    00 00 00 02             Pointer is to Record
                                                          #0002.
(junk)                       1000 .. .. .. .. .. .. ..    rest of the 1024-byte
                                                          block is unused
@end example

From the above illustrations, these facts should be clear:

@itemize @bullet

@item
Each key contains the entire contents of all the columns, including
trailing spaces in @code{CHAR} columns. There is no front truncation. There
is no back truncation. (There can be space truncation if @code{keyseg->flag}
@code{HA_SPACE_PACK} flag is on.)

@item
For fixed-row tables:
The pointer is a fixed-size (4-byte) number which contains an ordinal
row number. The first row is Record #0000. This item is analogous to
the ROWID, or RID (row identifier), which other DBMSs use.
For dynamic-row tables:
The pointer is an offset in the @file{.MYD} file.

@item
The normal block length is 0x0400 (1024) bytes.

@end itemize

These facts are not illustrated, but are also clear:

@itemize @bullet

@item
If a key value is @code{NULL}, then the first byte is 0x00 (instead
of 001 as in the above examples) and that's all. Even for a
fixed @code{CHAR(3)} column, the size of the key value is only 1 byte.

@item
Initially the junk at the end of a block is filler bytes,
value = 0xA5. If MySQL shifts key values up after a @code{DELETE},
the end of the block is not overwritten.

@item
A normal block is at least 65% full, and typically 80% full.
(This is somewhat denser than the typical B-tree algorithm
would cause, it is thus because @code{myisamchk -rq} will make blocks
nearly 100% full.)

@item
There is a pool of free blocks, which increases in size when
deletions occur. If all blocks have the same normal block length (1024),
then MySQL will always use the same pool.

@c TODO: max key length 1000 as of version ???

@item
The maximum number of keys is 32 (@code{MI_MAX_KEY}).
The maximum number of segments in a key is 16 (@code{MI_MAX_KEY_SEG}).
The maximum key length is 500 (@code{MI_MAX_KEY_LENGTH}).
The maimum block length is 16384 (@code{MI_MAX_KEY_BLOCK_LENGTH}).
All these MI_... constants are expressed by #defines in the @file{myisamdef.h} file.
@end itemize

@node MyISAM files,  , The .MYI file, The .MYI file
@section @code{MyISAM} Files

Some notes about @code{MyISAM} file handling:

@itemize @bullet
@item
If a table is never updated, MySQL will never touch the table
files, so it would never be marked as closed or corrupted.

@item
If a table is marked readonly by the OS, it will only be opened in
readonly mode. Any updates to it will fail.

@item
When a normal table is opened for reading by a @code{SELECT}, MySQL
will open it in
read/write mode, but will not write anything to it.

@item
A table can be closed during one of the following events:

@itemize @minus
@item
Out of space in table cache
@item
Someone executed flush tables
@item
MySQL was shut down
@item
flush_time expired (which causes an automatic flush-tables to be executed)
@end itemize

@item
When MySQL opens a table, it checks if the table is clean. If it isn't
and the server was started with the @code{--myisam-recover} option, check
the table and try to recover it if it's crashed.  (The safest automatic
recover option is probably @code{--myisam-recover=BACKUP}.)

@end itemize

@node InnoDB Record Structure, InnoDB Page Structure, The .MYI file, Top
@chapter @code{InnoDB} Record Structure

@menu
* InnoDB overview::             High-Altitude Picture
* InnoDB more information::     Where to Look For More Information
@end menu

This page contains:
@itemize @bullet
@item
A high-altitude "summary" picture of the parts of a MySQL/@code{InnoDB}
record structure.
@item
A description of each part.
@item
An example.
@end itemize

After reading this page, you will know how MySQL/@code{InnoDB} stores a
physical record.

@node InnoDB overview, InnoDB more information, InnoDB Record Structure, InnoDB Record Structure
@section High-Altitude Picture

@menu
* InnoDB field start offsets::  FIELD START OFFSETS
* InnoDB extra bytes::          EXTRA BYTES
* InnoDB field contents::       FIELD CONTENTS
@end menu

The chart below shows the three parts of a physical record.

@multitable @columnfractions .30 .65

@item @strong{Name} @tab @strong{Size}
@item Field Start Offsets
@tab (F*1) or (F*2) bytes
@item Extra Bytes
@tab 6 bytes
@item Field Contents
@tab depends on content

@end multitable

Legend: The letter 'F' stands for 'Number Of Fields'.

The meaning of the parts is as follows:
@itemize @bullet
@item
The FIELD START OFFSETS is a list of numbers containing the
information "where a field starts".
@item
The EXTRA BYTES is a fixed-size header.
@item
The FIELD CONTENTS contains the actual data.
@end itemize

@strong{An Important Note About The Word "Origin"}

The "Origin" or "Zero Point" of a record is the first byte of the
Field Contents --- not the first byte of the Field Start Offsets. If
there is a pointer to a record, that pointer is pointing to the
Origin. Therefore the first two parts of the record are addressed by
subtracting from the pointer, and only the third part is addressed by
adding to the pointer.

@node InnoDB field start offsets, InnoDB extra bytes, InnoDB overview, InnoDB overview
@subsection FIELD START OFFSETS

The Field Start Offsets is a list in which each entry is the
position, relative to the Origin, of the start of the next field. The
entries are in reverse order, that is, the first field's offset is at
the end of the list.

An example: suppose there are three columns. The first column's length
is 1, the second column's length is 2, and the third column's length is 4.
In this case, the offset values are, respectively, 1, 3 (1+2), and 7 (1+2+4).
Because values are reversed, a core dump of the Field Start Offsets
would look like this: @code{07,03,01}.

There are two complications for special cases:
@itemize @bullet
@item
Complication #1: The size of each offset can be either one byte or
two bytes. One-byte offsets are only usable if the total record size
is less than 127. There is a flag in the "Extra Bytes" part which will
tell you whether the size is one byte or two bytes.
@item
Complication #2: The most significant bits of an offset may contain
flag values. The next two paragraphs explain what the contents are.
@end itemize

@strong{When The Size Of Each Offset Is One Byte}
@itemize @bullet
@item
1 bit  = 0 if field is non-@code{NULL}, = 1 if field is @code{NULL}
@item
7 bits  = the actual offset, a number between 0 and 127
@end itemize

@strong{When The Size Of Each Offset Is Two Bytes}
@itemize @bullet
@item
1 bit  = 0 if field is non-@code{NULL}, = 1 if field is @code{NULL}
@item
1 bit  = 0 if field is on same page as offset, = 1 if field and offset are on different pages
@item
14 bits  = the actual offset, a number between 0 and 16383
@end itemize

It is unlikely that the "field and offset are on different pages"
unless the record contains a large @code{BLOB}.

@node InnoDB extra bytes, InnoDB field contents, InnoDB field start offsets, InnoDB overview
@subsection EXTRA BYTES

The Extra Bytes are a fixed six-byte header.

@multitable @columnfractions .25 .20 .55

@item @strong{Name} @tab @strong{Size} @tab @strong{Description}
@item @strong{info_bits:}
@item ()
@tab 1 bit
@tab unused or unknown
@item ()
@tab 1 bit
@tab unused or unknown
@item deleted_flag
@tab 1 bit
@tab 1 if record is deleted
@item min_rec_flag
@tab 1 bit
@tab 1 if record is predefined minimum record
@item n_owned
@tab 4 bits
@tab number of records owned by this record
@item heap_no
@tab 13 bits
@tab record's order number in heap of index page
@item n_fields
@tab 10 bits
@tab number of fields in this record, 1 to 1023
@item 1byte_offs_flag
@tab 1 bit
@tab 1 if each Field Start Offsets is 1 byte long (this item is also called the "short" flag)
@item @strong{next 16 bits}
@tab 16 bits
@tab pointer to next record in page
@item @strong{TOTAL}
@tab 48 bits

@end multitable

Total size is 48 bits, which is six bytes.

If you're just trying to read the record, the key bit in the Extra
Bytes is 1byte_offs_flag --- you need to know if 1byte_offs_flag is 1
(i.e.: "short 1-byteoffsets") or 0 (i.e.: "2-byte offsets").

Given a pointer to the Origin, @code{InnoDB} finds the start of the record as follows:
@itemize @bullet
@item
Let X = n_fields (the number of fields is by definition equal to the
number of entries in the Field Start Offsets Table).
@item
If 1byte_offs_flag equals 0, then let X = X * 2 because there are
two bytes for each entry instead of just one.
@item
Let X = X + 6, because the fixed size of Extra Bytes is 6.
@item
The start of the record is at (pointer value minus X).
@end itemize

@node InnoDB field contents,  , InnoDB extra bytes, InnoDB overview
@subsection FIELD CONTENTS

The Field Contents part of the record has all the data. Fields are
stored in the order they were defined in.

There are no markers between fields, and there is no marker or filler
at the end of a record.

Here's an example.
@itemize @bullet
@item
I made a table with this definition:

@example
CREATE TABLE T
    (FIELD1 VARCHAR(3), FIELD2 VARCHAR(3), FIELD3 VARCHAR(3))
    Type=InnoDB;
@end example

To understand what follows, you must know that table @code{T} has six columns
--- not three --- because @code{InnoDB} automatically added three "system
columns" at the start for its own housekeeping. It happens that these
system columns are the row ID, the transaction ID, and the rollback
pointer, but their values don't matter now. Regard them as three black
boxes.

@item
I put some rows in the table. My last three @code{INSERT} statements were:

@example
INSERT INTO T VALUES ('PP', 'PP', 'PP');
INSERT INTO T VALUES ('Q', 'Q', 'Q');
INSERT INTO T VALUES ('R', NULL, NULL);
@end example

@item
I ran Borland's TDUMP to get a hexadecimal dump of
the contents of @file{\mysql\data\ibdata1}, which (in my case) is the
MySQL/@code{InnoDB} data file (on Windows).
@end itemize

Here is an extract of the dump:

@multitable @columnfractions .65 .35

@item @strong{Address Values in Hexadecimal} @tab @strong{Values in ASCII}
@item @code{0D4280: 00 00 2D 00 84 4F 4F 4F 4F 4F 4F 4F 4F 4F 19 17}
@tab @code{..-..OOOOOOOOO..}
@item @code{0D4290: 15 13 0C 06 00 00 78 0D 02 BF 00 00 00 00 04 21}
@tab @code{......x........!}
@item @code{0D42A0: 00 00 00 00 09 2A 80 00 00 00 2D 00 84 50 50 50}
@tab @code{.....*....-..PPP}
@item @code{0D42B0: 50 50 50 16 15 14 13 0C 06 00 00 80 0D 02 E1 00}
@tab @code{PPP.............}
@item @code{0D42C0: 00 00 00 04 22 00 00 00 00 09 2B 80 00 00 00 2D}
@tab @code{....".....+....-}
@item @code{0D42D0: 00 84 51 51 51 94 94 14 13 0C 06 00 00 88 0D 00}
@tab @code{..QQQ...........}
@item @code{0D42E0: 74 00 00 00 00 04 23 00 00 00 00 09 2C 80 00 00}
@tab @code{t.....#.....,...}
@item @code{0D42F0: 00 2D 00 84 52 00 00 00 00 00 00 00 00 00 00 00}
@tab @code{.-..R...........}

@end multitable

A reformatted version of the dump, showing only the relevant bytes,
looks like this (I've put a line break after each field and added labels):

@strong{Reformatted Hexadecimal Dump}

@example
19 17 15 13 0C 06 Field Start Offsets /* First Row */
00 00 78 0D 02 BF Extra Bytes
00 00 00 00 04 21 System Column #1
00 00 00 00 09 2A System Column #2
80 00 00 00 2D 00 84 System Column #3
50 50 Field1 'PP'
50 50 Field2 'PP'
50 50 Field3 'PP'

16 15 14 13 0C 06 Field Start Offsets /* Second Row */
00 00 80 0D 02 E1 Extra Bytes
00 00 00 00 04 22 System Column #1
00 00 00 00 09 2B 80 System Column #2
00 00 00 2D 00 84 System Column #3
51 Field1 'Q'
51 Field2 'Q'
51 Field3 'Q'

94 94 14 13 0C 06 Field Start Offsets /* Third Row */
00 00 88 0D 00 74 Extra Bytes
00 00 00 00 04 23 System Column #1
00 00 00 00 09 2C System Column #2
80 00 00 00 2D 00 84 System Column #3
52 Field1 'R'
@end example

You won't need explanation if you followed everything I've said, but
I'll add helpful notes for the three trickiest details.
@itemize @bullet

@item
Helpful Notes About "Field Start Offsets":

Notice that the sizes of the record's fields, in forward order, are:
6, 6, 7, 2, 2, 2. Since each offset is for the start of the "next"
field, the hexadecimal offsets are 06, 0c (6+6), 13 (6+6+7), 15
(6+6+7+2), 17 (6+6+7+2+2), 19 (6+6+7+2+2+2). Reversing the order, the
Field Start Offsets of the first record are: @code{19,17,15,13,0c,06}.

@item
Helpful Notes About "Extra Bytes":

Look at the Extra Bytes of the first record: @code{00 00 78 0D 02 BF}. The
fourth byte is @code{0D hexadecimal}, which is @code{1101 binary} ... the 110 is the
last bits of n_fields (@code{110 binary} is 6 which is indeed the number of
fields in the record) and the final 1 bit is 1byte_offs_flag. The
fifth and sixth bytes, which contain @code{02 BF}, constitute the "next"
field. Looking at the original hexadecimal dump, at address
@code{0D42BF} (which is position @code{02BF} within the page), you'll see the beginning bytes of
System Column #1 of the second row. In other words, the "next" field
points to the "Origin" of the following row.

@item
Helpful Notes About NULLs:

For the third row, I inserted @code{NULL}s in FIELD2 and FIELD3. Therefore in
the Field Start Offsets the top bit is @code{on} for these fields (the
values are @code{94 hexadecimal}, @code{94 hexadecimal}, instead of 
@code{14 hexadecimal}, @code{14 hexadecimal}). And the row is
shorter because the @code{NULL}s take no space.

@end itemize

@node InnoDB more information,  , InnoDB overview, InnoDB Record Structure
@section Where to Look For More Information

@strong{References:}

The most relevant @code{InnoDB} source-code files are @file{rem0rec.c},
@file{rem0rec.ic},
and @file{rem0rec.h} in the @file{rem} ("Record Manager") directory.

@node InnoDB Page Structure, Error message, InnoDB Record Structure, Top
@chapter @code{InnoDB} Page Structure

@menu
* InnoDB page overview::        High-Altitude View
* InnoDB page example::         Example
* InnoDB more page information::  Where to Look For More Information
@end menu

@code{InnoDB} stores all records inside a fixed-size unit which is commonly
called a "page" (though @code{InnoDB} sometimes calls it a "block" instead).
Currently all pages are the same size, 16KB.

A page contains records, but it also contains headers and trailers.
I'll start this description with a high-altitude view of a page's parts,
then I'll describe each part of a page. Finally, I'll show an example. This 
discussion deals only with the most common format, for the leaf page of a data file.

@node InnoDB page overview, InnoDB page example, InnoDB Page Structure, InnoDB Page Structure
@section High-Altitude View

@menu
* InnoDB fil header::           Fil Header
* InnoDB page header::          Page Header
* InnoDB infimum and supremum records::  The Infimum and Supremum Records
* InnoDB user records::         User Records
* InnoDB free space::           Free Space
* InnoDB page directory::       Page Directory
* InnoDB fil trailer::          Fil Trailer
@end menu

An @code{InnoDB} page has seven parts:
@itemize @bullet
@item
Fil Header
@item
Page Header
@item
Infimum + Supremum Records
@item
User Records
@item
Free Space
@item
Page Directory
@item
Fil Trailer
@end itemize

As you can see, a page has two header/trailer pairs. The inner pair, "Page Header" and
"Page Directory", are mostly the concern of the \page program group,
while the outer pair, "Fil Header" and "Fil Trailer", are mostly the
concern of the \fil program group. The "Fil" header also goes goes by
the name of "File Page Header".

Sandwiched between the headers and trailers, are the records and
the free (unused) space. A page always begins with two unchanging
records called the Infimum and the Supremum. Then come the user
records. Between the user records (which grow downwards) and the page 
directory (which grows upwards) there is space for new records.

@node InnoDB fil header, InnoDB page header, InnoDB page overview, InnoDB page overview
@subsection Fil Header

The Fil Header has eight parts, as follows:

@multitable @columnfractions .25 .10 .65

@item @strong{Name} @tab @strong{Size} @tab @strong{Remarks}
@item @code{FIL_PAGE_SPACE}
@tab 4
@tab 4  ID of the space the page is in
@item @code{FIL_PAGE_OFFSET}
@tab 4
@tab ordinal page number from start of space
@item @code{FIL_PAGE_PREV}
@tab 4
@tab offset of previous page in key order
@item @code{FIL_PAGE_NEXT}
@tab 4
@tab offset of next page in key order
@item @code{FIL_PAGE_LSN}
@tab 8
@tab log serial number of page's latest log record
@item @code{FIL_PAGE_TYPE}
@tab 2
@tab current defined types are: @code{FIL_PAGE_INDEX},
@code{FIL_PAGE_UNDO_LOG}, @code{FIL_PAGE_INODE},
@code{FIL_PAGE_IBUF_FREE_LIST}
@item @code{FIL_PAGE_FILE_FLUSH_LSN}
@tab 8
@tab "the file has been flushed to disk at least up to this lsn" (log serial number), 
     valid only on the first page of the file
@item @code{FIL_PAGE_ARCH_LOG_NO}
@tab 4
@tab the latest archived log file number at the time that
@code{FIL_PAGE_FILE_FLUSH_LSN} was written (in the log)
@end multitable

@itemize @bullet
@item
@code{FIL_PAGE_SPACE} is a necessary identifier because different pages might belong to
different (table) spaces within the same file. The word
"space" is generic jargon for either "log" or "tablespace".

@item
@code{FIL_PAGE_PREV} and @code{FIL_PAGE_NEXT} are the page's "backward" and
"forward" pointers. To show what they're about, I'll draw a two-level
B-tree.

@example
  --------
  - root -
  --------
       |
  ----------------------
  |                    |
  |                    |
  --------          --------
  - leaf -  <-->    - leaf -
  --------          --------
@end example

Everyone has seen a B-tree and knows that the entries in the root page
point to the leaf pages. (I indicate those pointers with vertical '|'
bars in the drawing.) But sometimes people miss the detail that leaf
pages can also point to each other (I indicate those pointers with a horizontal
two-way pointer '<-->' in the drawing). This feature allows @code{InnoDB} to navigate from
leaf to leaf without having to back up to the root level. This is a
sophistication which you won't find in the classic B-tree, which is
why @code{InnoDB} should perhaps be called a B+-tree instead.

@item
The fields @code{FIL_PAGE_FILE_FLUSH_LSN}, @code{FIL_PAGE_PREV}, and
@code{FIL_PAGE_NEXT}
all have to do with logs, so I'll refer you to my article ``How Logs
Work With MySQL And InnoDB'' on @code{devarticles.com}.

@item
@code{FIL_PAGE_FILE_FLUSH_LSN} and @code{FIL_PAGE_ARCH_LOG_NO} are valid
only for the first page of a data file.
@end itemize

@node InnoDB page header, InnoDB infimum and supremum records, InnoDB fil header, InnoDB page overview
@subsection Page Header

The Page Header has 14 parts, as follows:

@multitable @columnfractions .25 .10 .65

@item @strong{Name} @tab @strong{Size} @tab @strong{Remarks}
@item @code{PAGE_N_DIR_SLOTS}
@tab 2
@tab number of directory slots in the Page Directory part; initial value = 2
@item @code{PAGE_HEAP_TOP}
@tab 2
@tab record pointer to first record in heap
@item @code{PAGE_N_HEAP}
@tab 2
@tab number of heap records; initial value = 2
@item @code{PAGE_FREE}
@tab 2
@tab record pointer to first free record
@item @code{PAGE_GARBAGE}
@tab 2
@tab "number of bytes in deleted records"
@item @code{PAGE_LAST_INSERT}
@tab 2
@tab record pointer to the last inserted record
@item @code{PAGE_DIRECTION}
@tab 2
@tab either @code{PAGE_LEFT}, @code{PAGE_RIGHT}, or @code{PAGE_NO_DIRECTION}
@item @code{PAGE_N_DIRECTION}
@tab 2
@tab number of consecutive inserts in the same direction, e.g. "last 5 were all to the left"
@item @code{PAGE_N_RECS}
@tab 2
@tab number of user records
@item @code{PAGE_MAX_TRX_ID}
@tab 8
@tab the highest ID of a transaction which might have changed a record on the page (only set for secondary indexes)
@item @code{PAGE_LEVEL}
@tab 2
@tab level within the index (0 for a leaf page)
@item @code{PAGE_INDEX_ID}
@tab 8
@tab identifier of the index the page belongs to
@item @code{PAGE_BTR_SEG_LEAF}
@tab 10
@tab "file segment header for the leaf pages in a B-tree" (this is irrelevant here)
@item @code{PAGE_BTR_SEG_TOP}
@tab 10
@tab "file segment header for the non-leaf pages in a B-tree" (this is irrelevant here)

@end multitable

(Note: I'll clarify what a "heap" is when I discuss the User Records part of the page.)

Some of the Page Header parts require further explanation:
@itemize @bullet
@item
@code{PAGE_FREE}:

Records which have been freed (due to deletion or migration) are in a
one-way linked list. The @code{PAGE_FREE} pointer in the page header points
to the first record in the list. The "next" pointer in the record
header (specifically, in the record's Extra Bytes) points to the next
record in the list.
@item
@code{PAGE_DIRECTION} and @code{PAGE_N_DIRECTION}:

It's useful to know whether inserts are coming in a constantly
ascending sequence. That can affect @code{InnoDB}'s efficiency.
@item
@code{PAGE_HEAP_TOP} and @code{PAGE_FREE} and @code{PAGE_LAST_INSERT}:

Warning: Like all record pointers, these point not to the beginning of the
record but to its Origin (see the earlier discussion of Record
Structure).
@item
@code{PAGE_BTR_SEG_LEAF} and @code{PAGE_BTR_SEG_TOP}:

These variables contain information (space ID, page number, and byte offset) about
index node file segments. @code{InnoDB} uses the information for allocating new pages. 
There are two different variables because @code{InnoDB} allocates separately for leaf 
pages and upper-level pages.
@end itemize

@node InnoDB infimum and supremum records, InnoDB user records, InnoDB page header, InnoDB page overview
@subsection The Infimum and Supremum Records

"Infimum" and "supremum" are real English words but they are found
only in arcane mathematical treatises, and in @code{InnoDB} comments. To
@code{InnoDB}, an infimum is lower than the the lowest possible real value
(negative infinity) and a supremum is greater than the greatest
possible real value (positive infinity). @code{InnoDB} sets up an infimum
record and a supremum record automatically at page-create time, and
never deletes them. They make a useful barrier to navigation so that
"get-prev" won't pass the beginning and "get-next" won't pass the end.
Also, the infimum record can be a dummy target for temporary record
locks.

The @code{InnoDB} code comments distinguish between "the infimum and supremum
records" and the "user records" (all other kinds).

It's sometimes unclear whether @code{InnoDB} considers the infimum and
supremum to be part of the header or not. Their size is fixed and
their position is fixed, so I guess so.

@node InnoDB user records, InnoDB free space, InnoDB infimum and supremum records, InnoDB page overview
@subsection User Records

In the User Records part of a page, you'll find all the records that the user
inserted.

There are two ways to navigate through the user records, depending
whether you want to think of their organization as an unordered or an
ordered list.

An unordered list is often called a "heap". If you make a pile of
stones by saying "whichever one I happen to pick up next will go on
top" --- rather than organizing them according to size and colour --
then you end up with a heap. Similarly, @code{InnoDB} does not want to insert
new rows according to the B-tree's key order (that would involve
expensive shifting of large amounts of data), so it inserts new rows
right after the end of the existing rows (at the
top of the Free Space part) or wherever there's space left by a
deleted row.

But by definition the records of a B-tree must be accessible in order
by key value, so there is a record pointer in each record (the "next"
field in the Extra Bytes) which points to the next record in key
order. In other words, the records are a one-way linked list. So
@code{InnoDB} can access rows in key order when searching.

@node InnoDB free space, InnoDB page directory, InnoDB user records, InnoDB page overview
@subsection Free Space

I think it's clear what the Free Space part of a page is, from the discussion of
other parts.

@node InnoDB page directory, InnoDB fil trailer, InnoDB free space, InnoDB page overview
@subsection Page Directory

The Page Directory part of a page has a variable number of record pointers.
Sometimes the record pointers are called "slots" or "directory slots".
Unlike other DBMSs, @code{InnoDB} does not have a slot for every record in
the page. Instead it keeps a sparse directory. In a fullish page, 
there will be one slot for every six records.

The slots track the records' logical order (the order by key rather
than the order by placement on the heap). Therefore, if the records
are @code{'A' 'B' 'F' 'D'} the slots will be @code{(pointer to 'A') (pointer to
'B') (pointer to 'D') (pointer to 'F')}. Because the slots are in key
order, and each slot has a fixed size, it's easy to do a binary
search of the records on the page via the slots.

(Since the Page Directory does not have a slot for every record,
binary search can only give a rough position and then @code{InnoDB} must
follow the "next" record pointers. @code{InnoDB}'s "sparse slots" policy also
accounts for the n_owned field in the Extra Bytes part of a record:
n_owned indicates how many more records must be gone through because
they don't have their own slots.)

@node InnoDB fil trailer,  , InnoDB page directory, InnoDB page overview
@subsection Fil Trailer

The Fil Trailer has one part, as follows:

@multitable @columnfractions .25 .10 .65

@item @strong{Name} @tab @strong{Size} @tab @strong{Remarks}
@item @code{FIL_PAGE_END_LSN}
@tab 8
@tab low 4 bytes = checksum of page, last 4 bytes = same as @code{FIL_PAGE_LSN}
@end multitable

The final part of a page, the fil trailer (or File Page Trailer),
exists because @code{InnoDB}'s architect worried about integrity. It's
impossible for a page to be only half-written, or corrupted by
crashes, because the log-recovery mechanism restores to a consistent
state. But if something goes really wrong, then it's nice to have a
checksum, and to have a value at the very end of the page which must
be the same as a value at the very beginning of the page.

@node InnoDB page example, InnoDB more page information, InnoDB page overview, InnoDB Page Structure
@section Example

For this example, I used Borland's TDUMP again, as I did for the earlier chapter on
Record Format. This is what a page looked like:

@multitable @columnfractions .65 .35

@item @strong{Address Values in Hexadecimal} @tab @strong{Values in ASCII}
@item @code{0D4000: 00 00 00 00 00 00 00 35 FF FF FF FF FF FF FF FF}
@tab @code{.......5........}
@item @code{0D4010: 00 00 00 00 00 00 E2 64 45 BF 00 00 00 00 00 00}
@tab @code{.......dE.......}
@item @code{0D4020: 00 00 00 00 00 00 00 05 02 F5 00 12 00 00 00 00}
@tab @code{................}
@item @code{0D4030: 02 E1 00 02 00 0F 00 10 00 00 00 00 00 00 00 00}
@tab @code{................}
@item @code{0D4040: 00 00 00 00 00 00 00 00 00 14 00 00 00 00 00 00}
@tab @code{................}
@item @code{0D4050: 00 02 16 B2 00 00 00 00 00 00 00 02 15 F2 08 01}
@tab @code{................}
@item @code{0D4060: 00 00 03 00 89 69 6E 66 69 6D 75 6D 00 09 05 00}
@tab @code{.....infimum....}
@item @code{0D4070: 08 03 00 00 73 75 70 72 65 6D 75 6D 00 22 1D 18}
@tab @code{....supremum."..}
@item @code{0D4080: 13 0C 06 00 00 10 0D 00 B7 00 00 00 00 04 14 00}
@tab @code{................}
@item @code{0D4090: 00 00 00 09 1D 80 00 00 00 2D 00 84 41 41 41 41}
@tab @code{.........-..AAAA}
@item @code{0D40A0: 41 41 41 41 41 41 41 41 41 41 41 1F 1B 17 13 0C}
@tab @code{AAAAAAAAAAA.....}
@item @code{ ... }
@item @code{ ... }
@item @code{0D7FE0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 74}
@tab @code{...............t}
@item @code{0D7FF0: 02 47 01 AA 01 0A 00 65 3A E0 AA 71 00 00 E2 64}
@tab @code{.G.....e:..q...d}
@end multitable

Let's skip past the first 38 bytes, which are Fil Header. The bytes
of the Page Header start at location @code{0d4026 hexadecimal}:

@multitable @columnfractions .25 .25 .50

@item @strong{Location} @tab @strong{Name} @tab @strong{Description}
@item @code{00 05}
@tab @code{PAGE_N_DIR_SLOTS}
@tab There are 5 directory slots.
@item @code{02 F5}
@tab @code{PAGE_HEAP_TOP}
@tab At location @code{0402F5}, not shown, is the beginning of free space.
Maybe a better name would have been @code{PAGE_HEAP_END}.
@item @code{00 12}
@tab @code{PAGE_N_HEAP}
@tab There are 18 (hexadecimal 12) records in the page.
@item @code{00 00}
@tab @code{PAGE_FREE}
@tab There are zero free (deleted) records.
@item @code{00 00}
@tab @code{PAGE_GARBAGE}
@tab There are zero bytes in deleted records.
@item @code{02 E1}
@tab @code{PAGE_LAST_INSERT}
@tab The last record was inserted at location @code{02E1}, not shown, within the page.
@item @code{00 02}
@tab @code{PAGE_DIRECTION}
@tab A glance at page0page.h will tell you that 2 is the #defined value for @code{PAGE_RIGHT}.
@item @code{00 0F}
@tab @code{PAGE_N_DIRECTION}
@tab The last 15 (hexadecimal 0F) inserts were all done "to the right"
because I was inserting in ascending order.
@item @code{00 10}
@tab @code{PAGE_N_RECS}
@tab There are 16 (hexadecimal 10) user records. Notice that
@code{PAGE_N_RECS} is
smaller than the earlier field, @code{PAGE_N_HEAP}.
@item @code{00 00 00 00 00 00 00}
@tab @code{PAGE_MAX_TRX_ID}
@item @code{00 00}
@tab @code{PAGE_LEVEL}
@tab Zero because this is a leaf page.
@item @code{00 00 00 00 00 00 00 14}
@tab @code{PAGE_INDEX_ID}
@tab This is index number 20.
@item @code{00 00 00 00 00 00 00 02 16 B2}
@tab @code{PAGE_BTR_SEG_LEAF}
@item @code{00 00 00 00 00 00 00 02 15 F2}
@tab @code{PAGE_BTR_SEG_TOP}
@end multitable

Immediately after the page header are the infimum and supremum
records. Looking at the "Values In ASCII" column in the hexadecimal
dump, you will see that the contents are in fact the words "infimum"
and "supremum" respectively.

Skipping past the User Records and the Free Space, many bytes later,
is the end of the 16KB page. The values shown there are the two trailers.
@itemize @bullet
@item
The first trailer (@code{00 74, 02 47, 01 AA, 01 0A, 00 65}) is the page
directory. It has 5 entries, because the header field @code{PAGE_N_DIR_SLOTS}
says there are 5.
@item
The next trailer (@code{3A E0 AA 71, 00 00 E2 64}) is the fil trailer. Notice
that the last four bytes, @code{00 00 E2 64}, appeared before in the fil
header.
@end itemize

@node InnoDB more page information,  , InnoDB page example, InnoDB Page Structure
@section Where to Look For More Information

@strong{References:}

The most relevant @code{InnoDB} source-code files are @file{page0page.c},
@file{page0page.ic}, and @file{page0page.h} in the @file{page} directory.

@node Error message, Files in MySQL Sources, InnoDB Page Structure, Top
@chapter Adding New Error Messages to MySQL

To add new error messages, use the following procedure:

@itemize @bullet
@item
Open the file @file{sql/share/english/errmsg.txt} in an editor.
@item
Add new error messages at the end of this file. Each message should be
on a separate line, it should be quoted within double quote (@samp{"})
characters and should end with a @samp{,} following the second double quote.
@item
For each new error message, add a define to the file
@file{include/mysqld_error.h} before the last line (@code{#define
ER_ERROR_MESSAGES}).
@item
Adjust the value of @code{ER_ERROR_MESSAGES} to the new number of error
messages.
@item
Add the defined error symbols to @file{include/sql_state.h}.
It contains the SQL states for the error messages. 
If the new errors don't have SQL states, add a comment instead.
Note that this file must be kept sorted according to the
value of the error number.
That is, although the @file{sql_state.h} file might not contain an entry for
every symbol in @file{mysqld_error.h}, those entries that are present in
@file{sql_state.h} must appear in the same order as those for the
corresponding entries in @file{mysqld_error.h}.
@item
Go to the @file{sql} directory in a terminal window and type @code{./add_errmsg
#}. This will copy the last @code{#} error messages from
@file{share/english.txt} to all the other language files in
@file{share/}.
@item
Translate the error message in the languages you know by editing the files
@code{share/XXXXXX/errmsg.txt}.
@item
Make a full build @code{(configure + make)}.
A @code{make all} is insufficient to build @file{sql/share/*/errmsg.sys}.
@end itemize

The maximum error message length is @code{MYSQL_ERRMSG_SIZE} = 512. Ensure by
using constructs such as @code{"%s-.64s"} that there are no buffer overflows!

@strong{Note}: you should NEVER add parameters (such as %s) to existing error
messages. Error messages are always backward compatible, and if a parameter
is added, older servers will crash.

@node Files in MySQL Sources, Files in InnoDB Sources, Error message, Top
@chapter Annotated List of Files in the MySQL Source Code Distribution

@menu
* Source directory listing::    Directory Listing
@end menu

This is a description of the files that you get when you download the
source code of MySQL. This description begins with a list
of the main directories and a short comment about each one. Then, for
each directory, in alphabetical order, a longer description is
supplied. When a directory contains significant program files, a list of each C
program is given along with an explanation of its intended function.

@node Source directory listing,  , Files in MySQL Sources, Files in MySQL Sources
@section Directory Listing

@menu
* BDB directory::               The @file{BDB} Directory
* BitKeeper directory::         The @file{BitKeeper} Directory
* BUILD directory::             The @file{BUILD} Directory
* Build-tools directory::       The @file{Build-tools} Directory
* client directory::            The @file{client} Directory
* cmd-line-utils directory::    The @file{cmd-line-utils} Directory
* dbug directory::              The @file{dbug} Directory
* Docs directory::              The @file{Docs} Directory
* extra directory::             The @file{extra} Directory
* heap directory::              The @file{heap} Directory
* include directory::           The @file{include} Directory
* innobase directory::          The @file{innobase} Directory
* libmysql directory::          The @file{libmysql} Directory
* libmysql_r directory::        The @file{libmysql_r} Directory
* libmysqld directory::         The @file{libmysqld} Directory
* man directory::               The @file{man} Directory
* myisam directory::            The @file{myisam} Directory
* myisammrg directory::         The @file{myisammrg} Directory
* mysql-test directory::        The @file{mysql-test} Directory
* mysys directory::             The @file{mysys} Directory
* netware directory::           The @file{netware} Directory
* NEW-RPMS directory::          The @file{NEW-RPMS} Directory
* os directory::                The @file{os2} Directory
* pstack directory::            The @file{pstack} Directory
* regex directory::             The @file{regex} Directory
* SCCS directory::              The @file{SCCS} Directory
* scripts directory::           The @file{scripts} Directory
* sql directory::               The @file{sql} Directory
* sql-bench directory::         The @file{sql-bench} Directory
* SSL directory::               The @file{SSL} Directory
* strings directory::           The @file{strings} Directory
* support-files directory::     The @file{support-files} Directory
* tests directory::             The @file{tests} Directory
* tools directory::             The @file{tools} Directory
* VC++Files directory::         The @file{VC++Files} Directory
* vio directory::               The @file{vio} Directory
* zlib directory::              The @file{zlib} Directory
@end menu

@strong{Directory  --  Short Comment}
@itemize @bullet
@item
bdb  --  The Berkeley Database table handler
@item
BitKeeper  --  BitKeeper administration (not part of the source distribution)
@item
BUILD  --  Frequently used build scripts
@item
Build-tools  --  Build tools (not part of the source distribution)
@item
client  --  Client library
@item
cmd-line-utils  --  Command-line utilities (libedit and readline)
@item
dbug  --  Fred Fish's dbug library
@item
Docs  --  Preliminary documents about internals and new modules; will eventually be moved to the mysqldoc repository
@item
extra  --  Some minor standalone utility programs
@item
heap  --  The HEAP table handler
@item
include  --  Header (*.h) files for most libraries; includes all header files distributed with the MySQL binary distribution
@item
innobase  --  The Innobase (InnoDB) table handler
@item
libmysql  --  For producing MySQL as a library (e.g. a Windows .DLL)
@item
libmysql_r  --  For building a thread-safe libmysql library
@item
libmysqld  --  The MySQL Server as an embeddable library
@item
man  --  Some user-contributed manual pages
@item
myisam  --  The @code{MyISAM} table handler 
@item
myisammrg  --  The @code{MyISAM} Merge table handler 
@item
mysql-test  --  A test suite for mysqld 
@item
mysys  --  MySQL system library (Low level routines for file access etc.)
@item
netware  --  Files related to the Novell NetWare version of MySQL 
@item
NEW-RPMS  --  Directory to place RPMs while making a distribution
@item
os2  --  Routines for working with the OS/2 operating system
@item
pstack  --  Process stack display (not currently used)
@item
regex  --  Henry Spencer's Regular Expression library for support of REGEXP function
@item
SCCS  --  Source Code Control System (not part of source distribution)
@item
scripts  --  SQL batches, e.g. mysqlbug and mysql_install_db
@item
sql  --  Programs for handling SQL commands; the "core" of MySQL 
@item
sql-bench  --  The MySQL benchmarks 
@item
SSL  --  Secure Sockets Layer; includes an example certification one can use to test an SSL (secure) database connection
@item
strings  --  Library for C string routines, e.g. atof, strchr 
@item
support-files  --  Files used to build MySQL on different systems
@item
tests  --  Tests in Perl and in C
@item
tools  --  mysqlmanager.c (tool under development, not yet useful)
@item
VC++Files  --  Includes this entire directory, repeated for VC++ (Windows) use
@item
vio  --  Virtual I/O Library 
@item
zlib  --  Data compression library, used on Windows
@end itemize

@node BDB directory, BitKeeper directory, Source directory listing, Source directory listing
@subsection The @file{BDB} Directory

The Berkeley Database table handler.

The Berkeley Database (BDB) is maintained by Sleepycat Software.
MySQL AB maintains only a few small patches to make BDB work
better with MySQL.

The documentation for BDB is available at
http://www.sleepycat.com/docs/. Since it's reasonably thorough
documentation, a description of the BDB program files is not included
in this document.

@node BitKeeper directory, BUILD directory, BDB directory, Source directory listing
@subsection The @file{BitKeeper} Directory

BitKeeper administration.

Bitkeeper administration is not part of the source distribution. This 
directory may be present if you downloaded the MySQL source using
BitKeeper rather than via the mysql.com site. The files in the
BitKeeper directory are for maintenance purposes only -- they are not
part of the MySQL package.

The MySQL Reference Manual explains how to use Bitkeeper to get the
MySQL source. Please see @url{http://www.mysql.com/doc/en/Installing_source_tree.html}
for more information.

@node BUILD directory, Build-tools directory, BitKeeper directory, Source directory listing
@subsection The @file{BUILD} Directory

Frequently used build scripts.

This directory contains the build switches for compilation on various
platforms. There is a subdirectory for each set of options. The main
ones are:
@itemize @bullet
@item
alpha
@item
ia64
@item
pentium (with and without debug or bdb, etc.)
@item
solaris
@end itemize

@node Build-tools directory, client directory, BUILD directory, Source directory listing
@subsection The @file{Build-tools} Directory

Build tools.

Build-tools is not part of the source distribution. This directory
contains batch files for extracting, making directories, and making
programs from source files. There are several subdirectories with
different scripts -- for building Linux executables, for compiling,
for performing all build steps, and so on.

@node client directory, cmd-line-utils directory, Build-tools directory, Source directory listing
@subsection The @file{client} Directory

Client library.

The client library includes @file{mysql.cc} (the source of the @code{mysql}
executable) and other utilities. Most of the utilities are mentioned
in the MySQL Reference Manual. Generally these are standalone C
programs which one runs in "client mode", that is, they call the
server.

The C program files in the directory are:
@itemize @bullet
@item
get_password.c  --  ask for a password from the console
@item
mysql.cc  --  "The MySQL command tool"
@item
mysqladmin.c  --  maintenance of MySQL databases
@item
mysqlcheck.c  --  check all databases, check connect, etc.
@item
mysqldump.c  --  dump table's contents as SQL statements, suitable to backup a MySQL database
@item
mysqlimport.c  --  import text files in different formats into tables
@item
mysqlmanager-pwgen.c  --  pwgen stands for "password generation" (not currently maintained)
@item
mysqlmanagerc.c  --  entry point for mysql manager (not currently maintained)
@item
mysqlshow.c  --  show databases, tables or columns 
@item
mysqltest.c  --  test program used by the mysql-test suite, mysql-test-run
@item
password.c  --  password checking routines (version 4.1 and up)
@end itemize

@node cmd-line-utils directory, dbug directory, client directory, Source directory listing
@subsection The @file{cmd-line-utils} Directory

Command-line utilities (libedit and readline).

There are two subdirectories: @file{\readline} and @file{\libedit}. All
the files here are "non-MySQL" files, in the sense that MySQL AB didn't
produce them, it just uses them. It should be unnecessary to study the
programs in these files unless you are writing or debugging a tty-like
client for MySQL, such as @code{mysql.exe}.

The @file{\readline} subdirectory contains the files of the GNU Readline
Library, "a library for reading lines of text with interactive input
and history editing". The programs are copyrighted by the Free
Software Foundation.

The @file{\libedit} (library of edit functions) subdirectory has files
written by Christos Zoulas. They are distributed and modifed under
the BSD License. These files are for editing the line contents.

These are the program files in the \libedit subdirectory:
@itemize @bullet
@item
chared.c  --  character editor
@item
common.c  --  common editor functions
@item
el.c  --  editline interface functions
@item
emacs.c  --  emacs functions
@item
fgetln.c  --  get line
@item
hist.c  --  history access functions
@item
history.c  --  more history access functions
@item
key.c  --  procedures for maintaining the extended-key map
@item
map.c  --  editor function definitions
@item
parse.c  --  parse an editline extended command
@item
prompt.c  --  prompt printing functions
@item
read.c  --  terminal read functions
@item
readline.c  --  read line
@item
refresh.c  --  "lower level screen refreshing functions"
@item
search.c  --  "history and character search functions"
@item
sig.c  --  for signal handling
@item
strlcpy.c  --  string copy
@item
term.c  --  "editor/termcap-curses interface"
@item
tokenizer.c  --  Bourne shell line tokenizer
@item
tty.c  --  for a tty interface
@item
vi.c  --  commands used when in the vi (editor) mode
@end itemize

@node dbug directory, Docs directory, cmd-line-utils directory, Source directory listing
@subsection The @file{dbug} Directory

Fred Fish's dbug library.

This is not really part of the MySQL package. Rather, it's a set of
public-domain routines which are useful for debugging MySQL programs.
The MySQL Server and all .c and .cc programs support the use of this
package.

How it works: One inserts a function call that begins with DBUG_* in
one of the regular MYSQL programs. For example, in get_password.c, you
will find this line:

@example
DBUG_ENTER("get_tty_password");
@end example

at the start of a routine, and this line:

@example
DBUG_RETURN(my_strdup(to,MYF(MY_FAE)));
@end example

at the end of the routine. These lines don't affect production code.
Features of the dbug library include extensive reporting and profiling
(the latter has not been used by the MySQL team).

The C programs in this directory are:
@itemize @bullet
@item
dbug.c  --  The main module
@item
dbug_analyze.c  --  Reads a file produced by trace functions
@item
example1.c  --  A tiny example
@item
example2.c  --  A tiny example
@item
example3.c  --  A tiny example
@item
factorial.c  --  A tiny example
@item
main.c  --  A tiny example
@item
sanity.c  --   Declaration of a variable
@end itemize

@node Docs directory, extra directory, dbug directory, Source directory listing
@subsection The @file{Docs} Directory

Preliminary documents about internals and new modules, which will eventually
be moved to the mysqldoc repository.

This directory doesn't have much at present that's very useful to the
student, but the plan is that some documentation related to the source
files and the internal workings of MySQL, including perhaps some
documentation from developers themselves, will be placed here. Files in
this directory will eventually be moved to the MySQL documentation repository.

These sub-directories are part of this directory:
@itemize @bullet
@item
books  --  .gif images and empty .txt files; no real information
@item
flags  --  images of flags of countries
@item
images  --  flag backgrounds and the MySQL dolphin logo
@item
mysql-logos  --  more MySQL-related logos, some of them moving
@item
raw-flags  --   more country flags, all .gif files
@item
support  --  various files for generating texinfo/docbook documentation
@item
to-be-included...  --  contains a MySQL-for-dummies file
@item
translations  --  some Portuguese myodbc documentation
@end itemize

In the main directory, you'll find some .txt files related to the
methods that MySQL uses to produce its printed and html documents, odd
bits in various languages, and the single file in the directory which
has any importance -- @file{internals.texi} -- The "MySQL Internals"
document.

Despite the name, @file{internals.texi} is not yet much of a description
of MySQL internals although work is in progress to make it so. However,
there is some useful description of the functions in the mysys directory
(see below), and of the structure of client/server messages (doubtless very
useful for eople who want to make their own JDBC drivers, or just sniff).

@node extra directory, heap directory, Docs directory, Source directory listing
@subsection The @file{extra} Directory

Some minor standalone utility programs.

These programs are all standalone utilities, that is, they have
a main() function and their main role is to show information that the
MySQL server needs or produces. Most are unimportant. They are as
follows:
@itemize @bullet
@item
my_print_defaults.c  --  print parameters from my.ini files. Can also be used in scripts to enable processing of my.ini files.
@item
mysql_waitpid.c  --  wait for a program to terminate. Useful for shell scripts when one needs to wait until a process terminates.
@item
perror.c  --  "print error" -- given error number, display message
@item
replace.c  --  replace strings in text files or pipe
@item
resolve_stack_dump.c  --  show symbolic information from a MySQL stack dump, normally found in the mysql.err file
@item
resolveip.c  --  convert an IP address to a hostname, or vice versa
@end itemize

@node heap directory, include directory, extra directory, Source directory listing
@subsection The @file{heap} Directory

The HEAP (MEMORY) table handler.

All the MySQL table handlers (i.e. the handlers that MySQL itself produces)
have files with similar names and functions. Thus, this (heap) directory
contains a lot of duplication of the myisam directory (for the @code{MyISAM}
table handler). Such duplicates have been marked with an "*" in the
following list. For example, you will find that @file{\heap\hp_extra.c}
has a close equivalent in the myisam directory (@file{\myisam\mi_extra.c})
with the same descriptive comment. (Some of the differences arise because
@code{HEAP} has different structures. @code{HEAP} does not need to use the
sort of B-tree indexing that @code{ISAM} and @code{MyISAM} use; instead
there is a hash index. Most importantly, @code{HEAP} is entirely in memory.
File-I/O routines lose some of their vitality in such a context.)

@itemize @bullet
@item
hp_block.c  --  Read/write a block (i.e. a page)
@item
hp_clear.c  --  Remove all records in the table
@item
hp_close.c  --  * close database
@item
hp_create.c  --  * create a table
@item
hp_delete.c  --  * delete a row
@item
hp_extra.c  --  * for setting options and buffer sizes when optimizing
@item
hp_hash.c  --  Hash functions used for saving keys
@item
hp_info.c  --  * Information about database status
@item
hp_open.c  --  * open database
@item
hp_panic.c  --  * the hp_panic routine, for shutdowns and flushes
@item
hp_rename.c  --  * rename a table
@item
hp_rfirst.c  --  * read first row through a specific key (very short)
@item
hp_rkey.c  --  * read record using a key
@item
hp_rlast.c  --  * read last row with same key as previously-read row
@item
hp_rnext.c  --  * read next row with same key as previously-read row
@item
hp_rprev.c  --  * read previous row with same key as previously-read row
@item
hp_rrnd.c  --  * read a row based on position
@item
hp_rsame.c  --  * find current row using positional read or key-based
read
@item
hp_scan.c  --  * read all rows sequentially
@item
hp_static.c  --  * static variables (very short)
@item
hp_test1.c  --  * testing basic functions
@item
hp_test2.c  --  * testing database and storing results
@item
hp_update.c  --  * update an existing row
@item
hp_write.c  --  * insert a new row
@end itemize

There are fewer files in the heap directory than in the myisam
directory, because fewer are necessary. For example, there is no need
for a \myisam\mi_cache.c equivalent (to cache reads) or a
\myisam\log.c equivalent (to log statements).

@node include directory, innobase directory, heap directory, Source directory listing
@subsection The @file{include} Directory

Header (*.h) files for most libraries; includes all header files distributed
with the MySQL binary distribution.

These files may be included in C program files. Note that each
individual directory will also have its own *.h files, for including
in its own *.c programs. The *.h files in the include directory are
ones that might be included from more than one place.

For example, the mysys directory contains a C file named rijndael.c,
but does not include rijndael.h. The include directory contains
rijndael.h. Looking further, you'll find that rijndael.h is also
included in other places: by my_aes.c and my_aes.h.

The include directory contains 51 *.h (header) files.

@node innobase directory, libmysql directory, include directory, Source directory listing
@subsection The @file{innobase} Directory

The Innobase (InnoDB) table handler.

A full description of these files can be found elsewhere in this
document.

@node libmysql directory, libmysql_r directory, innobase directory, Source directory listing
@subsection The @file{libmysql} Directory

The MySQL Library, Part 1.

The files here are for producing MySQL as a library (e.g. a Windows
DLL). The idea is that, instead of producing separate @code{mysql} (client)
and @code{mysqld} (server) programs, one produces a library. Instead of
sending messages, the client part merely calls the server part.

The @code{libmysql} files are split into three directories: @file{libmysql}
(this one), @file{libmysql_r} (the next one), and @file{libmysqld} (the
next one after that).

The "library of mysql" has some client-connection
modules. For example, as described in an earlier
section of this manual, there is a discussion of
@file{libmysql/libmysql.c} which sends packets from the
client to the server. Many of the entries in the
@file{libmysql} directory (and in the following @file{libmysqld}
directory) are 'symlinks' on Linux, that is, they
are in fact pointers to files in other directories.

The program files on this directory are:
@itemize @bullet
@item
conf_to_src.c  --  has to do with charsets
@item
dll.c  --  initialization of the dll library
@item
errmsg.c  --  English error messages, compare \mysys\errors.c
@item
get_password.c  --  get password
@item
libmysql.c  --  the code that implements the MySQL API, i.e. the functions a client that wants to connect to MySQL will call
@item
manager.c  --  initialize/connect/fetch with MySQL manager
@end itemize

@node libmysql_r directory, libmysqld directory, libmysql directory, Source directory listing
@subsection The @file{libmysql_r} Directory

The MySQL Library, Part 2.

There is only one file here, used to build a thread-safe libmysql library:
@itemize @bullet
@item
makefile.am
@end itemize

@node libmysqld directory, man directory, libmysql_r directory, Source directory listing
@subsection The @file{libmysqld} Directory

The MySQL library, Part 3.

The Embedded MySQL Server Library. The product of @code{libmysqld}
is not a client/server affair, but a library. There is a wrapper
to emulate the client calls. The program files on this directory
are:
@itemize @bullet
@item
libmysqld.c  --  The called side, compare the mysqld.exe source
@item
lib_vio.c --  Emulate the vio directory's communication buffer
@end itemize

@node man directory, myisam directory, libmysqld directory, Source directory listing
@subsection The @file{man} Directory

Some user-contributed manual pages

These are user-contributed "man" (manual) pages in a special markup
format. The format is described in a document with a heading like
"man page for man" or "macros to format man pages" which you can find
in a Linux directory or on the Internet.

@node myisam directory, myisammrg directory, man directory, Source directory listing
@subsection The @file{myisam} Directory

The @code{MyISAM} table handler.

The C files in this subdirectory come in six main groups:
@itemize @bullet
@item
ft*.c files  --  ft stands for "Full Text", code contributed by Sergei Golubchik
@item
mi*.c files  --  mi stands for "My Isam", these are the main programs for Myisam
@item
myisam*.c files  --  for example, "myisamchk" utility routine functions source
@item
rt*.c files  --  rt stands for "rtree", some code was written by Alexander Barkov
@item
sp*.c files  --  sp stands for "spatial", some code was written by Ramil Kalimullin
@item
sort.c  --  this is a single file that sorts keys for index-create purposes
@end itemize

The "full text" and "rtree" and "spatial" program sets are for special
purposes, so this document focuses only on the mi*.c "myisam" C
programs. They are:
@itemize @bullet
@item
mi_cache.c  --  for reading records from a cache 
@item
mi_changed.c  --  a single routine for setting a "changed" flag (very short)
@item
mi_check.c  --  for checking and repairing tables. Used by the myisamchk program and by the MySQL server.
@item
mi_checksum.c  --  calculates a checksum for a row 
@item
mi_close.c  --  close database 
@item
mi_create.c  --  create a table 
@item
mi_dbug.c  -- support routines for use with "dbug" (see \dbug description)
@item
mi_delete.c  --  delete a row 
@item
mi_delete_all.c  --  delete all rows 
@item
mi_delete_table.c  --  delete a table (very short)
@item
mi_dynrec.c  --  functions to handle space-packed records and blobs 
@item
mi_extra.c  --  setting options and buffer sizes when optimizing 
@item
mi_info.c  --  return useful base information for an open table
@item
mi_key.c  --  for handling keys
@item
mi_locking.c  --  lock database 
@item
mi_log.c  --  save commands in a log file which myisamlog program can read. Can be used to exactly replay a set of changes to a table.
@item
mi_open.c  --  open database 
@item
mi_packrec.c  --  read from a data file compresed with myisampack
@item
mi_page.c  --  read and write pages containing keys
@item
mi_panic.c  --  the mi_panic routine, probably for sudden shutdowns
@item
mi_range.c  --  approximate count of how many records lie between two keys
@item
mi_rename.c  --  rename a table
@item
mi_rfirst.c  --  read first row through a specific key (very short)
@item
mi_rkey.c  --  read a record using a key
@item
mi_rlast.c  --  read last row with same key as previously-read row
@item
mi_rnext.c  --  read next row with same key as previously-read row
@item
mi_rnext_same.c  --  same as mi_rnext.c, but abort if the key changes
@item
mi_rprev.c  --  read previous row with same key as previously-read row
@item
mi_rrnd.c  --  read a row based on position
@item
mi_rsame.c  --  find current row using positional read or key-based read
@item
mi_rsamepos.c  --  positional read
@item
mi_scan.c  --  read all rows sequentially
@item
mi_search.c  --  key-handling functions
@item
mi_static.c  --  static variables (very short)
@item
mi_statrec.c  --  functions to handle fixed-length records
@item
mi_test1.c  --  testing basic functions
@item
mi_test2.c  --  testing database and storing results
@item
mi_test3.c  --  testing locking
@item
mi_unique.c  --  functions to check if a row is unique
@item
mi_update.c  --  update an existing row
@item
mi_write.c  --  insert a new row
@end itemize

@node myisammrg directory, mysql-test directory, myisam directory, Source directory listing
@subsection The @file{myisammrg} Directory

@code{MyISAM} Merge table handler.

As with other table handlers, you'll find that the @file{*.c} files in
the @file{myissammrg} directory have counterparts in the @file{myisam}
directory. In fact, this general description of a @code{myisammrg} program
is almost always true: The @file{myisammrg} function checks an argument,
the @file{myisammrg} function formulates an expression for passing to
a @file{myisam} function, the @file{myisammrg} calls a @file{myisam}
function, the @file{myisammrg} function returns.

These are the 21 files in the @file{myisammrg} directory, with notes about
the @code{myisam} functions or programs they're connected with:
@itemize @bullet
@item
myrg_close.c  --  mi_close.c 
@item
myrg_create.c  --  mi_create.c 
@item
myrg_delete.c  --  mi_delete.c / delete last-read record 
@item
myrg_extra.c  --  mi_extra.c / "extra functions we want to do ..." 
@item
myrg_info.c  --  mi_info.c / display information about a mymerge file 
@item
myrg_locking.c  --  mi_locking.c / lock databases 
@item
myrg_open.c  --  mi_open.c / open a @code{MyISAM} @code{MERGE} table 
@item
myrg_panic.c  --  mi_panic.c / close in a hurry 
@item
myrg_queue.c  --  read record based on a key 
@item
myrg_range.c  --  mi_range.c / find records in a range 
@item
myrg_rfirst.c  --  mi_rfirst.c / read first record according to
specific key 
@item
myrg_rkey.c  --  mi_rkey.c / read record based on a key 
@item
myrg_rlast.c  --  mi_rlast.c / read last row with same key as previous
read 
@item
myrg_rnext.c  --  mi_rnext.c / read next row with same key as previous
read 
@item
myrg_rnext_same.c  --  mi_rnext_same.c / read next row with same key
@item
myrg_rprev.c  --  mi_rprev.c / read previous row with same key 
@item
myrg_rrnd.c  --  mi_rrnd.c / read record with random access 
@item
myrg_rsame.c  --  mi_rsame.c / call mi_rsame function, see
\myisam\mi_rsame.c 
@item
myrg_static.c  --  mi_static.c / static variable declaration 
@item
myrg_update.c  --  mi_update.c / call mi_update function, see
\myisam\mi_update.c 
@item
myrg_write.c  --  mi_write.c / call mi_write function, see
\myisam\mi_write.c 
@end itemize

@node mysql-test directory, mysys directory, myisammrg directory, Source directory listing
@subsection The @file{mysql-test} Directory

A test suite for @command{mysqld}.

The directory has a @file{README} file which explains how to run the tests,
how to make new tests (in files with the filename extension @file{*.test}),
and how to report errors.

There are four subdirectories:
@itemize @bullet
@item
\misc  --  contains one minor Perl program
@item
\r  --  contains *.result, i.e. "what happened" files and
*.required, i.e. "what should happen" file
@item
\std_data  --  contains standard data for input to tests
@item
\t  --  contains tests
@end itemize

There are 186 @file{*.test} files in the @file{\t} subdirectory. Primarily
these are SQL scripts which try out a feature, output a result, and compare
the result with what's required. Some samples of what the test files check
are: latin1_de comparisons, date additions, the @code{HAVING} clause,
outer joins, openSSL, load data, logging, truncate, and @code{UNION}.

There are other tests in these directories:
@itemize @bullet
@item
sql-bench
@item
tests
@end itemize

@node mysys directory, netware directory, mysql-test directory, Source directory listing
@subsection The @file{mysys} Directory

MySQL system library. Low level routines for file access and so on.

There are 115 *.c programs in this directory:
@itemize @bullet
@item
array.c  --  Dynamic array handling 
@item
charset.c  --  Using dynamic character sets, set default character set, ...
@item
charset2html.c  --  Check what character set a browser is using
@item
checksum.c  --  Calculate checksum for a memory block, used for pack_isam
@item
default.c  --  Find defaults from *.cnf or *.ini files 
@item
errors.c  --  English text of global errors 
@item
hash.c  --  Hash search/compare/free functions "for saving keys" 
@item
list.c  --  Double-linked lists 
@item
make-conf.c  --  "Make a charset .conf file out of a ctype-charset.c file"
@item
md5.c  --  MD5 ("Message Digest 5") algorithm from RSA Data Security
@item
mf_brkhant.c  --  Prevent user from doing a Break during critical execution
(not used in MySQL; can be used by standalone @code{MyISAM} applications)
@item
mf_cache.c  --  "Open a temporary file and cache it with io_cache"
@item
mf_dirname.c  --  Parse/convert directory names
@item
mf_fn_ext.c  --  Get filename extension
@item
mf_format.c  --  Format a filename
@item
mf_getdate.c  --  Get date, return in yyyy-mm-dd hh:mm:ss format
@item
mf_iocache.c  --  Cached read/write of files in fixed-size units
@item
mf_iocache2.c  --  Continuation of mf_iocache.c
@item
mf_keycache.c  --  Key block caching for certain file types
@item
mf_loadpath.c  --  Return full path name (no ..\ stuff)
@item
mf_pack.c  --  Packing/unpacking directory names for create purposes
@item
mf_path.c  --  Determine where a program can find its files
@item
mf_qsort.c  --  Quicksort
@item
mf_qsort2.c  --  Quicksort, part 2 (allows the passing of an extra argument to the sort-compare routine)
@item
mf_radix.c  --  Radix sort
@item
mf_same.c  --  Determine whether filenames are the same
@item
mf_sort.c  --  Sort with choice of Quicksort or Radix sort
@item
mf_soundex.c  --  Soundex algorithm derived from EDN Nov. 14, 1985 (pg. 36)
@item
mf_strip.c  --  Strip trail spaces from a string
@item
mf_tempdir.c  --  Initialize/find/free temporary directory
@item
mf_tempfile.c  --  Create a temporary file
@item
mf_unixpath.c  --  Convert filename to UNIX-style filename 
@item
mf_util.c  --  Routines, #ifdef'd, which may be missing on some
machines 
@item
mf_wcomp.c  --  Comparisons with wildcards 
@item
mf_wfile.c  --  Finding files with wildcards 
@item
mulalloc.c  --  Malloc many pointers at the same time 
@item
my_aes.c  --  AES encryption 
@item
my_alarm.c  --  Set a variable value when an alarm is received 
@item
my_alloc.c  --  malloc of results which will be freed simultaneously
@item
my_append.c  --  one file to another 
@item
my_bit.c  --  smallest X where 2^X >= value, maybe useful for
divisions 
@item
my_bitmap.c  --  Handle uchar arrays as large bitmaps 
@item
my_chsize.c  --  Truncate file if shorter, else fill with a filler
character 
@item
my_clock.c  --  Time-of-day ("clock()") function, with OS-dependent
#ifdef's  
@item
my_compress.c  --  Compress packet (see also description of \zlib
directory)
@item
my_copy.c  --  Copy files 
@item
my_create.c  --  Create file 
@item
my_delete.c  --  Delete file 
@item
my_div.c  --  Get file's name 
@item
my_dup.c  --  Open a duplicated file 
@item
my_error.c  --  Return formatted error to user 
@item
my_fopen.c  --  File open 
@item
my_fstream.c  --  Streaming file read/write 
@item
my_getwd.c  --  Get working directory 
@item
my_gethostbyname.c  --  Thread-safe version of standard net
gethostbyname() func 
@item
my_getopt.c  --  Find out what options are in effect 
@item
my_handler.c  --  Compare two keys in various possible formats 
@item
my_init.c  --  Initialize variables and functions in the mysys library
@item
my_lib.c  --  Compare/convert directory names and file names 
@item
my_lock.c  --  Lock part of a file 
@item
my_lockmem.c  --  "Allocate a block of locked memory" 
@item
my_lread.c  --  Read a specified number of bytes from a file into
memory 
@item
my_lwrite.c  --  Write a specified number of bytes from memory into a
file 
@item
my_malloc.c  --  Malloc (memory allocate) and dup functions 
@item
my_messnc.c  --  Put out a message on stderr with "no curses" 
@item
my_mkdir.c  --  Make directory 
@item
my_net.c  --  Thread-safe version of net inet_ntoa function 
@item
my_netware.c  --  Functions used only with the Novell Netware version
of MySQL 
@item
my_once.c  --  Allocation / duplication for "things we don't need to
free" 
@item
my_open.c  --  Open a file 
@item
my_os2cond.c  --  OS2-specific: "A simple implementation of posix conditions"
@item
my_os2dirsrch.c  --  OS2-specific: Emulate a Win32 directory search 
@item
my_os2dlfcn.c  --  OS2-specific: Emulate UNIX dynamic loading 
@item
my_os2file64.c  --  OS2-specific: For File64bit setting 
@item
my_os2mutex.c  --  OS2-specific: For mutex handling 
@item
my_os2thread.c  --  OS2-specific: For thread handling 
@item
my_os2tls.c  --  OS2-specific: For thread-local storage 
@item
my_port.c  --  OS/machine-dependent porting functions, e.g. AIX-specific my_ulonglong2double()
@item
my_pread.c  --  Read a specified number of bytes from a file 
@item
my_pthread.c  --  A wrapper for thread-handling functions in different OSs
@item
my_quick.c  --  Read/write (labeled a "quicker" interface, perhaps
obsolete)
@item
my_read.c  --  Read a specified number of bytes from a file, possibly
retry 
@item
my_realloc.c  --  Reallocate memory allocated with my_alloc.c
(probably)
@item
my_redel.c  --  Rename and delete file 
@item
my_rename.c  --  Rename without delete 
@item
my_seek.c  --  Seek, i.e. point to a spot within a file 
@item
my_semaphore.c  --  Semaphore routines, for use on OS that doesn't support them
@item
my_sleep.c  --  Wait n microseconds 
@item
my_static.c  --  Static variables used by the mysys library
@item
my_symlink.c  --  Read a symbolic link (symlinks are a UNIX thing, I guess)
@item
my_symlink2.c  --  Part 2 of my_symlink.c
@item
my_tempnam.c  --  Obsolete temporary-filename routine used by ISAM table handler
@item
my_thr_init.c  --  initialize/allocate "all mysys & debug thread variables"
@item
my_wincond.c  --  Windows-specific: emulate Posix conditions
@item
my_winsem.c  --  Windows-specific: emulate Posix threads
@item
my_winthread.c  --  Windows-specific: emulate Posix threads
@item
my_write.c  --  Write a specified number of bytes to a file
@item
ptr_cmp.c  --  Point to an optimal byte-comparison function
@item
queues.c  --  Handle priority queues as in Robert Sedgewick's book
@item
raid2.c  --  RAID support (the true implementation is in raid.cc)
@item
rijndael.c  --  "Optimized ANSI C code for the Rijndael cipher (now AES")
@item
safemalloc.c  --  A version of the standard malloc() with safety checking
@item
sha1.c  --  Implementation of Secure Hashing Algorithm 1
@item
string.c  --  Initialize/append/free dynamically-sized strings; see also sql_string.cc in the /sql directory
@item
testhash.c  --  Standalone program: test the hash library routines
@item
test_charset.c  --  Standalone program: display character set information
@item
test_dir.c  --  Standalone program: placeholder for "test all functions" idea
@item
test_fn.c  --  Standalone program: apparently tests a function
@item
test_xml.c  --  Standalone program: test XML routines
@item
thr_alarm.c  --  Thread alarms and signal handling
@item
thr_lock.c  --  "Read and write locks for Posix threads"
@item
thr_mutex.c  --  A wrapper for mutex functions
@item
thr_rwlock.c  --  Synchronizes the readers' thread locks with the writer's lock
@item
tree.c  --  Initialize/search/free binary trees
@item
typelib.c  --  Find a string in a set of strings; returns the offset to the string found
@end itemize

You can find documentation for the main functions in these files
elsewhere in this document. For example, the main functions in
@file{my_getwd.c} are described thus:

@example
"int my_getwd _A((string buf, uint size, myf MyFlags));
     int my_setwd _A((const char *dir, myf MyFlags));
     Get and set working directory."
@end example

@node netware directory, NEW-RPMS directory, mysys directory, Source directory listing
@subsection The @file{netware} Directory

Files related to the Novell NetWare version of MySQL.

There are 39 files on this directory. Most have filename extensions of
@file{*.def}, @file{*.sql}, or @file{*.c}.

The twenty-five @file{*.def} files are all from Novell Inc. They contain import or
export symbols. (@file{.def} is a common filename extension for "definition".)

The two @file{*.sql} files are short scripts of SQL statements used in
testing.

These are the five *.c files, all from Novell Inc.:
@itemize @bullet
@item
libmysqlmain.c  --  Only one function: init_available_charsets()
@item
my_manage.c  --  Standalone management utility
@item
mysql_install_db.c  --  Compare \scripts\mysql_install_db.sh
@item
mysql_test_run.c  --  Short test program
@item
mysqld_safe.c  --  Compare \scripts\mysqld_safe.sh
@end itemize

Perhaps the most important file is:
@itemize @bullet
@item
netware.patch  --  NetWare-specific build instructions and switches
(compare \mysql-4.1\ltmain.sh)
@end itemize

For instructions about basic installation, see "Deployment Guide For
NetWare AMP" at:
@url{http://developer.novell.com/ndk/whitepapers/namp.htm}

@node NEW-RPMS directory, os directory, netware directory, Source directory listing
@subsection The @file{NEW-RPMS} Directory

Directory to place RPMs while making a distribution.

This directory is not part of the Windows distribution. It is
a temporary directory used during RPM builds with Linux distributions.

@node os directory, pstack directory, NEW-RPMS directory, Source directory listing
@subsection The @file{os2} Directory

Routines for working with the OS2 operating system.

The files in this directory are the product of the efforts of three
people from outside MySQL: Yuri Dario, Timo Maier, and John M
Alfredsson. There are no @file{.C} program files in this directory.

The contents of \os2 are:
@itemize @bullet
@item
A Readme.Txt file
@item
An \include subdirectory containing .h files which are for OS/2 only
@item
Files used in the build process (configuration, switches, and one
.obj)
@end itemize

The README file refers to MySQL version 3.23, which suggests that
there have been no updates for MySQL 4.0 for this section.

@node pstack directory, regex directory, os directory, Source directory listing
@subsection The @file{pstack} Directory

Process stack display (not currently used).

This is a set of publicly-available debugging aids which all do pretty
well the same thing: display the contents of the stack, along with
symbolic information, for a running process. There are versions for
various object file formats (such as ELF and IEEE-695). Most of the
programs are copyrighted by the Free Software Foundation and are
marked as "part of GNU Binutils".

In other words, the pstack files are not really part of the MySQL
library. They are merely useful when you re-program some MYSQL code
and it crashes.

@node regex directory, SCCS directory, pstack directory, Source directory listing
@subsection The @file{regex} Directory

Henry Spencer's Regular Expression library for support of REGEXP function.

This is the copyrighted product of Henry Spencer from the University
of Toronto. It's a fairly-well-known implementation of the
requirements of POSIX 1003.2 Section 2.8. The library is bundled with
Apache and is the default implementation for regular-expression
handling in BSD Unix. MySQL's Monty Widenius has made minor changes in
three programs (debug.c, engine.c, regexec.c) but this is not a MySQL
package. MySQL calls it only in order to support two MySQL functions:
REGEXP and RLIKE.

Some of Mr Spencer's documentation for the regex library can be found
in the README and WHATSNEW files.

One MySQL program which uses regex is \cmd-line-utils\libedit\search.c

This program calls the 'regcomp' function, which is the entry point in
\regex\regexp.c.

@node SCCS directory, scripts directory, regex directory, Source directory listing
@subsection The @file{SCCS} Directory

Source Code Control System (not part of source distribution).

You will see this directory if and only if you used BitKeeper for
downloading the source. The files here are for BitKeeper
administration and are not of interest to application programmers.

@node scripts directory, sql directory, SCCS directory, Source directory listing
@subsection The @file{scripts} Directory

SQL batches, e.g. mysqlbug and mysql_install_db.

The @file{*.sh} filename extension stands for "shell script". Linux
programmers use it where Windows programmers would use a @file{*.bat}
(batch filename extension).

The @file{*.sh} files on this directory are:
@itemize @bullet
@item
fill_help_tables.sh  --  Create help-information tables and insert
@item
make_binary_distribution.sh  --  Get configure information, make, produce tar
@item
msql2mysql.sh  --  Convert (partly) mSQL programs and scripts to MySQL
@item
mysqlbug.sh  --  Create a bug report and mail it
@item
mysqld_multi.sh  --  Start/stop any number of mysqld instances
@item
mysqld_safe-watch.sh  --  Start/restart in safe mode
@item
mysqld_safe.sh  --  Start/restart in safe mode
@item
mysqldumpslow.sh  --  Parse and summarize the slow query log
@item
mysqlhotcopy.sh  --  Hot backup
@item
mysql_config.sh  --  Get configuration information that might be needed to compile a client
@item
mysql_convert_table_format.sh  --  Conversion, e.g. from @code{ISAM} to
@code{MyISAM}
@item
mysql_explain_log.sh  --  Put a log (made with @code{--log}) into a MySQL table
@item
mysql_find_rows.sh  --  Search for queries containing @code{<regexp>}
@item
mysql_fix_extensions.sh  --  Renames some file extensions, not recommended
@item
mysql_fix_privilege_tables.sh  --  Fix @code{mysql.user} etc. when upgrading. Can be safely run during any upgrade to get the newest 
MySQL privilege tables
@item
mysql_install_db.sh  --  Create privilege tables and func table
@item
mysql_secure_installation.sh  --  Disallow remote root login, eliminate test, etc.
@item
mysql_setpermission.sh  --  Aid to add users or databases, sets privileges
@item
mysql_tableinfo.sh  --  Puts info re MySQL tables into a MySQL table
@item
mysql_zap.sh  --  Kill processes that match pattern
@end itemize

@node sql directory, sql-bench directory, scripts directory, Source directory listing
@subsection The @file{sql} Directory

Programs for handling SQL commands. The "core" of MySQL.

These are the @file{.c} and @file{.cc} files in the @file{sql} directory:
@itemize @bullet
@item
convert.cc  --  convert tables between different character sets
@item
derror.cc  --  read language-dependent message file
@item
des_key_file.cc  --  load DES keys from plaintext file
@item
field.cc  --  "implement classes defined in @file{field.h}" (long); defines all storage methods MySQL uses to store field information 
into records that are then passed to handlers
@item
field_conv.cc  --  functions to copy data between fields
@item
filesort.cc  --  sort a result set, using memory or temporary files
@item
frm_crypt.cc  --  contains only one short function: @file{get_crypt_for_frm}
@item
gen_lex_hash.cc  --  Knuth's algorithm from Vol 3 Sorting and Searching, Chapter 6.3; used to search for SQL keywords in a query
@item
gstream.cc  --  GTextReadStream, used to read GIS objects
@item
handler.cc  --  handler-calling functions
@item
hash_filo.cc  --  static-sized hash tables, used to store info like hostname -> ip tables in a FIFO manner
@item
ha_berkeley.cc  --  Handler: BDB
@item
ha_heap.cc  --  Handler: Heap
@item
ha_innodb.cc  --  Handler: InnoDB
@item
ha_isam.cc  --  Handler: ISAM
@item
ha_isammrg.cc  --  Handler: (ISAM MERGE)
@item
ha_myisam.cc  --  Handler: MyISAM
@item
ha_myisammrg.cc  --  Handler: (MyISAM MERGE)
@item
hostname.cc  --  Given IP, return hostname
@item
init.cc  --  Init and dummy functions for interface with unireg
@item
item.cc  --  Item functions
@item
item_buff.cc  --  Buffers to save and compare item values
@item
item_cmpfunc.cc  --  Definition of all compare functions
@item
item_create.cc  --  Create an item. Used by @file{lex.h}.
@item
item_func.cc  --  Numerical functions
@item
item_row.cc  --  Row items for comparing rows and for @code{IN} on rows
@item
item_sum.cc  --  Set functions (@code{SUM()}, @code{AVG()}, etc.)
@item
item_strfunc.cc  --  String functions
@item
item_subselect.cc  --  Item subquery
@item
item_timefunc.cc  --  Date/time functions, e.g. week of year
@item
item_uniq.cc  --  Empty file, here for compatibility reasons
@item
key.cc  --  Functions to create keys from records and compare a key to a key in a record
@item
lock.cc  --  Locks
@item
log.cc  --  Logs
@item
log_event.cc  --  Log event (a binary log consists of a stream of log events)
@item
matherr.c  --  Handling overflow, underflow, etc.
@item
mf_iocache.cc  --  Caching of (sequential) reads and writes
@item
mini_client.cc  --  Client included in server for server-server messaging; used by the replication code
@item
mysqld.cc  --  Source for @code{mysqld.exe}; includes the @code{main()}
program that starts @code{mysqld}, handling of signals and connections
@item
my_lock.c  --  Lock part of a file (like @file{/mysys/my_lock.c}, but with timeout handling for threads)
@item
net_serv.cc  --  Read/write of packets on a network socket
@item
nt_servc.cc  --  Initialize/register/remove an NT service
@item
opt_ft.cc  --  Create a FT or QUICK RANGE based on a key (very short)
@item
opt_range.cc  --  Range of keys
@item
opt_sum.cc  --  Optimize functions in presence of (implied) @code{GROUP BY}
@item
password.c  --  Password checking
@item
procedure.cc  --  Procedure interface, as used in @code{SELECT * FROM
Table_name PROCEDURE ANALYSE()}
@item
protocol.cc  --  Low level functions for PACKING data that is sent to client;
actual sending done with @file{net_serv.cc}
@item
records.cc  --  Functions for easy reading of records, possible through a cache
@item
repl_failsafe.cc  --  Replication fail-save (not yet implemented)
@item
set_var.cc  --  Set and retrieve MySQL user variables
@item
slave.cc  --  Procedures for a slave in a master/slave (replication) relation
@item
spatial.cc  --  Geometry stuff (lines, points, etc.)
@item
sql_acl.cc  --  Functions related to ACL security; checks, stores, retrieves, and deletes MySQL user level privileges
@item
sql_analyse.cc  --  Implements the @code{PROCEDURE ANALYSE()}, which analyzes a query result and returns the 'optimal' data type for each result column
@item
sql_base.cc  --  Basic functions needed by many modules, like opening and closing tables with table cache management
@item
sql_cache.cc  --  SQL query cache, with long comments about how caching works
@item
sql_class.cc  --  SQL class; implements the SQL base classes, of which THD (THREAD object) is the most important
@item
sql_crypt.cc  --  Encode / decode, very short
@item
sql_db.cc  --  Create / drop database
@item
sql_delete.cc  --  The @code{DELETE} statement
@item
sql_derived.cc  --  Derived tables, with long comments
@item
sql_do.cc  --  The @code{DO} statement
@item
sql_error.cc  --  Errors and warnings
@item
sql_handler.cc  --  Implements the @code{HANDLER} interface, which gives direct
access to rows in @code{MyISAM} and @code{InnoDB}
@item
sql_help.cc  --  The @code{HELP} statement
@item
sql_insert.cc  --  The @code{INSERT} statement
@item
sql_lex.cc  --  Does lexical analysis of a query; i.e. breaks a query string into pieces and determines the basic type (number,
string, keyword, etc.) of each piece
@item
sql_list.cc  --  Only list_node_end_of_list, short (the rest of the list class
is implemented in @file{sql_list.h})
@item
sql_load.cc  --  The @code{LOAD DATA} statement
@item
sql_map.cc  --  Memory-mapped files (not yet in use)
@item
sql_manager.cc  --  Maintenance tasks, e.g. flushing the buffers periodically;
used with @code{BDB} table logs
@item
sql_olap.cc  --  @code{ROLLUP}
@item
sql_parse.cc  --  Parse an SQL statement; do initial checks and then jump to the function that should execute the statement
@item
sql_prepare.cc  --  Prepare an SQL statement, or use a prepared statement
@item
sql_repl.cc  --  Replication
@item
sql_rename.cc  --  Rename table
@item
sql_select.cc  --  Select and join optimization
@item
sql_show.cc  --  The @code{SHOW} statement
@item
sql_string.cc  --  String functions: alloc, realloc, copy, convert, etc.
@item
sql_table.cc  --  The @code{DROP TABLE} and @code{ALTER TABLE} statements
@item
sql_test.cc  --  Some debugging information
@item
sql_udf.cc  --  User-defined functions
@item
sql_union.cc  --  The @code{UNION} operator
@item
sql_update.cc  --  The @code{UPDATE} statement
@item
stacktrace.c  --  Display stack trace (Linux/Intel only)
@item
table.cc  --  Table metadata retrieval; read the table definition from a
@file{.frm} file and store it in a TABLE object
@item
thr_malloc.cc  --  Thread-safe interface to @file{/mysys/my_alloc.c}
@item
time.cc  --  Date and time functions
@item
udf_example.cc  --  Example file of user-defined functions
@item
uniques.cc  --  Function to handle quick removal of duplicates
@item
unireg.cc  --  Create a unireg form file (.frm) from a @code{FIELD} and field-info struct
@end itemize

@node sql-bench directory, SSL directory, sql directory, Source directory listing
@subsection The @file{sql-bench} Directory

The MySQL Benchmarks.

This directory has the programs and input files which MySQL uses for
its comparisons of MySQL, PostgreSQL, mSQL, Solid, etc. Since MySQL
publishes the comparative results, it's only right that it should make
available all the material necessary to reproduce all the tests.

There are five subdirectories and sub-subdirectories:
@itemize @bullet
@item
\Comments  --  Comments about results from tests of Access, Adabas, etc.
@item
\Data\ATIS  --  @file{.txt} files containing input data for the "ATIS" tests
@item
\Data\Wisconsin  --  @file{.txt} files containing input data for the "Wisconsin" tests
@item
\Results  --  old test results
@item
\Results-win32  --  old test results from Windows 32-bit tests
@end itemize

There are twenty-four @file{*.sh} (shell script) files, which involve Perl
programs.

There are three @file{*.bat} (batch) files.

There is one README file and one TODO file.

@node SSL directory, strings directory, sql-bench directory, Source directory listing
@subsection The @file{SSL} Directory

Secure Sockets Layer; includes an example certification one can use
test an SSL (secure) database connection.

This isn't a code directory. It contains a short note from Tonu Samuel
(the NOTES file) and seven @file{*.pem} files. PEM stands for "Privacy
Enhanced Mail" and is an Internet standard for adding security to
electronic mail. Finally, there are two short scripts for running
clients and servers over SSL connections.

@node strings directory, support-files directory, SSL directory, Source directory listing
@subsection The @file{strings} Directory

The string library.

Many of the files in this subdirectory are equivalent to well-known
functions that appear in most C string libraries. For those, there is
documentation available in most compiler handbooks.

On the other hand, some of the files are MySQL additions or
improvements. Often the MySQL changes are attempts to optimize the
standard libraries. It doesn't seem that anyone tried to optimize for
recent Pentium class processors, though.

The .C files are:
@itemize @bullet
@item
atof.c  --  ascii-to-float, MySQL version
@item
bchange.c  --  short replacement routine written by Monty Widenius in
1987 
@item
bcmp.c  --  binary compare, rarely used 
@item
bcopy-duff.c  --  block copy: attempt to copy memory blocks faster
than cmemcpy 
@item
bfill.c  --  byte fill, to fill a buffer with (length) copies of a
byte 
@item
bmove.c  --  block move 
@item
bmove512.c  --  "should be the fastest way to move a multiple of 512
bytes" 
@item
bmove_upp.c  --  bmove.c variant, starting with last byte 
@item
bzero.c  --  something like bfill with an argument of 0 
@item
conf_to_src.c  --  reading a configuration file
@item
ctype*.c  --  string handling programs for each char type MySQL
handles 
@item
do_ctype.c  --  display case-conversion and sort-conversion tables 
@item
int2str.c  --  integer-to-string 
@item
is_prefix.c  --  checks whether string1 starts with string2 
@item
llstr.c  --  convert long long to temporary-buffer string, return
pointer 
@item
longlong2str.c  --  ditto, but to argument-buffer 
@item
memcmp.c  --  memory compare 
@item
memset.c  --  memory set 
@item
my_vsnprintf.c  --  variant of printf 
@item
r_strinstr.c  --  see if one string is within another 
@item
str2int.c  --  convert string to integer 
@item
strappend.c  --  fill up a string to n characters
@item
strcat.c  --  concatenate strings 
@item
strcend.c  --  point to where a character C occurs within str, or NULL
@item
strchr.c  --  point to first place in string where character occurs 
@item
strcmp.c  --  compare two strings 
@item
strcont.c  --  point to where any one of a set of characters appears
@item
strend.c  --  point to the '\0' byte which terminates str 
@item
strfill.c  --  fill a string with n copies of a byte 
@item
strinstr.c  --  find string within string 
@item
strlen.c  --  return length of string in bytes 
@item
strmake.c  --  create new string from old string with fixed length, append end \0 if needed
@item
strmov.c  --  move source to dest and return pointer to end
@item
strnlen.c  --  return min(length of string, n)
@item
strnmov.c  --  move source to dest for source size, or for n bytes 
@item
strrchr.c  --  find a character within string, searching from end 
@item
strstr.c  --  find an instance of pattern within source 
@item
strto.c  --  string to long, to long long, to unsigned long, etc. 
@item
strtol.c  --  string to long 
@item
strtoll.c  --  string to long long 
@item
strtoul.c  --  string to unsigned long 
@item
strtoull.c  --  string to unsigned long long 
@item
strxmov.c  --  move a series of concatenated source strings to dest 
@item
strxnmov.c  --  like strxmov.c but with a maximum length n 
@item
str_test.c  --  test of all the string functions encoded in assembler 
@item
udiv.c  --  unsigned long divide, for operating systems that don't support these
@item
xml.c  --  read and parse XML strings; used to read character definition information stored in /sql/share/charsets
@end itemize

There are also four .ASM files -- macros.asm, ptr_cmp.asm,
strings.asm, and strxmov.asm -- which can replace some of the
C-program functions. But again, they look like optimizations for old
members of the Intel processor family.

@node support-files directory, tests directory, strings directory, Source directory listing
@subsection The @file{support-files} Directory

Files used to build MySQL on different systems.

The files here are for building ("making") MySQL given a package
manager, compiler, linker, and other build tools. The support files
provide instructions and switches for the build processes. They 
include example my.cnf files one can use as a default setup for
MySQL.

@node tests directory, tools directory, support-files directory, Source directory listing
@subsection The @file{tests} Directory

Tests in Perl and in C.

The files in this directory are test programs that can be used 
as a base to write a program to simulate problems in MySQL in various
scenarios: forks, locks, big records, exporting, truncating, and so on. 
Some examples are:
@itemize @bullet
@item
connect_test.c  --  test that a connect is possible
@item
insert_test.c  --  test that an insert is possible
@item
list_test.c  --  test that a select is possible
@item
select_test.c  --  test that a select is possible
@item
showdb_test.c  --  test that a show-databases is possible
@item
ssl_test.c  --  test that SSL is possible
@item
thread_test.c  --  test that threading is possible
@end itemize

@node tools directory, VC++Files directory, tests directory, Source directory listing
@subsection The @file{tools} Directory

Tools -- well, actually, one tool.

The only file is:
@itemize @bullet
@item
mysqlmanager.c  --  A "server management daemon" by Sasha Pachev. This
is a tool under development and is not yet useful. Related to fail-safe 
replication.
@end itemize

@node VC++Files directory, vio directory, tools directory, Source directory listing
@subsection The @file{VC++Files} Directory

Visual C++ Files.

Includes this entire directory, repeated for VC++ (Windows) use.

VC++Files includes a complete environment to compile MySQL with the VC++
compiler. To use it, just copy the files on this directory; the make_win_src_distribution.sh
script uses these files to create a Windows source installation.

This directory has subdirectories which are copies of the main directories.
For example, there is a subdirectory \VC++Files\heap, which has the Microsoft
developer studio project file to compile \heap with VC++. So for a description 
of the files in \VC++Files\heap, see the description of the files in \heap. The 
same applies for almost all of VC++Files's subdirectories (bdb, client,
isam, libmysql, etc.). The difference is that the \VC++Files variants
are specifically for compilation with Microsoft Visual C++ in 32-bit
Windows environments.

In addition to the "subdirectories which are duplicates of
directories", VC++Files contains these subdirectories, which are not
duplicates:
@itemize @bullet
@item
comp_err  --  (nearly empty)
@item
contrib  --  (nearly empty)
@item
InstallShield  --  script files
@item
isamchk  --  (nearly empty)
@item
libmysqltest  --  one small non-MySQL test program: mytest.c
@item
myisamchk  --  (nearly empty)
@item
myisamlog  --  (nearly empty)
@item
myisammrg  --  (nearly empty)
@item
mysqlbinlog  --  (nearly empty)
@item
mysqlmanager  --  MFC foundation class files created by AppWizard
@item
mysqlserver  --  (nearly empty)
@item
mysqlshutdown  --  one short program, mysqlshutdown.c
@item
mysqlwatch.c  --  Windows service initialization and monitoring
@item
my_print_defaults  --  (nearly empty)
@item
pack_isam  --  (nearly empty)
@item
perror  --  (nearly empty)
@item
prepare  --  (nearly empty)
@item
replace  --  (nearly empty)
@item
SCCS  --  source code control system
@item
test1  --  tests connecting via X threads
@item
thr_insert_test  --  (nearly empty)
@item
thr_test  --  one short program used to test for memory-allocation bug
@item
winmysqladmin  --  the winmysqladmin.exe source
@end itemize

The "nearly empty" subdirectories noted above (e.g. comp_err and isamchk) 
are needed because VC++ requires one directory per project (i.e. executable). 
We are trying to keep to the MySQL standard source layout and compile only 
to different directories.

@node vio directory, zlib directory, VC++Files directory, Source directory listing
@subsection The @file{vio} Directory

Virtual I/O Library.

The VIO routines are wrappers for the various network I/O calls that
happen with different protocols. The idea is that in the main modules
one won't have to write separate bits of code for each protocol. Thus
vio's purpose is somewhat like the purpose of Microsoft's winsock
library.

The underlying protocols at this moment are: TCP/IP, Named Pipes (for
WindowsNT), Shared Memory, and Secure Sockets (SSL).

The C programs are:
@itemize @bullet
@item
test-ssl.c  --  Short standalone test program: SSL 
@item
test-sslclient.c  --  Short standalone test program: clients 
@item
test-sslserver.c  --  Short standalone test program: server 
@item
vio.c  --  Declarations + open/close functions 
@item
viosocket.c  --  Send/retrieve functions 
@item
viossl.c  --  SSL variations for the above 
@item
viosslfactories.c  --  Certification / Verification 
@item
viotest.cc  --  Short standalone test program: general 
@item
viotest-ssl.c  --  Short standalone test program: SSL 
@item
viotest-sslconnect.cc  --  Short standalone test program: SSL connect 
@end itemize

The older functions -- raw_net_read, raw_net_write -- are now
obsolete.

@node zlib directory,  , vio directory, Source directory listing
@subsection The @file{zlib} Directory

Data compression library, used on Windows.

zlib is a data compression library used to support the compressed
protocol and the COMPRESS/UNCOMPRESS functions under Windows.
On Unix, MySQL uses the system libgz.a library for this purpose.

Zlib -- which presumably stands for "Zip Library" -- is not a MySQL
package. It was produced by the GNU Zip (gzip.org) people. Zlib is a
variation of the famous "Lempel-Ziv" method, which is also used by
"Zip". The method for reducing the size of any arbitrary string of
bytes is as follows:
@itemize @bullet
@item
Find a substring which occurs twice in the string.
@item
Replace the second occurrence of the substring with (a) a pointer to
the first occurrence, plus (b) an indication of the length of the
first occurrence.
@end itemize

There is a full description of the library's functions in the gzip
manual at
@url{http://www.gzip.org/zlib/manual.html}.
There is therefore no need to list the modules in this document.

The MySQL program \mysys\my_compress.c uses zlib for packet compression. 
The client sends messages to the server which are compressed by zlib. 
See also: @file{\sql\net_serv.cc}.

@node Files in InnoDB Sources,  , Files in MySQL Sources, Top
@chapter Annotated List of Files in the @code{InnoDB} Source Code Distribution

ERRATUM BY HEIKKI TUURI (START)

Errata about @code{InnoDB} row locks:

@example
  #define LOCK_S  4 /* shared */
  #define LOCK_X  5 /* exclusive */
...
@strong{/* Waiting lock flag */}
  #define LOCK_WAIT 256
/* this wait bit should be so high that it can be ORed to the lock
mode and type; when this bit is set, it means that the lock has not
yet been granted, it is just waiting for its turn in the wait queue */
...
@strong{/* Precise modes */}
  #define LOCK_ORDINARY 0
/* this flag denotes an ordinary next-key lock in contrast to LOCK_GAP
or LOCK_REC_NOT_GAP */
  #define LOCK_GAP 512
/* this gap bit should be so high that it can be ORed to the other
flags; when this bit is set, it means that the lock holds only on the
gap before the record; for instance, an x-lock on the gap does not
give permission to modify the record on which the bit is set; locks of
this type are created when records are removed from the index chain of
records */
  #define LOCK_REC_NOT_GAP 1024
/* this bit means that the lock is only on the index record and does
NOT block inserts to the gap before the index record; this is used in
the case when we retrieve a record with a unique key, and is also used
in locking plain SELECTs (not part of UPDATE or DELETE) when the user
has set the READ COMMITTED isolation level */
  #define LOCK_INSERT_INTENTION 2048
/* this bit is set when we place a waiting gap type record lock
request in order to let an insert of an index record to wait until
there are no conflicting locks by other transactions on the gap; note
that this flag remains set when the waiting lock is granted, or if the
lock is inherited to a neighboring record */
@end example

ERRATUM BY HEIKKI TUURI (END)

The @code{InnoDB} source files are the best place to look for information
about internals of the file structure that MySQLites can optionally
use for transaction support. But when you first look at all the
subdirectories and file names you'll wonder: Where Do I Start? It can
be daunting.

Well, I've been through that phase, so I'll pass on what I had to
learn on the first day that I looked at @code{InnoDB} source files. I am very
sure that this will help you grasp, in overview, the organization of
@code{InnoDB} modules. I'm also going to add comments about what is going on
-- which you should mistrust! These comments are reasonable working
hypotheses; nevertheless, they have not been subjected to expert peer
review.

Here's how I'm going to organize the discussion. I'll take each of the
32 @code{InnoDB} subdirectories that come with the MySQL 4.0 source code in
@file{\mysql\innobase} (on my Windows directory). The format of each section
will be like this every time:

@strong{\subdirectory-name (LONGER EXPLANATORY NAME)}@*
@multitable @columnfractions .10 .20 .40 .50
@item @strong{File Name} @tab @strong{What Name Stands For} @tab @strong{Size} @tab @strong{Comment Inside File}
@item file-name
@tab my-own-guess
@tab in-bytes
@tab from-the-file-itself
@end multitable
...@*
My-Comments@*

For example:
@example
"
@strong{\ha (HASHING)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  ha0ha.c     Hashing/Hashing        7,452   Hash table with external chains

  Comments about hashing will be here.
"
@end example

The "Comment Inside File" column is a direct copy from the first /*
comment */ line inside the file. All other comments are mine. After
I've discussed each directory, I'll finish with some notes about
naming conventions and a short list of URLs that you can use for
further reference.

Now let's begin.

@example

@strong{\ha (HASHING)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  ha0ha.c     Hashing / Hashing      7,452   Hash table with external chains

I'll hold my comments until the next section, \hash (HASHING).

@strong{\hash (HASHING)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  hash0hash.c Hashing / Hashing      3,257   Simple hash table utility

The two C programs in the \ha and \hashing directories -- ha0ha.c and
hash0hash.c -- both refer to a "hash table" but hash0hash.c is
specialized, it is mostly about accessing points in the table under
mutex control.

When a "database" is so small that InnoDB can load it all into memory
at once, it's more efficient to access it via a hash table. After all,
no disk i/o can be saved by using an index lookup, if there's no disk.

@strong{\os (OPERATING SYSTEM)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  os0shm.c    OS / Shared Memory     3,150   To shared memory primitives
  os0file.c   OS / File             64,412   To i/o primitives
  os0thread.c OS / Thread            6,827   To thread control primitives
  os0proc.c   OS / Process           3,700   To process control primitives
  os0sync.c   OS / Synchronization  10,208   To synchronization primitives

This is a group of utilities that other modules may call whenever they
want to use an operating-system resource. For example, in os0file.c
there is a public InnoDB function named os_file_create_simple(), which
simply calls the Windows-API function CreateFile. Naturally the
contents of this group are somewhat different for other operating systems.

The "Shared Memory" functions in os0shm.c are only called from the
communications program com0shm.c (see \com COMMUNICATIONS). The i/o
and thread-control primitives are called extensively. The word
"synchronization" in this context refers to the mutex-create and
mutex-wait functionality.

@strong{\ut (UTILITIES)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  ut0ut.c     Utilities / Utilities  7,041   Various utilities
  ut0byte.c   Utilities / Debug      1,856   Byte utilities
  ut0rnd.c    Utilities / Random     1,475   Random numbers and hashing
  ut0mem.c    Utilities / Memory     5,530   Memory primitives
  ut0dbg.c    Utilities / Debug        642   Debug utilities

The two functions in ut0byte.c are just for lower/upper case
conversion and comparison. The single function in ut0rnd.c is for
finding a prime slightly greater than the given argument, which is
useful for hash functions, but unrelated to randomness. The functions
in ut0mem.c are wrappers for "malloc" and "free" calls -- for the
real "memory" module see section \mem (MEMORY). Finally, the
functions in ut0ut.c are a miscellany that didn't fit better elsewhere:
get_high_bytes, clock, time, difftime, get_year_month_day, and "sprintf"
for various diagnostic purposes.

In short: the \ut group is trivial.

@strong{\buf (BUFFERING)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  buf0buf.c   Buffering / Buffering 53,246   The database buffer buf_pool
  buf0flu.c   Buffering / Flush     23,711   ... flush algorithm
  buf0lru.c   / least-recently-used 20,245   ... replacement algorithm
  buf0rea.c   Buffering / read      17,399   ... read

There is a separate file group (\mem MEMORY) which handles memory
requests in general.A "buffer" usually has a more specific
definition, as a memory area which contains copies of pages that
ordinarily are in the main data file. The "buffer pool" is the set
of all buffers (there are lots of them because InnoDB doesn't
depend on the OS's caching to make things faster).

The pool size is fixed (at the time of this writing) but the rest of
the buffering architecture is sophisticated, involving a host of
control structures. In general: when InnoDB needs to access a new page
it looks first in the buffer pool; InnoDB reads from disk to a new
buffer when the page isn't there; InnoDB chucks old buffers (basing
its decision on a conventional Least-Recently-Used algorithm) when it
has to make space for a new buffer.

There are routines for checking a page's validity, and for read-ahead.
An example of "read-ahead" use: if a sequential scan is going on, then
a DBMS can read more than one page at a time, which is efficient
because reading 32,768 bytes (two pages) takes less than twice as long
as reading 16,384 bytes (one page).

@strong{\btr (B-TREE)}
  File Name   What Name Stands For         Size     Comment Inside File
  ---------   --------------------         ------   -------------------
  btr0btr.c   B-tree / B-tree              74,255   B-tree
  btr0cur.c   B-tree / Cursor              94,950   index tree cursor
  btr0sea.c   B-tree / Search              36,580   index tree adaptive search
  btr0pcur.c  B-tree / persistent cursor   14,548   index tree persistent cursor

If you total up the sizes of the C files, you'll see that \btr is the
second-largest file group in InnoDB. This is understandable because
maintaining a B-tree is a relatively complex task. Luckily, there has
been a lot of work done to describe efficient management of B-tree and
B+-tree structures, much of it open-source or public-domain, since
their original invention over thirty years ago.

@code{InnoDB} likes to put everything in B-trees. This is what I'd call a
"distinguishing characteristic" because in all the major DBMSs (like
IBM DB2, Microsoft SQL Server, and Oracle), the main or default or
classic structure is the heap-and-index. In InnoDB the main structure
is just the index. To put it another way: InnoDB keeps the rows in the
leaf node of the index, rather than in a separate file. Compare
Oracle's Index Organized Tables, and Microsoft SQL Server's Clustered
Indexes.

This, by the way, has some consequences. For example, you may as well
have a primary key since otherwise InnoDB will make one anyway. And
that primary key should be the shortest of the candidate keys, since
@code{InnoDB}
will use it as a pointer if there are secondary indexes.

Most importantly, it means that rows have no fixed address. Therefore
the routines for managing file pages should be good. We'll see about
that when we look at the \row (ROW) program group later.

@strong{\com (COMMUNCATION)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  com0com.c   Communication          6,913   Communication primitives
  com0shm.c   Communication /       24,633   ... through shared memory
              Shared Memory

The communication primitives in com0com.c are said to be modelled
after the ones in Microsoft's winsock library (the Windows Sockets
interface). The communication primitives in com0shm.c are at a
slightly lower level, and are called from the routines in com0com.c.

I was interested in seeing how InnoDB would handle inter-process
communication, since there are many options -- named pipes, TCP/IP,
Windows messaging, and Shared Memory being the main ones that come to
mind. It appears that InnoDB prefers Shared Memory. The main idea is:
there is an area of memory which two different processes (or threads,
of course) can both access. To communicate, a thread gets an
appropriate mutex, puts in a request, and waits for a response. Thread 
interaction is also a subject for the os0thread.c program in another 
program group, \os (OPERATING SYSTEM).

@strong{\dyn (DYNAMICALLY ALLOCATED ARRAY)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  dyn0dyn.c   Dynamic / Dynamic        994   dynamically allocated array

There is a single function in the dyn0dyn.c program, for adding a
block to the dynamically allocated array. InnoDB might use the array
for managing concurrency between threads.

At the moment, the \dyn program group is trivial.

@strong{\fil (FILE)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  fil0fil.c   File / File           39,725   The low-level file system

The reads and writes to the database files happen here, in
co-ordination with the low-level file i/o routines (see os0file.h in
the \os program group).

Briefly: a table's contents are in pages, which are in files, which
are in tablespaces. Files do not grow; instead one can add new files
to the tablespace. As we saw earlier (discussing the \btr program group)
the pages are nodes of B-trees. Since that's the case, new additions can
happen at various places in the logical file structure, not
necessarily at the end. Reads and writes are asynchronous, and go into
buffers, which are set up by routines in the \buf program group.

@strong{\fsp (FILE SPACE)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  fsp0fsp.c   File Space Management 100,271  File space management

I would have thought that the \fil (FILE) and \fsp (FILE SPACE)
MANAGEMENT programs would fit together in the same program group;
however, I guess the InnoDB folk are splitters rather than lumpers.

It's in fsp0fsp.c that one finds some of the descriptions and comments
of extents, segments, and headers. For example, the "descriptor bitmap
of the pages in the extent" is in here, and you can find as well how
the free-page list is maintained, what's in the bitmaps, and what
various header fields' contents are.

@strong{\fut (FILE UTILITY)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  fut0fut.c   File Utility / Utility   293   File-based utilities
  fut0lst.c   File Utility / List   14,129   File-based list utilities

Mainly these small programs affect only file-based lists, so maybe
saying "File Utility" is too generic. The real work with data files 
goes on in the \fsp program group.

@strong{\log (LOGGING)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  log0log.c   Logging / Logging     77,834   Database log
  log0recv.c  Logging / Recovery    80,701   Recovery

I've already written about the \log program group, so here's a link to
my previous article: "How Logs work with MySQL and InnoDB":
@url{http://www.devarticles.com/c/a/MySQL/How-Logs-Work-On-MySQL-With-InnoDB-Tables}


@strong{\mem (MEMORY)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  mem0mem.c   Memory / Memory        9,971   The memory management
  mem0dbg.c   Memory / Debug        21,297   ... the debug code
  mem0pool.c  Memory / Pool         16,293   ... the lowest level

There is a long comment at the start of the mem0pool.c program, which
explains what the memory-consumers are, and how InnoDB tries to
satisfy them. The main thing to know is that there are really three
pools: the buffer pool (see the \buf program group), the log pool (see the \log
program group), and the common pool, which is where everything that's
not in the buffer or log pools goes (for example the parsed SQL
statements and the data dictionary cache).

@strong{\mtr (MINI-TRANSACTION)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  mtr0mtr.c   Mini-transaction /    12,433   Mini-transaction buffer
  mtr0log.c   Mini-transaction / Log 8,180   ... log routines

The mini-transaction routines are called from most of the other
program groups. I'd describe this as a low-level utility set.

@strong{\que (QUERY GRAPH)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  que0que.c   Query Graph / Query   35,964   Query graph

The program que0que.c ostensibly is about the execution of stored
procedures which contain commit/rollback statements. I took it that
this has little importance for the average MySQL user.

@strong{\rem (RECORD MANAGER)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  rem0rec.c   Record Manager        14,961   Record Manager
  rem0cmp.c   Record Manager /      25,263   Comparison services for records
              Comparison

There's an extensive comment near the start of rem0rec.c title
"Physical Record" and it's recommended reading. At some point you'll
ask what are all those bits that surround the data in the rows on a page, 
and this is where you'll find the answer.

@strong{\row (ROW)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  row0row.c   Row / Row             16,764   General row routines
  row0uins.c  Row / Undo Insert      7,199   Fresh insert undo
  row0umod.c  Row / Undo Modify     17,147   Undo modify of a row
  row0undo.c  Row / Undo            10,254   Row undo
  row0vers.c  Row / Version         12,288   Row versions
  row0mysql.c Row / MySQL           63,556   Interface [to MySQL]
  row0ins.c   Row / Insert          42,829   Insert into a table
  row0sel.c   Row / Select          85,923   Select
  row0upd.c   Row / Update          44,456   Update of a row
  row0purge.c Row / Purge           14,961   Purge obsolete records

Rows can be selected, inserted, updated/deleted, or purged (a
maintenance activity). These actions have ancillary actions, for
example after insert there can be an index-update test, but it seems 
to me that sometimes the ancillary action has no MySQL equivalent (yet) 
and so is inoperative.

Speaking of MySQL, notice that one of the larger programs in the \row
program group is the "interface between Innobase row operations and
MySQL" (row0mysql.c) -- information interchange happens at this level
because rows in InnoDB and in MySQL are analogous, something which
can't be said for pages and other levels.

@strong{\srv (Server)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  srv0srv.c   Server / Server       79,058   Server main program
  srv0que.c   Server / Query         2,361   Server query execution
  srv0start.c Server / Start        34,586   Starts the server

This is where the server reads the initial configuration files, splits
up the threads, and gets going. There is a long comment deep in the
program (you might miss it at first glance) titled "IMPLEMENTATION OF
THE SERVER MAIN PROGRAM" in which you'll find explanations about
thread priority, and about what the responsibiities are for various 
thread types.

@code{InnoDB} has many threads, for example "user threads" (which wait for
client requests and reply to them), "parallel communication threads"
(which take part of a user thread's job if a query process can be
split), "utility threads" (background priority), and a "master thread"
(high priority, usually asleep).

@strong{\thr (Thread Local Storage)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  thr0loc.c   Thread / Local         5,261   The thread local storage

@code{InnoDB} doesn't use the Windows-API thread-local-storage functions,
perhaps because they're not portable enough.

@strong{\trx (Transaction)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  trx0trx.c   Transaction /         37,447   The transaction
  trx0purge.c Transaction / Purge   26,782   ... Purge old versions
  trx0rec.c   Transaction / Record  36,525   ... Undo log record
  trx0sys.c   Transaction / System  20,671   ... System
  trx0rseg.c  / Rollback segment     6,214   ... Rollback segment
  trx0undo.c  Transaction / Undo    46,595   ... Undo log

@code{InnoDB}'s transaction management is supposedly "in the style of Oracle"
and that's close to true but can mislead you. 
@itemize @bullet
@item
First: @code{InnoDB} uses rollback segments like Oracle8i does -- but
Oracle9i uses a different name 
@item
Second: @code{InnoDB} uses multi-versioning like Oracle does -- but I see
nothing that looks like an Oracle ITL being stored in the @code{InnoDB} data
pages. 
@item
Third: @code{InnoDB} and Oracle both have short (back-to-statement-start)
versioning for the @code{READ COMMITTED} isolation level and long
(back-to-transaction-start) versioning for higher levels -- but @code{InnoDB}
and Oracle have different "default" isolation levels. 
@item
Finally: @code{InnoDB}'s documentation says it has to lock "the gaps before
index keys" to prevent phantoms -- but any Oracle user will tell you that
phantoms are impossible anyway at the @code{SERIALIZABLE} isolation level, so 
key-locks are unnecessary.
@end itemize

The main idea, though, is that @code{InnoDB} has multi-versioning. So does
Oracle. This is very different from the way that DB2 and SQL Server do
things.

@strong{\usr (USER)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  usr0sess.c  User / Session        27,415   Sessions

One user can have multiple sessions (the session being all the things
that happen betweeen a connect and disconnect). This is where @code{InnoDB}
tracks session IDs, and server/client messaging. It's another of those
items which is usually MySQL's job, though.

@strong{\data (DATA)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  data0data.c Data / Data           26,002   SQL data field and tuple
  data0type.c Data / Type            2,122   Data types

This is a collection of minor utility routines affecting rows.

@strong{\dict (DICTIONARY)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  dict0dict.c Dictionary / Dictionary 84,667 Data dictionary system
  dict0boot.c Dictionary / boot     12,134   ... creation and booting
  dict0load.c Dictionary / load     26,546   ... load to memory cache
  dict0mem.c  Dictionary / memory    8,221   ... memory object creation

The data dictionary (known in some circles as the catalog) has the
metadata information about objects in the database -- column sizes,
table names, and the like.

@strong{\eval (EVALUATING)}
  File Name   What Name Stands For  Size    Comment Inside File
  ---------   --------------------  ------  -------------------
  eval0eval.c Evaluating/Evaluating 15,682  SQL evaluator
  eval0proc.c Evaluating/Procedures  5,000  Executes SQL procedures

The evaluating step is a late part of the process of interpreting an
SQL statement -- parsing has already occurred during \pars (PARSING).

The ability to execute SQL stored procedures is an InnoDB feature, but
not a MySQL feature, so the eval0proc.c program is unimportant.

@strong{\ibuf (INSERT BUFFER)}
  File Name   What Name Stands For  Size     Comment Inside File
  ---------   --------------------  ------   -------------------
  ibuf0ibuf.c Insert Buffer /       69,884   Insert buffer

The words "Insert Buffer" mean not "buffer used for INSERT" but
"insertion of a buffer into the buffer pool" (see the \buf BUFFER
program group description). The matter is complex due to possibilities
for deadlocks, a problem to which the comments in the ibuf0ibuf.c 
program devote considerable attention.

@strong{\mach (MACHINE FORMAT)}
  File Name   What Name Stands For  Size    Comment Inside File
  ---------   --------------------  ------  -------------------
  mach0data.c Machine/Data           2,319  Utilities for converting

The mach0data.c program has two small routines for reading compressed
ulints (unsigned long integers).

@strong{\lock (LOCKING)}
  File Name   What Name Stands For  Size    Comment Inside File
  ---------   --------------------  ------  -------------------
  lock0lock.c Lock / Lock           127,646 The transaction lock system

If you've used DB2 or SQL Server, you might think that locks have their
own in-memory table, that row locks might need occasional escalation to 
table locks, and that there are three lock types: Shared, Update, Exclusive. 

All those things are untrue with @code{InnoDB}! Locks are kept in the database 
pages. A bunch of row locks can't be rolled together into a single table 
lock. And most importantly there's only one lock type. I call this type 
"Update" because it has the characteristics of DB2 / SQL Server Update 
locks, that is, it blocks other updates but doesn't block reads. 
Unfortunately, @code{InnoDB} comments refer to them as "x-locks" etc.

To sum it up: if your background is Oracle you won't find too much
surprising, but if your background is DB2 or SQL Server the locking
concepts and terminology will probably confuse you at first.

You can find an online article about the differences between
Oracle-style and DB2/SQL-Server-style locks at:
@url{http://dbazine.com/gulutzan6.html}

@strong{\odbc (ODBC)}
  File Name   What Name Stands For Size    Comment Inside File
  ---------   --------------------  ------  -------------------
  odbc0odbc.c ODBC / ODBC           16,865  ODBC client library

The odbc0odbc.c program has a small selection of old ODBC-API
functions: SQLAllocEnv, SQLAllocConnect, SQLAllocStmt, SQLConnect, 
SQLError, SQLPrepare, SQLBindParameter, SQLExecute.

@strong{\page (PAGE)}
  File Name   What Name Stands For  Size    Comment Inside File
  ---------   --------------------  ------  -------------------
  page0page.c Page / Page           44,309  Index page routines
  page0cur.c  Page / Cursor         30,305  The page cursor

It's in the @file{page0page.c} program that you'll learn as follows: index
pages start with a header, entries in the page are in order, at the
end of the page is a sparse "page directory" (what I would have called
a slot table) which makes binary searches easier.

Incidentally, the program comments refer to "a page size of 8 kB"
which seems obsolete. In @file{univ.i} (a file containing universal
constants) the page size is now #defined as 16KB.

@strong{\pars (PARSING)}
  File Name   What Name Stands For Size    Comment Inside File
  ---------   -------------------- ------  -------------------
  pars0pars.c Parsing/Parsing      49,947  SQL parser
  pars0grm.c  Parsing/Grammar      62,685  A Bison parser
  pars0opt.c  Parsing/Optimizer    30,809  Simple SQL Optimizer
  pars0sym.c  Parsing/Symbol Table  5,541  SQL parser symbol table
  lexyy.c     ?/Lexer              59,948  Lexical scanner

The job is to input a string containing an SQL statement and output an
in-memory parse tree. The EVALUATING (subdirectory \eval) programs
will use the tree.

As is common practice, the Bison and Flex tools were used -- @file{pars0grm.c} 
is what the Bison parser produced from an original file named
@file{pars0grm.y} 
(not supplied), and @file{lexyy.c} is what Flex produced.

Since @code{InnoDB} is a DBMS by itself, it's natural to find SQL parsing in
it. But in the MySQL/InnoDB combination, MySQL handles most of the
parsing. These files are unimportant.

@strong{\read (READ)}
  File Name   What Name Stands For Size    Comment Inside File
  ---------   -------------------- ------  -------------------
  read0read.c Read / Read           6,244  Cursor read

The @file{read0read.c} program opens a "read view" of a query result, using
some functions in the \trx program group.

@strong{\sync (SYNCHRONIZATION)}
  File Name   What Name Stands For Size    Comment Inside File
  ---------   -------------------- ------  -------------------
  sync0sync.c Synchronization /    35,918  Mutex, the basic sync primitive
  sync0arr.c  ... / array          26,461  Wait array used in primitives
  sync0ipm.c  ... / interprocess    4,027  for interprocess sync
  sync0rw.c   ... / read-write     22,220  read-write lock for thread sync

A mutex (Mutual Exclusion) is an object which only one thread/process
can hold at a time. Any modern operating system API has some functions
for mutexes; however, as the comments in the sync0sync.c code indicate, it
can be faster to write one's own low-level mechanism. In fact the old
assembly-language XCHG trick is in here -- this is the only program
that contains any assembly code.
@end example

This is the end of the section-by-section account of @code{InnoDB}
subdirectories.

@*
@strong{A Note About File Naming}

There appears to be a naming convention. The first letters of the file
name are the same as the subdirectory name, then there is a '0'
separator, then there is an individual name. For the main program in a
subdirectory, the individual name may be a repeat of the subdirectory
name. For example, there is a file named ha0ha.c (the first two
letters ha mean "it's in in subdirectory ..\ha", the next letter 0
means "0 separator", the next two letters mean "this is the main ha
program"). This naming convention is not strict, though: for example
the file lexyy.c is in the \pars subdirectory.

@*
@strong{A Note About Copyrights}

Most of the files begin with a copyright notice or a creation date,
for example "Created 10/25/1995 Heikki Tuuri". I don't know a great
deal about the history of @code{InnoDB}, but found it interesting that most
creation dates were between 1994 and 1998.

@*
@strong{References}

@itemize @bullet
@item
Ryan Bannon, Alvin Chin, Faryaaz Kassam and Andrew Roszko.
"InnoDB Concrete Architecture"
@url{http://www.swen.uwaterloo.ca/~mrbannon/cs798/assignment_02/innodb.pdf}

A student paper. It's an interesting attempt to figure out @code{InnoDB}'s
architecture using tools, but I didn't end up using it for the specific 
purposes of this article.

@item
Peter Gulutzan.
"How Logs Work With MySQL And InnoDB"
@url{http://www.devarticles.com/c/a/MySQL/How-Logs-Work-On-MySQL-With-InnoDB-Tables}

@item
Heikki Tuuri.
"InnoDB Engine in MySQL-Max-3.23.54 / MySQL-4.0.9: The Up-to-Date
Reference Manual of InnoDB"
@url{http://www.innodb.com/ibman.html}

This is the natural starting point for all InnoDB information. Mr
Tuuri also appears frequently on MySQL forums.
@end itemize

@summarycontents
@contents

@bye
